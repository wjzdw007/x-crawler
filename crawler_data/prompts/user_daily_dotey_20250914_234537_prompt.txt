# LLM Prompt 保存记录
生成时间: 2025-09-14 23:45:37
总结类型: user_daily
用户: @dotey
推文数量: 11
数据哈希: 51b8aea0

================================================================================
完整Prompt内容:
================================================================================

请分析以下dotey的推文，重点关注AI技术、编程技巧和学习资源：

用户信息：用户名: @dotey

推文内容：


==================================================1. 推文ID: 1966931397542900041
时间: Sat Sep 13 18:26:03 +0000 2025
内容: &gt; “语言是人为了实现泛化而发明出来的工具，这一点比其他东西更本质。”

感触最深的是姚顺雨谈到语言对于通用人工智能的重要性，正因为有了语言和推理，才让智能有了泛化的可能，在大语言模型之前，AI 都是在各个细分领域耕耘。

2. 推文ID: 1966771858402836675
时间: Sat Sep 13 07:52:06 +0000 2025
内容: RT @9hills: @dotey 我最近在研究对应的训练，其实function calling后面也是渲染为chat template。所以逻辑上越强大的模型，泛化能力越强。你用react template还是fc template 都差不多。

然后react有个好处就是…

3. 推文ID: 1966765123118170304
时间: Sat Sep 13 07:25:20 +0000 2025
内容: https://t.co/wPzpuqfKvB 这个 Agent 能力指的是：
1. 规划能力
2. 调用工具的能力
3. 判断任务是否完成的能力

举个例子来说，让 AI Agent 去 Debug 一个程序 Bug。

如果是以前 GPT-4o 这样没有 Agent 能力的模型，这个任务需要先写一段 ReAct 提示词，让模型先思考（Thought），模型输出思考的文本后，程序去解析文本，来分析下一步是做什么 Action，分析完了后去执行 Action，比如调用搜索代码工具，调用完工具后，把执行结果给模型，再让模型去观察执行结果，根据执行的结果去看任务是否完成，完成返回结果，没完成继续思考。

这个过程是在模型外部由提示词+代码来控制的，你需要在提示词里面说清楚模型怎么思考，怎么调用工具，怎么观察。模型自己没有能力去思考这些。

就好比你个刚毕业的大学生，你需要给他们详细的操作手册，每一步让他照着操作手册去完成。

如果是 Claude 4 Sonnet 这样的模型，那么你不需要去写 ReAct 提示词和相关代码，只需要告诉它去 Debug 程序 Bug，它有什么工具可以用，那么它会自己去规划任务，去调用工具，去检索代码，去判断是否定位到了 Bug。

代码也相当简单，一个 While 循环就搞定了：当前 LLM 返回结果是不是工具调用，如果是，就继续调用工具，不是，任务结束，就这么简单。

就好比这个大学生已经不需要依赖操作手册，已经学会了不依赖手册去干活了。
[包含媒体: photo, photo]

4. 推文ID: 1966745777063051272
时间: Sat Sep 13 06:08:28 +0000 2025
内容: 过于真实，引起不适🥲 https://t.co/y1RQuu2txn
[包含媒体: photo]

5. 推文ID: 1966728987989672004
时间: Sat Sep 13 05:01:45 +0000 2025
内容: RT @shengxj1: 为了践行vibe coding 今天拍了个歪脖抠腚 https://t.co/NuYEXzYLGn
[包含媒体: photo]

6. 推文ID: 1966719342550176045
时间: Sat Sep 13 04:23:25 +0000 2025
内容: 什么是 ReAct？

ReAct 是 “Reasoning and Acting”（推理与行动）的缩写。它是一种先进的提示词框架，旨在让大语言模型（LLM）不再仅仅是根据已有知识直接生成答案，而是能像人一样，为了找到答案而主动地思考、规划并采取行动。

简单来说，ReAct 就是为AI的大脑植入了一个“思考-行动循环”的机制。在接收到你的问题后，AI会：

1. 思考（Thought）: 首先，它会分析问题，并规划出解决问题的第一步。它会像自言自语一样，把自己的“内心想法”写出来。例如：“我需要先搜索一下关于《三体》作者的信息。”

2. 行动（Action）: 接着，它会决定并执行一个具体的“动作”。这个动作通常是利用外部工具，比如调用一个搜索引擎、一个计算器，或者查询一个数据库。

3. 观察（Observation）: 执行动作后，它会“看到”这个动作带来的结果。例如，搜索引擎返回了刘慈欣的百科页面摘要。

4. 重复循环: AI会根据观察到的新信息，进行下一步的“思考”，然后再次“行动”，再“观察”……如此循环往复，直到它认为已经收集到足够的信息来回答最初的问题为止。

举个例子，如果你问：“苹果公司昨天的收盘价是多少？”
- 思考: “用户在问苹果昨天的股价，我需要用金融查询工具来获取这个信息。”
- 行动: [调用金融API，查询“AAPL”昨天的收盘价]
- 观察: [API返回结果：175.04美元]
- 思考: “我已经获得了准确的股价，现在可以回答用户了。”
- 最终答案: “苹果公司昨天的收盘价是175.04美元。”

7. 推文ID: 1966699902458536246
时间: Sat Sep 13 03:06:10 +0000 2025
内容: RT @vista8: 图片生成提示词：

真实摄影质感，性感亚洲美女特写，乌黑长发慵懒散落，轻咬红唇半张，深邃双眸迷离凝视，微汗珠光泽肌肤，暖橘色氛围光，侧逆光勾勒完美轮廓，锁骨线条若隐若现，柔光虚化背景，超高清肌肤细节，湿润玻璃感唇釉，金色滤镜效果。

选中一张图，输入视频…

8. 推文ID: 1966690065066721779
时间: Sat Sep 13 02:27:05 +0000 2025
内容: 如何用好工具可以参考这篇
https://t.co/HuwXCtTDhu

9. 推文ID: 1966689857863913597
时间: Sat Sep 13 02:26:16 +0000 2025
内容: 如果你的 Agent 还要用 ReAct 框架写 Prompt，那么要么说明你在用没有 Agent 能力的模型（比如 GPT-4o、Gemini 2.5 Pro），要么就是用错了。

因为有 Agent 能力的模型，比如 Claude 4 系列（包括前面的 Claude 3.7 和 GPT-5），是不需要通过 ReAct 提示词来激发 Agent 能力，只要提供正确的工具和合适的工具描述，就会自动的去规划、调用工具和完成任务。

10. 推文ID: 1966687236344123676
时间: Sat Sep 13 02:15:51 +0000 2025
内容: RT @Jason_Young1231: 是时候在 Claude Code 里感受国产模型的实力了！使用 cc-switch, 只需要填入 key 即可一键接入国产模型，本周末将发布重大更新！ https://t.co/UFLWPXfqX6
[包含媒体: photo]

11. 推文ID: 1966685276333281453
时间: Sat Sep 13 02:08:03 +0000 2025
内容: 这其实是取决于使用者的水平，如果你水平高强度大，那么 $200 的是最能发挥 AI 能力的。真正专业人士用 AI 写代码，如果是在 AI Coding 的舒适区：用的人懂+AI 能实现，那么效率会飞起，能做相当多的事情，所产生的价值远超 $200。

我用 AI 写过三类代码：

一类是我很熟悉，相对简单的 AI 训练过的，可以说指哪打哪，速度飞快，因为我只要简单的几句话就能给 AI 提供充足的上下文，指出正确的方向，然后 AI 就是个不知疲倦的聪明的员工，哪怕做出来的结果有点瑕疵，我也能一眼看出来问题所在，稍加指正 AI 就能马上修复。

一类是我自己不熟悉的领域，也没那么简单，那么瓶颈其实是在我自己，我很难精准的描述想要的东西，只能依赖于 AI 随机的抽卡，生成的结果也无法从代码层面验证，只能靠运行结果，但是功能稍微多一点错误累加就无法控制了。

这其实也是很多编程新手用 AI 的困境，瓶颈还是在自身技术水平，已经不是单纯靠 AI 进化能解决的问题。

一类是我自己熟悉但是 AI 能力还不够的领域，这通常是由于 AI 训练预料不足，或者需求过于复杂难以描述清楚，这种说实话 AI 能帮的有限，最多就是一些自动完成或者小模块可以干点体力活。

所以要看你要自己和要让 AI 完成的任务在哪个区间，如果是在 AI Coding 舒适区，就可以多花点，花得多赚得多，否则还是慎重选择。

请整理出技术要点和实用资源。

================================================================================
Prompt结束
================================================================================

# 使用说明
这个文件包含了发送给LLM的完整prompt内容，你可以：
1. 直接复制到其他LLM服务（Claude、ChatGPT等）
2. 调试和优化prompt结构
3. 作为训练数据或示例使用
4. 分析LLM输入输出的对应关系

# 数据来源信息
- 原始推文数据来源: @dotey的推文时间线
- 数据处理: 经过优化嵌套结构转换，便于LLM理解
- 结构特点: 支持复杂的转推、引用、多层嵌套关系分析
