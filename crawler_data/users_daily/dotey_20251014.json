{
  "user": {
    "screen_name": "dotey",
    "name": "",
    "description": "",
    "followers_count": 0,
    "verified": false,
    "is_blue_verified": false
  },
  "date": "20251014",
  "last_updated": "2025-10-21T01:38:27.767810",
  "tweet_count": 16,
  "tweets": [
    {
      "id": "1977905081379926444",
      "text": "张朝阳谈如何对抗焦虑症，很像写 Prompt：多告诉 AI 该干什么，少说不要干什么，说多了反而可能强化了 AI 负面行为\n\n以下内容是 AI 帮总结的内容\n----\n\n别再试图“战胜”焦虑了：重塑心智的真正法则\n\n我们与深渊的距离，或许比想象中更近。在一个看似寻常的夜晚，围坐篝火旁的张朝阳说：“每个人离抑郁症和焦虑症，只有一步之遥。” 这句话如同一颗投入平静湖面的石子，瞬间激起我们内心深处的涟漪。现代生活的快节奏、无休止的竞争与不确定性，让焦虑如影随形，仿佛成了我们这个时代的集体背景音。我们拼命寻找出口，阅读无数文章，尝试各种方法，试图“战胜”或“消除”这种令人不适的情绪，却往往发现自己陷入了更深的泥潭。\n\n这究竟是为什么？难道我们对抗焦虑的方式从一开始就错了吗？如果说，摆脱焦虑的关键并非与之搏斗，而在于一种截然不同的心智模式与行动哲学，我们是否愿意放下手中早已无效的武器，重新学习一种与内心风暴共处，乃至将其转化为生命动力的智慧？这不仅是一场关于情绪管理的探讨，更是一次深入大脑运作原理、重塑自我认知的心智之旅。\n\n为何越想摆脱，越被牢牢抓住？——焦虑的“强化”陷阱\n要理解这一切，我们首先需要洞察一个深刻的心理学悖论：放大焦虑的最好方法，就是去解决焦虑。这个观点听起来或许有悖常理，但它却精准地揭示了我们为何常常在与负面情绪的斗争中败下阵来。我们的本能反应是，当一个问题（比如焦虑）出现时，就必须立刻找到方法去消除它。然而，正是这种“解决”的意图，为焦虑本身提供了源源不断的养料。\n\n想象一下，你因为担心明天的一次重要会议而焦虑不安。为了缓解这种情绪，你可能会开始反复检查演讲稿，上网搜索所有可能的突发状况，甚至试图通过幻想会议的完美情景来“说服”自己不要紧张。这些行为的初衷都是为了“解决”焦虑，但其潜台词却是：“焦虑是一个巨大的、必须被清除的威胁。” 你越是投入精力去对抗它，就越是在向你的大脑确认——这个威胁是真实且致命的。于是，你的大脑进入高度戒备状态，分泌更多压力荷尔蒙，让你变得更加焦虑。你所有的“努力”，都事与愿违地变成了一个自我强化的负面循环。\n\n这种现象在心理学上被称为“经验性回避”（Experiential Avoidance）。我们试图回避、压抑或消除不想要的内在体验（思想、情绪、记忆），但这种回避行为本身，却极大地限制了我们的生活，并最终让那些我们试图摆脱的东西变得更加强大。就如同陷入流沙，越是挣扎，下陷得越快。无论是通过拖延来回避对失败的恐惧，还是通过强迫性检查来消除不安全感，这些看似“合乎逻辑”的应对方式，都在无形中将我们与焦虑捆绑得更紧。\n\n大脑的可塑性：你不是情绪的囚徒，而是心智的工程师\n要打破这个恶性循环，我们必须首先建立一个颠覆性的信念：我们并非自身情绪的囚徒，而是自我心智的工程师。这个信念的科学基础，便是大脑的神经可塑性（Neuroplasticity）。长久以来，我们习惯于将自己的性格、情绪模式归咎于原生家庭、成长经历或是某种天生的特质，仿佛它们是刻在石头上无法更改的宿命。然而，现代神经科学告诉我们，大脑更像是一块可以被反复雕琢的黏土。\n\n我们的每一次思考、每一个行为，都在物理层面上塑造着大脑的神经回路。当两条神经元被同时激活时，它们之间的连接就会被加强。这个过程可以用一句简单的话来概括：“神经元同步放电，连接就会增强”（Neurons that fire together, wire together）。这意味着，你反复进行的思维和行为模式，会像在森林中反复踩踏走出一条小路一样，在大脑中刻下深刻的、自动化的通路。焦虑的循环之所以难以打破，正是因为它已经形成了一条被反复强化的“高速公路”。\n\n但这个原理同样也为我们指明了出路。既然旧的通路可以被强化，那么新的、更健康的通路同样可以被建立。这赋予了我们一种惊人的力量——通过有意识地选择和实践新的行为模式，我们可以主动地、物理性地重塑自己的大脑结构。我们不必再抱怨过去的经历如何塑造了今天的自己，因为从此刻起，我们所做的每一个选择，都在决定着未来大脑的形态。这不再是哲学层面的鼓舞，而是神经科学层面的事实。你，拥有重新布线自己大脑的权力。\n\n“价值锚定”行动法：在情绪风暴中，找到你的指南针\n认识到大脑的可塑性只是第一步，真正的关键在于如何“施工”。这就引出了应对焦虑的核心策略——我称之为“价值锚定”行动法。其精髓在于，将你的行动准则从“感觉”切换到“价值”。换言之，做你认为重要的事，而不是做感觉舒服的事。\n\n当焦虑来临时，我们本能地想去做那些能让我们“感觉好一点”的事，也就是前文提到的“经验性回避”。而“价值锚定”法则要求我们反其道而行之。首先，你需要清晰地定义什么对你而言是真正重要的——你的核心价值是什么？你想成为一个怎样的人？是成为一个有责任感的父母，一个勤奋上进的职员，还是一个健康自律的人？这些价值，就是你在情绪风暴中赖以导航的“指南针”。\n\n接下来，无论你的内心感受如何翻江倒海，你的行动都只听从这个指南针的指引。你感到社交恐惧，但你的价值是“建立真诚的人际关系”，那么你就去参加那个聚会，哪怕只是待上十分钟。你感到拖延和自我怀疑，但你的价值是“完成对手头工作的承诺”，那么你就打开电脑，写下第一行字。你因为担心健康而焦虑，但你的价值是“过一种积极平衡的生活”，那么你就放下手机，出门散步，而不是无休止地搜索症状。\n\n这个过程的核心在于“接纳”与“行动”的并行。你不必等到焦虑消失了再去行动。恰恰相反，你带着焦虑去行动。你允许焦虑作为一种背景噪音存在，就像允许窗外的雨声存在一样，不去理会它，也不去驱赶它，只是将你的全部注意力聚焦在手头那件符合你价值的事情上。每一次这样的行动，都是在为大脑中那条代表着“健康”、“积极”与“勇敢”的新神经通路添砖加瓦。久而久之，这条新路会变得越来越宽阔，而那条通往焦虑的旧路，则因为无人问津而渐渐荒芜。\n\n生命的修行：从“感受”到“行动”的伟大转向\n\n归根结底，摆脱焦虑困扰的旅程，是一场从“被感受驱动”到“以行动引领”的伟大转向。我们总以为，必须先拥有良好的感觉，才能去过理想的生活。但真相恰恰相反，是先去过理想的生活（即践行你的价值），良好的感觉才会随之而来。\n\n我们的想法和情绪，如同天空中飘过的云朵，变幻莫测，我们无法控制它们何时出现，也无法决定它们是什么形状。试图与每一片“乌云”搏斗，只会让我们精疲力竭。而“价值锚定”的智慧在于，承认云的存在，但让我们的双脚始终稳稳地踩在自己选择的道路上。\n\n语言，在这个过程中扮演着至关重要的角色。它不仅仅是交流的工具，更是塑造思维的模具。每天主动地朗读、交谈，甚至自言自语，都是在用积极的、有结构的声音来占据你的心智带宽，让那些随机产生的负面念头无处扎根。这是一种主动的“心智园艺”，用你想种植的花草去填满土地，野草自然就失去了生长的空间。\n\n所以，请停止与焦虑的战争吧。那是一场注定无法获胜的战斗。真正的自由，在于培养一种能力：无论内心有多少噪音，你都能清晰地听到自己价值观的声音，并让那个声音，而不是恐惧的声音，来决定你下一步的方向。这并非一日之功，而是一生的修行。但每一步，都算数。",
      "created_at": "Tue Oct 14 01:11:33 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "video",
          "id": "1977898414869229568",
          "url": "https://video.twimg.com/amplify_video/1977898414869229568/vid/avc1/852x480/zMAOAvJwslB9cz5T.mp4?tag=21",
          "bitrate": 2176000
        }
      ],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 4,
        "favorite_count": 16,
        "reply_count": 1,
        "quote_count": 0
      }
    },
    {
      "id": "1977905155518390356",
      "text": "原始会话：\nhttps://t.co/moJJ2Vntyx",
      "created_at": "Tue Oct 14 01:11:51 +0000 2025",
      "lang": "ja",
      "media": [],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 0,
        "favorite_count": 1,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1977906047013556656",
      "text": "这是由 OpenAI 的 @hemanth_asir 制作的短片，讲述了科技发展的历史。完全由 Sora 制作的短片拼接而成，目前这个拼接过程还很繁琐，据说他们会改进。\n\nhttps://t.co/meTxh2aErR",
      "created_at": "Tue Oct 14 01:15:23 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "video",
          "id": "1977831210505453568",
          "url": "https://video.twimg.com/amplify_video/1977831210505453568/vid/avc1/3780x2160/KKMtckBM_92NMVFn.mp4?tag=21",
          "bitrate": 25128000
        }
      ],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 1,
        "favorite_count": 7,
        "reply_count": 1,
        "quote_count": 0
      }
    },
    {
      "id": "1977953062523183279",
      "text": "RT @JamesGoong: 我举一个为什么程序员必须走出门的例子。\n\n多年前我上班之余做项目，一年都泡在图书馆写代码，因此认识了另外一个也在图书馆写产品创业的上班族。他花了一年业余时间写了一个网站。整个故事是这样的：…",
      "created_at": "Tue Oct 14 04:22:13 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1843666936535887919",
        "text": "我举一个为什么程序员必须走出门的例子。\n\n多年前我上班之余做项目，一年都泡在图书馆写代码，因此认识了另外一个也在图书馆写产品创业的上班族。他花了一年业余时间写了一个网站。整个故事是这样的：\n\n他在澳洲勤工俭学时候在按摩店打工，观察到按摩店客人都是打电话预约，员工都是纸笔记录预约和排班。忙碌起来的时候感觉非常混乱。这种生意里面的员工流转率也高，所以员工请假或者离职了，排班什么也都是手工在本子上处理。有的老板可能还有几个店，就感觉更乱了。\n\n从程序员的角度出发，他觉得弄一个网站，集成日历，可以处理排班和客户预约。然后那边再做一个手机端，客户还可以网站上下单预约，然后客户和商家还能得到提醒等。再加一个多店管理，这么一套东西收点订阅费，不光可以卖按摩店，美容，美发店都可以是潜在客户。\n\n然后我和他去跑地推，那对程序员真的很挑战。这个过程就不细说了。\n\n最后没一个买单的，原因是这样的：\n\n首先按摩店的客户，就算不考虑产品触达的问题，也不会用app或者网站来预约。因为他们最方便的方式就是打个电话预约，麻不麻烦是商家的事。何况按摩店的客户群里面很多可能是中老年，更习惯传统方式。\n\n客户没有用这个产品下单的需求，那么商家用这个产品就不是刚需。事实上对于商家来说，这个网站也并没降本增效。因为对于按摩店，很多就不会专门请一个接电话的前台，本来就是谁闲着谁接电话记录一下。即使专门找个打杂的，他们的人工成本也巨低。而采用一套系统，意味着小小的店面里面，还要有一套前台，电脑和wifi。更别说员工培训的成本，而且这个行业员工还是高流转率。所以这个东西其实反而是增本降效。\n\n美容院和高档美发店，有连锁也有需求，但是他们的需求早就被满足了，对于这种高利润行业，系统迁移和学习的成本，远比订阅是不是便宜一点来的重要。\n\n这件事对我朋友伤害是巨大的，他基本上就不再做创业了。上班的人，没有多少心气和时间可以再来几遍。从 #精益创业 的角度，有很多方法论可以避免我朋友这种浪费了一年的情况。\n\n但是我想说的是，现实和程序员的思维方式往往是完全两样的。从程序员的角度，这个世界上太多东西都不够自动化，不够高效。如果待在自己思维里面头脑风暴，只会越想越对。但是从商业或者行业角度，完全不是这么一回事，是不是全自动化，很多时候一点也不重要。\n\n小到个人创业者，大到互联网企业给传统行业做转型，很多时候都犯了这种自以为是的错误。\n\n#独立开发 #公开构建",
        "created_at": "Tue Oct 08 14:57:06 +0000 2024",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1708132468216487936",
          "name": "在悉尼和稀泥",
          "screen_name": "JamesGoong",
          "description": "💰 上班牛马，下班副业，周末学术，闲暇咨询。边赚工资边搞钱 🚀 做过产品，踩过坑，亏过百万，也赚过📖 记录真实的赚钱过程，研究副业、出海方法，分享真实经历",
          "followers_count": 19336,
          "friends_count": 270,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 195,
          "favorite_count": 1315,
          "reply_count": 85,
          "quote_count": 23
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 195,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1977975824973189320",
      "text": "Ilya 要发新模型了吗？",
      "created_at": "Tue Oct 14 05:52:40 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1977971110923968656",
        "text": "truly the greatest day ever🎗️",
        "created_at": "Tue Oct 14 05:33:56 +0000 2025",
        "lang": "en",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1720046887",
          "name": "Ilya Sutskever",
          "screen_name": "ilyasut",
          "description": "SSI @SSI",
          "followers_count": 532790,
          "friends_count": 3,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 660,
          "favorite_count": 14500,
          "reply_count": 690,
          "quote_count": 346
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 15,
        "reply_count": 7,
        "quote_count": 0
      }
    },
    {
      "id": "1977977682357842354",
      "text": "原来是这个原因🫡\nhttps://t.co/zt5WG1ZWK7",
      "created_at": "Tue Oct 14 06:00:03 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1977973434996130293",
        "text": "@ilyasut It’s about the hostages coming home, not ai. https://t.co/X781cD1bJR",
        "created_at": "Tue Oct 14 05:43:10 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1977973429832921088",
            "url": "https://pbs.twimg.com/media/G3MsWsxaMAAVrFY.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1417826366687383563",
          "name": "Jimmy Apples 🍎/acc",
          "screen_name": "apples_jimmy",
          "description": "Wagmi. 2025. As featured in Bloomberg. As quoted by Nobel Prize winner Demis Hassabis. As mentioned on the Lex Fridman Podcast💺",
          "followers_count": 58728,
          "friends_count": 1610,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 10,
          "favorite_count": 951,
          "reply_count": 17,
          "quote_count": 6
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 5,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1977979568444014969",
      "text": "RT @AI_Whisper_X: 扫描了全球110个AI陪伴平台，发现了一个很魔幻的现象：美国在疯狂做AI女友，中国在疯狂做AI男友。…",
      "created_at": "Tue Oct 14 06:07:32 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1977933948903993402",
        "text": "扫描了全球110个AI陪伴平台，发现了一个很魔幻的现象：美国在疯狂做AI女友，中国在疯狂做AI男友。\n全球52%的AI陪伴公司总部在美国，男性用户占70%，18-24岁这个年龄段男女比甚至到了8:2。Reddit上AI女友社区有4.4万人，AI男友社区不到100人……路透社报道说50%的年轻男性更愿意和AI约会，因为怕被拒绝。https://t.co/7bycED05O6",
        "created_at": "Tue Oct 14 03:06:16 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1841436670169923584",
          "name": "AI Dance",
          "screen_name": "AI_Whisper_X",
          "description": "头部大模型核心算法&VC\n小红书4.0万粉\naidance.info@gmail.com",
          "followers_count": 2534,
          "friends_count": 122,
          "verified": false,
          "is_blue_verified": false
        },
        "stats": {
          "retweet_count": 31,
          "favorite_count": 197,
          "reply_count": 9,
          "quote_count": 4
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 31,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1978116738068742573",
      "text": "帮转",
      "created_at": "Tue Oct 14 15:12:36 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1978079300189356312",
        "text": "公司成立9个月\n搬了新的办公室\n有了新的工位\n非常开心\n有几个空闲工位等你来\n海外增长，AI前端，全栈 Agent 工程师\n投递 o@marswave.ai https://t.co/kl8kufg4U3",
        "created_at": "Tue Oct 14 12:43:50 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1978079262348365826",
            "url": "https://pbs.twimg.com/media/G3OMm9nXUAIdUvf.jpg"
          },
          {
            "type": "photo",
            "id": "1978079262348300289",
            "url": "https://pbs.twimg.com/media/G3OMm9nWUAEknLV.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "6782882",
          "name": "orange.ai",
          "screen_name": "oran_ge",
          "description": "聊硅基 AI，看有机 Orange。",
          "followers_count": 138153,
          "friends_count": 772,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 11,
          "favorite_count": 272,
          "reply_count": 73,
          "quote_count": 3
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 4,
        "reply_count": 0,
        "quote_count": 1
      }
    },
    {
      "id": "1978118963461595478",
      "text": "RT @frxiaobei: 《为什么 95% 的 AI Agent 做不起来？》\n\n非常推荐，踩的坑和解决方案跟我们几乎一模一样，虽然讲得很清楚，架构师视角，值得花 10 分钟读完，应用到工程实践中。\n\n几个点：\n1. 现在大家都还在拼 prompt，只有少数人开始拼上下文结…",
      "created_at": "Tue Oct 14 15:21:27 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1978040334874824867",
        "text": "《为什么 95% 的 AI Agent 做不起来？》\n\n非常推荐，踩的坑和解决方案跟我们几乎一模一样，虽然讲得很清楚，架构师视角，值得花 10 分钟读完，应用到工程实践中。\n\n几个点：\n1. 现在大家都还在拼 prompt，只有少数人开始拼上下文结构。\n\n特别对的一点是：prompt engineering 已经不是核心了，context engineering 才是下一阶段的主战场。给再聪明的大模型喂进去一堆乱七八糟的输入，它还是只会胡说八道。\n市面上跑得稳的 Agent，都是在“什么该让模型看、怎么看、以什么形式看”上下了大功夫的，这一点现在应该是共识了。\n\n2. 记忆系统这事，光是能存起来远远不够\n\n很多公司的 memory，说得好听点是长期记忆，难听点就是个聊天记录仓库。\n\n真正落地的系统要分层记忆（用户级 / 团队级 / 系统级）。文章读完我感觉更多的篇 B 端，C 端要思考的是结合业务来做分层记忆，并且要能让人知道 它记住了什么，并且用户能自己改。否则就不是记忆是监控。\n\n3. 不迷信单模型，这年头还不做 routing 的 agent 就别说自己做 infra 了。\n\n这篇文章提到多模型路由，说得很对。不可能所有请求都丢给 GPT5，成本和时延直接炸掉，表现也未必好。\n\n真正合理的系统，一定是：\n快速反应的轻模型做分类和前处理、重模型做主任务、补一个模型做验证或追问。\n\n一个 agent 后面绑定的一定是一个 LLM 团队。\n\n4. 可追溯/可控/可信，是企业愿意用 Agent 的底线\n\n很多人只想着怎么让 agent 能回答，但企业更关心：这句话是从哪里来的？有没有越权？出了错我怎么追责？\n\nAI 要可治理。\n\n5. 最被低估的一点：Agent ≠ Chatbot\n\n这篇文章最后说到的一点我非常赞同但还不够狠：如果还在用聊天当所有用户交互的方式，那agent 最多是个语音助理。\n\n真的 agent 应该是：先用语言调度任务，然后在页面上看到结构化结果，还能继续点选、调整、组合下一步。这部分很多公司现在在尝试了，交互上比之前全部自然语言高效了太多。\n\n一个特别有意思的点，当主持人问观众“你们中有多少人构建了文本到 SQL 并投入生产？”时，没有一个人举手。",
        "created_at": "Tue Oct 14 10:09:00 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1830880351801221120",
          "name": "凡人小北",
          "screen_name": "frxiaobei",
          "description": "行道途中。非求速成，惟求通达。\n2023 年扎进AI ，打通Know-How，不少赚钱项目，踩过坑，也见过光。\n围城里待得够久了，出来聊聊世界，聊聊技术、聊聊赚钱。",
          "followers_count": 17175,
          "friends_count": 306,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 134,
          "favorite_count": 532,
          "reply_count": 21,
          "quote_count": 5
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 134,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1978155566749950439",
      "text": "Sam Altman 说 ChatGPT 要支持青涩内容了！\n\nSam：我们之前给 ChatGPT 加了一些比较严格的限制，主要是为了在心理健康问题上保持谨慎。我们知道，这样做让很多心理健康完全没问题的用户感觉 ChatGPT 没那么有趣、没那么好用了。不过，考虑到心理健康问题的严重性，我们当时觉得“宁严勿松”，一定要先确保安全。\n\n好消息是，现在我们找到了更好的办法，成功缓解了严重心理健康问题的风险，同时开发了一些新工具。这意味着，我们终于可以放心地放宽之前的大部分限制了。\n\n未来几周内，我们计划推出新版的 ChatGPT。这一版本会允许用户设置更有人情味的个性，就像大家过去最喜欢的那个4o版本一样（甚至我们希望能做得更好！）。如果你希望 ChatGPT 回答起来更像个真人，用大量的表情包，或者表现得就像朋友一样，那么 ChatGPT 都可以做到！（当然，前提是你自己想要，而不是我们为了单纯追求使用量而主动这么做。）\n\n到了今年12月，我们的年龄验证功能会全面上线。这符合我们“把成年人当成成年人来对待”的原则，因此对通过认证的成年人，我们还会进一步放宽限制，比如允许提供成人内容（erotica）。\n\n（注：Erotica 通常翻译为“情色内容”，此处特指适度的成人文学或内容，而非违法的色情内容。）",
      "created_at": "Tue Oct 14 17:46:54 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1978129344598827128",
        "text": "We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.\n\nNow that we have been able to mitigate the serious mental health issues and have new tools, we are going to be able to safely relax the restrictions in most cases.\n\nIn a few weeks, we plan to put out a new version of ChatGPT that allows people to have a personality that behaves more like what people liked about 4o (we hope it will be better!). If you want your ChatGPT to respond in a very human-like way, or use a ton of emoji, or act like a friend, ChatGPT should do it (but only if you want it, not because we are usage-maxxing).\n\nIn December, as we roll out age-gating more fully and as part of our “treat adult users like adults” principle, we will allow even more, like erotica for verified adults.",
        "created_at": "Tue Oct 14 16:02:42 +0000 2025",
        "lang": "en",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1605",
          "name": "Sam Altman",
          "screen_name": "sama",
          "description": "AI is cool i guess",
          "followers_count": 4039640,
          "friends_count": 971,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 1768,
          "favorite_count": 17002,
          "reply_count": 4040,
          "quote_count": 2280
        }
      },
      "stats": {
        "retweet_count": 3,
        "favorite_count": 58,
        "reply_count": 16,
        "quote_count": 2
      }
    },
    {
      "id": "1978186850247295205",
      "text": "RT @Gorden_Sun: NotebookLM生成视频时，会使用nano banana生成视频里的配图了。整体能力提升特别大，有视频，有语音（中文稍有瑕疵但问题不大），视频内容有配图有文字（文字是程序写上去的不是生成的）。\n如果内容足够好，用NotebookLM发自媒体也…",
      "created_at": "Tue Oct 14 19:51:12 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1978046226924019895",
        "text": "NotebookLM生成视频时，会使用nano banana生成视频里的配图了。整体能力提升特别大，有视频，有语音（中文稍有瑕疵但问题不大），视频内容有配图有文字（文字是程序写上去的不是生成的）。\n如果内容足够好，用NotebookLM发自媒体也不是不行。\n下方是我上传了纳瓦尔宝典生成的视频。 https://t.co/vyiHwIbMJM",
        "created_at": "Tue Oct 14 10:32:25 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "video",
            "id": "1978046018487975936",
            "url": "https://video.twimg.com/amplify_video/1978046018487975936/vid/avc1/1280x720/Hzx_8VIYM2Jd7hqP.mp4?tag=21",
            "bitrate": 2176000
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1657474831",
          "name": "Gorden Sun",
          "screen_name": "Gorden_Sun",
          "description": "只发AI相关信息，个人维护的AI资讯日报（已连续日更两年半）👇",
          "followers_count": 35888,
          "friends_count": 1596,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 11,
          "favorite_count": 73,
          "reply_count": 4,
          "quote_count": 0
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 11,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1978211783157731601",
      "text": "REFRAG：Make RAG Great Again\n\nMeta 超级智能实验室（Superintelligence Labs）招了那么多牛人，第一篇论文有点出人意料——他们选择先来优化一下我们已经很熟悉的 RAG（检索增强生成）。\n\n最近 RAG 风评不佳，速度慢，检索精度不高，尤其是现在 Agent 势头正猛，很多人都觉得 RAG 已死，而 REFRAG 则给人以“Make RAG Great Again”的感觉。\n\n先看数据：\n- 首次生成延迟（Time-to-First-Token）缩短了整整 30.85 倍（远超之前最先进方法 3.75 倍）\n- 能够处理的上下文长度增加了 16 倍\n- 在16项主流RAG任务上，全面超越 LLaMA 等之前的明星模型。\n- token 使用数量降低了2-4倍，意味着算力消耗更低。\n- 在摘要、多轮对话、检索问答等场景下，没有任何精度损失。\n\n我本来以为技术很高深，但学习了一下发现原理我也能懂，都不需要等马老师 @dongxi_nlp 讲课了。\n\n不得不感叹：有时候你以为理所当然的事，结果牛人就是能提出一个更好的方案，让你一拍大腿：“原来还能这样。”\n\n传统的 RAG 方案很多人已经不陌生了：\n预处理：文本分块 -> 向量化(Embedding) -> 存向量数据库（通常还会存 Meta 信息，方便找到原始文本和位置）\n检索：用户输入 -> 向量化 -> 向量数据库检索 -> 返回 Top-K 相关文本\n生成：将 Top-K 相关文本和用户输入一起拼接成 Prompt -> LLM 生成 -> 返回结果\n\n这样做，确实能解决不少问题，但也存在一些问题：\n- 绝大部分检索出来的内容其实和用户的问题并不相关。\n- LLM 被迫要处理大量无用的文本。\n- 计算成本高，速度慢，延迟长，上下文空间还被浪费了。\n\n那么 REFRAG 是怎么优化的呢？\n\n它的做法很巧妙，就是检索的时候，返回的结果不是文本块，而是文本块的向量，只有少量重要的文本块的向量会返回原始的文本内容，其他的文本块只返回向量。这样既节约了上下文空间，也让 LLM 能够专注于处理重要的文本。\n\n这可能有点不好理解，来打个比方：\n> 我们有一个百科全书，我们把每一页纸生成一张缩略图（向量），然后把这些缩略图和对应的百科全书页码存到数据库里。现在用户来问问题，我们先把用户的问题也生成一张缩略图，然后在数据库里找出和用户问题缩略图最相似的前 K 张缩略图。假设我们找到了 10 张缩略图，其中有 2 张是非常相关的，我们就把这 2 张缩略图对应的百科全书页码和内容都返回给 LLM，其他 8 张只返回缩略图和页码，不返回内容。这样 LLM 就能专注于处理这 2 页重要内容，而不是被其他 8 页无关内容干扰。而且内容少了，上下文不容易被占满，而且有其他内容的缩略图也可以帮助更好的理解上下文，必要的话还可以二次请求获取更多详细信息。\n\n就好比过去我们逼着模型“看整本书”。而现在让模型先“看缩略图墙”，只在关键处“点开原文”。\n\n这就解决了三个痛点：\n- 首字节很慢 → 少传大量 token，更快开始说话。\n- 显存/KV 压力大 → 输入更短，占用更小，同卡跑更多并发。\n- 吞吐不稳 → 注意力计算随 token 增长很快；压成向量后，每次算得更轻。\n\n在哪些场景有用呢？\n\n- 客服问答、知识搜索、长文总结、垂直智能体：资料多但不需要句句逐字引用。\n- 多轮对话/很长上下文：能把中间那些“参考资料”大部分用缩略图带着走。\n\n但可能不适合的场景：\n- 严格引用/逐字精确（法律、医学、合同条款等）：需要更高“点开原文”的预算，甚至干脆多给 token。\n- 知识库更新很频繁：要有快速重算向量的管线，否则可能“新知识不新”。比如像代码库，还不如用 Greg 更简单方便。\n- 团队工程能力有限：要训练/对齐“缩略图制作器”和“点开什么”的策略，落地不等于即插即用。\n\n其实这还有一个启发，也许以后模型内部的通信，真的不需要用人类的语言了。模型之间可以直接交换“向量”+“元信息”，而不是“文本”，这样效率会更高。",
      "created_at": "Tue Oct 14 21:30:17 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "video",
          "id": "1978195270207717376",
          "url": "https://video.twimg.com/amplify_video/1978195270207717376/vid/avc1/1280x720/BUREg_wul6jX0vzo.mp4?tag=21",
          "bitrate": 2176000
        }
      ],
      "retweet": null,
      "quoted": {
        "id": "1967633931756507564",
        "text": "First paper published by Meta Superintelligence Labs!\n\nIn this paper, they make RAG faster by swapping most retrieved tokens for precomputed &amp; reusable chunk embeddings, called REFRAG\n\nThis method improves its speed by 30x and fitting 16x longer contexts without accuracy loss https://t.co/Tf7oWoqowp",
        "created_at": "Mon Sep 15 16:57:40 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1967633688591843328",
            "url": "https://pbs.twimg.com/media/G05wajCbwAAJ51w.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1722422481942884352",
          "name": "alphaXiv",
          "screen_name": "askalphaxiv",
          "description": "High fidelity research",
          "followers_count": 19674,
          "friends_count": 39,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 229,
          "favorite_count": 1470,
          "reply_count": 20,
          "quote_count": 16
        }
      },
      "stats": {
        "retweet_count": 31,
        "favorite_count": 152,
        "reply_count": 8,
        "quote_count": 4
      }
    },
    {
      "id": "1978219014233972983",
      "text": "视频是 NotebookLM 做的，原始论文加上一点自己的引导，比如使用缩略图的比喻\nhttps://t.co/oSnJlhAihm\n\nhttps://t.co/pbgnAipV8C",
      "created_at": "Tue Oct 14 21:59:01 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1978216234782224814",
        "text": "@dotey 请问这种视频是什么做的？",
        "created_at": "Tue Oct 14 21:47:58 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1846779842920173568",
          "name": "别扒拉我",
          "screen_name": "qinqinlove99",
          "description": "",
          "followers_count": 9,
          "friends_count": 120,
          "verified": false,
          "is_blue_verified": false
        },
        "stats": {
          "retweet_count": 0,
          "favorite_count": 0,
          "reply_count": 0,
          "quote_count": 1
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 8,
        "reply_count": 2,
        "quote_count": 0
      }
    },
    {
      "id": "1978221497954037967",
      "text": "RT @vista8: 刚才看《救猫咪》这本书，里边有一个概念很好玩，就是一定要学会一句话解读任何东西。\n\n写了一个提示词，无论输入任何内容，都变成一句话解读。\n\n提示词如下\n\n【角色 Role】\n你是一位精通叙事艺术的内容策划专家，擅长用最简洁的语言提炼任何内容的核心价值和吸…",
      "created_at": "Tue Oct 14 22:08:53 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1977993907419136344",
        "text": "刚才看《救猫咪》这本书，里边有一个概念很好玩，就是一定要学会一句话解读任何东西。\n\n写了一个提示词，无论输入任何内容，都变成一句话解读。\n\n提示词如下\n\n【角色 Role】\n你是一位精通叙事艺术的内容策划专家，擅长用最简洁的语言提炼任何内容的核心价值和吸引力。你具备：\n- 编剧和影评人的叙事洞察力\n- 图书编辑的内容提炼能力\n- 文案策划的表达技巧\n- 跨媒介内容的理解力\n\n【任务 Task】\n请为用户提供的内容创作一句话概述。内容可能是：\n- 电影、剧集、纪录片等影视作品\n- 书籍、文章、长文本\n- 事件、新闻、故事\n- 概念、理论、主题\n- 或任何其他需要概述的内容\n\n这句话需要：\n1. 准确提炼内容的核心要点或主要冲突\n2. 突出最具吸引力、最独特的元素\n3. 使用简洁、口语化、易懂的表达\n4. 长度控制在20-50字之间（根据内容复杂度灵活调整）\n5. 能够激发读者的兴趣和好奇心\n6. 保持客观准确，不夸大不误导\n\n【格式 Format】\n根据内容类型，采用相应格式输出：\n\n**影视作品：**\n[一句话概述]——《[中文名]》([英文名/原名])\n\n**书籍：**\n[一句话概述]——《[书名]》，[作者]\n\n**文本/文章：**\n[一句话概述]——[来源/标题]\n\n**事件/概念/其他：**\n[一句话概述]——[名称/主题]\n\n**如果用户直接提供大段文本：**\n[一句话概述]\n\n【示例 Examples】\n\n影视作品：\n一对新婚夫妇要在圣诞节这天跑遍双方父母的四个再婚家庭。——《四个圣诞节》(Four Christmases)\n\n一个新入职的员工去参加公司的周末集体度假，结果发现有个人想杀他。——《度假》(The Retreat)\n\n书籍：\n一个普通程序员意外获得了能看到别人剩余寿命的能力，却发现自己只剩三个月。——《三体》前传设定（示例）\n\n文本概述：\n这篇文章分析了为什么人们在社交媒体上会表现得比现实生活中更极端。——社交媒体心理学研究\n\n事件：\n一家初创公司用AI在三天内完成了传统需要三年的药物研发流程。——2024年生物科技突破\n\n概念：\n通过刻意练习任何技能的最小单元，普通人也能在短时间内达到专业水平。——刻意练习理论",
        "created_at": "Tue Oct 14 07:04:31 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1977993590807891968",
            "url": "https://pbs.twimg.com/media/G3M-sOQakAAPiXM.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "6690032",
          "name": "向阳乔木",
          "screen_name": "vista8",
          "description": "喜欢摇滚乐、爱钓鱼的PM\n网站：https://t.co/vnUpLt752o",
          "followers_count": 65624,
          "friends_count": 1363,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 37,
          "favorite_count": 160,
          "reply_count": 5,
          "quote_count": 1
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 37,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1978221696197726568",
      "text": "RT @zouxulucky: 发现Reddit官方出了一个AI问答功能，分享一下这个工具如何挖掘用户需求\n用translate PDF online举例，问了2个问题：\n1、what are the most common complaints from users abou…",
      "created_at": "Tue Oct 14 22:09:40 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1978068307875074430",
        "text": "发现Reddit官方出了一个AI问答功能，分享一下这个工具如何挖掘用户需求\n用translate PDF online举例，问了2个问题：\n1、what are the most common complaints from users about the topic of translate PDF online \n2、common issues with online PDF translator\n评论区告诉你意想不到的使用问题结果方式👇",
        "created_at": "Tue Oct 14 12:00:09 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1978064511291817984",
            "url": "https://pbs.twimg.com/media/G3N_MVpbAAAOADR.jpg"
          },
          {
            "type": "photo",
            "id": "1978066123661955072",
            "url": "https://pbs.twimg.com/media/G3OAqMMa0AAzK2h.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1602939289532502016",
          "name": "翼小旭Sunny Zou",
          "screen_name": "zouxulucky",
          "description": "效率工具PM｜10+年软件出海 & 商业化经验｜动手党，偶尔手搓小工具 记录产品思考 & 出海实战",
          "followers_count": 1887,
          "friends_count": 239,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 14,
          "favorite_count": 76,
          "reply_count": 5,
          "quote_count": 3
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 14,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1978235045249712537",
      "text": "无需改解码器架构，但要补一条训练管线：重建任务 + 课程式持续预训练（CPT）对齐编码器与解码器，再做 SFT 与策略学习。\nhttps://t.co/0xelEnNeyb",
      "created_at": "Tue Oct 14 23:02:43 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1978229881977684352",
        "text": "@dotey 把向量值丢给llm吗 那它能识别吗？这个还真没试过。",
        "created_at": "Tue Oct 14 22:42:12 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "52944483",
          "name": "Wilson",
          "screen_name": "WilsonLiu123",
          "description": "角色(Role) : \n程序猿 (Programer) ｜产品经理(PM) ｜猫奴(Cat Person)  \n爱好( Hobby) : \n阅读(Reading)  | 篮球(Play basketball) |音乐(Music)",
          "followers_count": 29,
          "friends_count": 265,
          "verified": false,
          "is_blue_verified": false
        },
        "stats": {
          "retweet_count": 0,
          "favorite_count": 0,
          "reply_count": 0,
          "quote_count": 1
        }
      },
      "stats": {
        "retweet_count": 1,
        "favorite_count": 2,
        "reply_count": 0,
        "quote_count": 0
      }
    }
  ]
}