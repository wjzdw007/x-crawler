{
  "user": {
    "screen_name": "dotey",
    "name": "",
    "description": "",
    "followers_count": 0,
    "verified": false,
    "is_blue_verified": false
  },
  "date": "20251105",
  "last_updated": "2025-11-07T01:39:11.641835",
  "tweet_count": 23,
  "tweets": [
    {
      "id": "1985873353929081292",
      "text": "原提示词中文非JSON版：\n\n核心风格与外观\n- 模式： 原始照片级真实感，高保真度。\n- 外观： K-Pop 偶像美学，肤色无瑕，高分辨率数码摄影质感，风格时尚。\n\n摄像机与镜头\n- 视角： 略微的高角度，主体直视镜头。\n- 取景： 极端特写（ECU），构图紧凑，焦点集中在脸部和肩膀。\n- 镜头效果： 使用肖像镜头（例如85mm定焦镜头），营造出极浅的景深（DoF），焦点清晰地对准眼睛。\n- 画质： 高保真，无数字噪点。\n\n场景、光照与主体\n\n1. 环境与光照\n- 设置： 室内工作室或简约的室内环境。\n- 光线： 采用柔和、均匀的美颜光（例如使用大型柔光箱或美颜碟），最大限度地减少阴影。必须在眼睛中创造出清晰的“眼神光”，并强调出皮肤和唇部的光泽高光。\n\n2. 主体描述\n- 身份： 年轻的东亚女性，采用K-Pop偶像的造型风格。\n- 发型： 深棕色长发，呈波浪卷，具有高级的光泽感。\n- 表情： 俏皮、自信，同时略带一丝性感。她直视镜头，嘴巴微张，舌头轻微伸出并搭在下唇上。\n\n3. 妆容与着装\n- 妆容风格： 现代韩式美妆（K-beauty）趋势。\n  * 肤质： 追求无瑕的“玻璃肌”效果，呈现水润、高光泽的完妆感，同时保留逼真的皮肤微观纹理（如毛孔细节）。\n  * 面颊： 涂有玫瑰色腮红，腮红位置偏高。\n  * 唇部： 涂有光泽感的粉色唇彩。\n- 着装： 穿着一件灰色细条纹挂脖上衣，具有结构化设计。上衣带有白色撞色领口翻领，并饰有银色按扣和圆形的金属硬件。\n- 配饰：\n  * 发夹： 在她的左侧头发上佩戴一个装饰性的银色/水钻发夹。\n  * 耳环： 佩戴垂坠式银色耳环（心形图案）。\n\n4. 背景\n- 描述： 简约的、中性的灰色或白色墙壁，完全模糊（呈现焦外成像/背景虚化效果）。\n\n美学控制与渲染要求\n- 渲染目标： 最终图像应为一张高质量的数码照片，适用于宣传材料或社交媒体发布。\n- 材质保真度（重点表现）：\n  * 逼真的皮肤微观纹理（毛孔、光泽感、妆容与皮肤的交互）。\n  * 根根分明的发丝细节。\n  * 细条纹面料的织物质感。\n  * 所有配饰的金属光泽。\n- 色彩与影调：\n  * 色调： 整体色调中性、略微偏暖，肤色应充满活力。\n  * 清晰度： 高清晰度。\n  * 对比度： 均衡的对比度。\n\n排除项 (负面提示词)\n- 禁止的元素： 皮肤瑕疵、斑点、皱纹、刺眼的硬阴影、粗糙或哑光的皮肤、干燥的嘴唇、户外环境、扭曲的面部特征、运动模糊、数字失真或噪点。\n- 禁止的风格： 动漫、绘画、插画、CGI渲染、低分辨率、粗糙的现实主义风格、复古摄影、恐怖谷效应、过度磨皮或塑料质感的皮肤。",
      "created_at": "Wed Nov 05 00:54:37 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1985873344235720705",
          "url": "https://pbs.twimg.com/media/G489SPQWUAEwRWo.jpg"
        }
      ],
      "retweet": null,
      "quoted": {
        "id": "1985682978182480251",
        "text": "Google Gemini Flash 2.5 Nano banana \n\n{\n    \"style_mode\": \"raw_photoreal_high_fidelity\",\n    \"look\": \"K-Pop idol aesthetic, flawless complexion, high-resolution digital photography, trendy\",\n    \"camera\": {\n      \"vantage\": \"slightly high angle (selfie perspective), direct address\",\n      \"framing\": \"extreme close-up (ECU), tight framing on the face and shoulders\",\n      \"lens_behavior\": \"portrait lens (e.g., 85mm prime), extremely shallow depth of field (DoF), sharp focus on the eyes\",\n      \"sensor_quality\": \"high fidelity, no digital noise\"\n    }\n  },\n  \"scene\": {\n    \"environment\": {\n      \"setting\": \"indoor studio or simple interior\",\n      \"lighting\": \"soft, even beauty lighting (e.g., large softbox or beauty dish), minimizing shadows, creating clear catchlights in the eyes, emphasizing glossy highlights\"\n    },\n    \"subject\": {\n      \"description\": \"young East Asian female, K-Pop idol styling\",\n      \"hair\": \"long, dark brown, wavy, glossy finish\",\n      \"expression\": {\n        \"mood\": \"playful, confident, slightly sultry\",\n        \"action\": \"looking directly into the lens, mouth slightly open, tongue slightly sticking out over the lower lip\"\n      },\n      \"makeup\": {\n        \"style\": \"contemporary K-beauty trends\",\n        \"complexion\": \"flawless, 'glass skin' effect, dewy/glossy finish, realistic micro-texture\",\n        \"cheeks\": \"rosy blush, high application\",\n        \"lips\": \"glossy, pink tint\"\n      },\n      \"attire\": {\n        \"top\": \"grey pinstriped halter top, structured design\",\n        \"details\": \"white contrasting collar lapel with silver snap buttons and circular metal hardware\"\n      },\n      \"accessories\": {\n        \"hair_clip\": \"decorative silver/rhinestone clip on her left side\",\n        \"earrings\": \"dangling silver earrings (heart motif)\"\n      }\n    },\n    \"background\": {\n      \"description\": \"plain, neutral grey or white wall, blurred (bokeh)\"\n    }\n  },\n  \"aesthetic_controls\": {\n    \"render_intent\": \"high-quality digital photograph suitable for promotional material or social media\",\n    \"material_fidelity\": [\n      \"realistic skin micro-texture (pores, gloss, makeup interaction)\",\n      \"individual hair strand detail\",\n      \"fabric texture of the pinstripe material\",\n      \"metallic shine of accessories\"\n    ],\n    \"color_grade\": {\n      \"overall\": \"neutral, slightly warm, vibrant skin tones, high clarity\",\n      \"contrast\": \"balanced\"\n    }\n  },\n  \"negative_prompt\": {\n    \"forbidden_elements\": [\"skin imperfections\", \"blemishes\", \"wrinkles\", \"harsh shadows\", \"textured/matte skin\", \"dry lips\", \"outdoor setting\", \"distorted features\", \"motion blur\", \"digital artifacts\"],\n    \"forbidden_style\": [\"anime\", \"painting\", \"illustration\", \"CGI render\", \"low resolution\", \"gritty realism\", \"vintage photography\", \"uncanny valley\", \"overly airbrushed/plastic skin\"]\n  }\n}",
        "created_at": "Tue Nov 04 12:18:08 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1985682970326556672",
            "url": "https://pbs.twimg.com/media/G46QJBLbYAA9JMw.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "2872720562",
          "name": "Emily",
          "screen_name": "IamEmily2050",
          "description": "Any sufficiently advanced technology is indistinguishable from magic.  Arthur C. Clarke.",
          "followers_count": 31749,
          "friends_count": 664,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 45,
          "favorite_count": 628,
          "reply_count": 60,
          "quote_count": 8
        }
      },
      "stats": {
        "retweet_count": 7,
        "favorite_count": 28,
        "reply_count": 8,
        "quote_count": 0
      }
    },
    {
      "id": "1985897893635543311",
      "text": "这有些片面了：\n1. 简单把 OpenAI 当成了模型公司，而无视了 OpenAI 有个超级用户量的 ChatGPT；\n2. 从模型能力上来说，OpenAI 在 Coding 上的能力已经反超 Claude Code 了；\n3. 从模型领域上来说，Anthropic 主要在单点突破编程和 Agent，但比起 OAI 在多模态、图像、视频上并无多少建树",
      "created_at": "Wed Nov 05 02:32:08 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1985879262021501342",
        "text": "非常简单的语音访谈：为什么Open AI在商业上很难成功\n听一听投资前线和一直在观察市场生态，并挑选赢家的人怎么说\nhttps://t.co/nWtBanYTmn",
        "created_at": "Wed Nov 05 01:18:06 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1597654998971604992",
          "name": "金融汪",
          "screen_name": "yuyy614893671",
          "description": "油管频道：金融汪 ，网址：https://t.co/mE0zmyZHPv\n\n金融市场老兵. Former Investment manager. 观察和理解这个世界每天在发生着什么，是我的兴趣也是工作。X上的内容只是分享，不是投资建议。",
          "followers_count": 61069,
          "friends_count": 436,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 5,
          "favorite_count": 54,
          "reply_count": 9,
          "quote_count": 2
        }
      },
      "stats": {
        "retweet_count": 11,
        "favorite_count": 97,
        "reply_count": 21,
        "quote_count": 0
      }
    },
    {
      "id": "1985905907327172736",
      "text": "统一多模态模型既能生成文本，也能生成图像，但它们真的具备跨模态的推理 (reasoning) 能力吗？\n\n这篇论文推出的是专门评估统一模型中“交互式跨模态推理” (reciprocal cross-modal reasoning) 能力的基准。\n\n简单来说就是“文字思考”评测模型推理时是否可以用文本推理生成图像，或者“视觉思考”：用图像推理生成文本。\n\n从测试结果看模型相对都擅长“文字思考”，“视觉思考”比较弱。",
      "created_at": "Wed Nov 05 03:03:59 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1985838110186619102",
        "text": "Unified multimodal models can generate text and images, but can they truly reason across modalities? 🎨\nIntroducing ROVER, the first benchmark that evaluates reciprocal cross-modal reasoning in unified models, the next frontier of omnimodal intelligence.\n\n🌐 Project: https://t.co/qA5EPaK5s7\n📄 Paper: https://t.co/UjLGs3ZFel\n📂 Benchmark: https://t.co/2oyk8SyYOo",
        "created_at": "Tue Nov 04 22:34:35 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "video",
            "id": "1985838041550778368",
            "url": "https://video.twimg.com/amplify_video/1985838041550778368/vid/avc1/2118x1080/qjFjX91EgZ8tR1qv.mp4?tag=21",
            "bitrate": 10368000
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1338752121563312128",
          "name": "Yongyuan Liang",
          "screen_name": "cheryyun_l",
          "description": "cs phd @umdcs • multi-modal models/rl",
          "followers_count": 1506,
          "friends_count": 344,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 22,
          "favorite_count": 107,
          "reply_count": 5,
          "quote_count": 5
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 13,
        "reply_count": 2,
        "quote_count": 0
      }
    },
    {
      "id": "1985907219301314887",
      "text": "RT @karminski3: 可口可乐今年的广告爆了(-10086)\n\n可口可乐今年的圣诞广告刚放出，100% AI制作，结果我刚刷了一下油管，底下全是骂的. 到底好不好, 我视频后半段给大家拼上了2006年获得艾美奖的可口可乐广告，大家评判一下权当一乐。\n\n2006年那个广…",
      "created_at": "Wed Nov 05 03:09:12 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1985888203703009506",
        "text": "可口可乐今年的广告爆了(-10086)\n\n可口可乐今年的圣诞广告刚放出，100% AI制作，结果我刚刷了一下油管，底下全是骂的. 到底好不好, 我视频后半段给大家拼上了2006年获得艾美奖的可口可乐广告，大家评判一下权当一乐。\n\n2006年那个广告主题是 \"每台可口可乐自动售货机都藏着一个充满奇异物种的世界，这些物种历经磨难以确保顾客获得幸福\" (由 Psyop 公司的 Todd & Kylie 导演，Hungry Man 公司的 Peter Lydon 拍摄实拍部)",
        "created_at": "Wed Nov 05 01:53:38 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "video",
            "id": "1985875067147051008",
            "url": "https://video.twimg.com/amplify_video/1985875067147051008/vid/avc1/1920x1080/o9G31Aj0_xrbIJDP.mp4?tag=21",
            "bitrate": 10368000
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1071224721046261760",
          "name": "karminski-牙医",
          "screen_name": "karminski3",
          "description": "A coder, road bike rider, server fortune teller, electronic waste collector, co-founder of KCORES, ex-director at IllaSoft, KingsoftOffice, Juejin.",
          "followers_count": 28888,
          "friends_count": 1409,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 38,
          "favorite_count": 250,
          "reply_count": 51,
          "quote_count": 11
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 38,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1985927706035269731",
      "text": "对于向深入学习上下文工程（Context Engineering）的同学，这又是一篇必看的文章。\n\n这篇文章讲的是如何解决 MCP 工具太多的问题，但凡你做过 Agent 开发，用了大量 MCP 工具，就会知道 MCP 工具多了后最大的问题就是上下文占用太多，不仅导致成本高，还会影响推理和生成质量。\n\n另外一个问题就是 MCP 工具返回的中间结果也会挤占大量的上下文空间。\n\n看这文章的时候忍不住夸了一下 Manus，他们确实在上下文工程方面探索的很深入了，里面的工程技巧和他们以前分享过的很类似（我一会把之前分享过的 Manus 相关的文章在评论也发一下）。\n\nAnthropic 的方案也很简单直接，就是把“代码”也当作工具的一种，然后从代码中去调用 MCP。\n\n这样做有很多好处：\n\n1. 解决了系统提示词中工具定义太多的问题\n\n不需要在系统提示词中加载所有 MCP 工具，只需要定义一个“代码”工具。\n\n那需要工具了怎么办呢？\n\n这些代码都保存在统一的目录下，去目录检索下就能找到合适的工具了，比如这是文中的一个目录示例：\n\nservers\n├── google-drive\n│   ├── getDocument.ts\n│   ├── ... (other tools)\n│   └── index.ts\n├── salesforce\n│   ├── updateRecord.ts\n│   ├── ... (other tools)\n│   └── index.ts\n└── ... (other servers)\n\n找不到现成的工具怎么办？\n\n直接现写一个！写完了还可以保存起来下次继续用。\n\n2. 解决了 MCP 工具返回结果太长的问题\n\n比如说我们要用 MPC 工具获取 1 万行数据后筛选转换出合格的数据，就可以先从代码中调用 MCP 工具获取这 1 万行数据，然后从代码中去筛选过滤，最后只返回 5 条数据，这样上下文中就只需要保留那 5 条过滤的数据，而不是像以前一样有 1 万条数据在里面。\n\n3. 解决了数据隐私问题\n\n如果你直接使用 MCP 工具，工具返回的数据都要加载到上下文每次上传给 LLM，用代码就可以对敏感数据先二次处理再加到上下文\n\n4. 中间结果持久化和技能沉淀\n\n代码可以把一些中间结果写入文件保存到硬盘，一方面可以不占用上下文空间，另一方面也可以随时从硬盘避免反复调用 MCP。\n\n还有就是虽然很多代码是临时生成的，但是这些临时生成的代码可以保存下来，沉淀为“技能”（Skill），加上 SKILL .MD 文件就和 Claude Code 的技能一样可以被反复使用了。",
      "created_at": "Wed Nov 05 04:30:36 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1985927696103231488",
          "url": "https://pbs.twimg.com/media/G49ut7vX0AAVZ8C.jpg"
        }
      ],
      "retweet": null,
      "quoted": {
        "id": "1985846791842250860",
        "text": "New on the Anthropic Engineering blog: tips on how to build more efficient agents that handle more tools while using fewer tokens.\n\nCode execution with the Model Context Protocol (MCP): https://t.co/PeStmufIkp",
        "created_at": "Tue Nov 04 23:09:05 +0000 2025",
        "lang": "en",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1353836358901501952",
          "name": "Anthropic",
          "screen_name": "AnthropicAI",
          "description": "We're an AI safety and research company that builds reliable, interpretable, and steerable AI systems. Talk to our AI assistant @claudeai on https://t.co/FhDI3KQh0n.",
          "followers_count": 675395,
          "friends_count": 35,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 360,
          "favorite_count": 2951,
          "reply_count": 84,
          "quote_count": 121
        }
      },
      "stats": {
        "retweet_count": 82,
        "favorite_count": 396,
        "reply_count": 13,
        "quote_count": 8
      }
    },
    {
      "id": "1985929129993388335",
      "text": "RT @MANISH1027512: 有一种发型，真的会记一辈子… 对我来说，就是它！😬\n\n估计是高中时喜欢的一个女生就是这个发型，导致我的审美被锁死了，这么多年过去了依然杀我（doge）。\n\n我也尝试给兄弟们用🍌去复刻这种当年的心动瞬间，但效果都不尽人意\n\n🍌做糖水人像、时尚…",
      "created_at": "Wed Nov 05 04:36:16 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1985910969038455291",
        "text": "有一种发型，真的会记一辈子… 对我来说，就是它！😬\n\n估计是高中时喜欢的一个女生就是这个发型，导致我的审美被锁死了，这么多年过去了依然杀我（doge）。\n\n我也尝试给兄弟们用🍌去复刻这种当年的心动瞬间，但效果都不尽人意\n\n🍌做糖水人像、时尚人像等它都胜任\n\n但唯独它就是get不到：情绪氛围感\n\n我尝试过在prompt中加入FUJI相机参数、CC滤镜、抓拍感等参数，效果甚微\n\n然而这一点对于MJ来说，却是其最擅长的。\n\nbanana测试prompt：\n{\n  \"scene\": {\n    \"description\": \"Candid waist-up portrait of a very young, pretty woman beside claw machines in an indoor arcade, caught mid-moment.\",\n    \"environment\": \"Narrow arcade aisle with bright claw-machine lightboxes on camera-left and distant neon signs forming creamy bokeh.\",\n    \"mood\": \"Dreamy, nostalgic, effortless—natural snapshot rather than posed.\"\n  },\n  \"output\": {\n    \"aspect_ratio\": \"1:1 square EXACT\",\n    \"target_resolution\": \"3072x3072–4096x4096\",\n    \"safe_margins\": \"8% inner padding; no text near edges\"\n  },\n  \"aesthetic\": {\n    \"style\": \"Naturalistic indoor portrait with subtle vintage film character.\",\n    \"look\": \"Fujifilm Classic Chrome feel—muted saturation, cool cyan shadows, warm peachy skin, soft contrast, gentle highlight roll-off; light halation on neon points; fine film-like luminance grain.\"\n  },\n  \"lighting\": {\n    \"description\": \"Key from claw-machine panel at camera-left (cool, soft); warm practicals in depth; no hard shadows.\",\n    \"exposure\": \"Protect highlights in glass; background ~1 stop darker for separation.\"\n  },\n  \"subject\": {\n    \"demographics\": {\n      \"age\": \"late teens to early 20s\",\n      \"gender\": \"female\",\n      \"ethnicity\": \"East Asian\",\n      \"beauty\": \"Very youthful and pretty; clear skin; elegant idol aura.\"\n    },\n    \"appearance\": {\n      \"hair\": \"Straight dark bob ending just above shoulders; airy see-through bangs; a few wispy strands near cheeks.\",\n      \"skin\": \"Smooth natural texture with soft blush; minimal makeup (hydrated base, soft peach-pink lip, clean straight brows).\",\n      \"likeness_guidance\": \"K-POP idol-inspired features (e.g., Jang Wonyoung vibe)—large bright almond eyes, long lashes, refined straight brows, high nasal bridge with soft tip, V/oval face, soft full lips—DO NOT exactly replicate any specific person.\"\n    },\n    \"wardrobe\": {\n      \"top\": \"Deep-V knit camisole with thin spaghetti straps in slate/denim blue; fine ribbed texture; subtle sheen.\"\n    },\n    \"pose\": {\n      \"type\": \"Waist-up portrait, FRONTAL.\",\n      \"framing\": \"Centered; shoulders与上胸可见；左侧保留机器玻璃亮面；头部靠上三分之一。\",\n      \"body_orientation\": \"Torso facing camera 0° (正对镜头)，肩线水平自然放松。\",\n      \"head_orientation\": \"Yaw +8–12° toward camera-right; Pitch −4–6° (slightly lowered); Roll −0.5° (handheld tilt).\",\n      \"gaze\": \"Eyes not smiling; look slightly down-right past the lens (not direct eye contact).\",\n      \"expression\": \"Neutral/serene; NO smile; lips closed or very slightly parted without upturn.\",\n      \"hands\": \"Out of frame.\"\n    }\n  },\n  \"props_in_scene\": {\n    \"background\": \"Row of arcade machines receding with neon/LED signs; round ceiling downlights; everything beyond subject rendered as soft bokeh.\",\n    \"materials\": \"Glass reflections on machine door; glossy plastic frames; polished floor.\"\n  },\n  \"camera_lock\": {\n    \"camera_height\": \"Clavicle level (slightly above bust line).\",\n    \"camera_distance\": \"1.0–1.2 m from subject.\",\n    \"camera_angle\": \"Yaw 0°, pitch −3°, roll −0.5° (subtle handheld tilt).\",\n    \"lens\": \"35 mm equivalent preferred (acceptable 35–50 mm).\",\n    \"depth_of_field\": \"f/1.8–f/2.0 look for creamy bokeh and gentle falloff.\"\n  },\n  \"camera_technical\": {\n    \"requirements\": \"Frontal chest/shoulder alignment; true facial proportions; knit texture readable; eyelashes和发丝清晰；反射真实；无品牌文字或伪字形。\",\n    \"capture\": {\n      \"camera_model\": \"FUJIFILM X-T5\",\n      \"film_simulation\": \"Classic Chrome\",\n      \"white_balance\": \"4300–4600 K\",\n      \"iso\": \"640 (±1 stop) to preserve available-light feel\",\n      \"shutter_speed\": \"1/125–1/160 s (retain a hint of ambient motion while keeping subject sharp)\",\n      \"aperture\": \"f/1.8–f/2.0\",\n      \"focus\": \"Single-point AF on near eye; slight falloff to ears/hair.\",\n      \"format\": \"RAW or 16-bit render\",\n      \"aspect_ratio\": \"1:1 EXACT\"\n    },\n    \"composition\": \"Left frame shows machine glass edge; right side leaves negative space with bokeh; avoid clipping shoulders.\"\n  },\n\n  \"mood_lock\": {\n    \"emotion\": \"nostalgic, tender, calm; candid not posed\",\n    \"micro_expression\": \"neutral lips (0% smile); relaxed eyelids; subtle jaw relaxation\",\n    \"timing\": \"captured mid-breath; between blinks; micro head dip to camera-right\",\n    \"story_cue\": \"She pauses at the machine, reading the prize card; unaware of camera.\"\n  },\n\n  \"light_recipe\": {\n    \"key\": \"Soft area light from camera-left (claw-machine panel), 5400–5600 K.\",\n    \"ambient\": \"Warm practicals 2800–3200 K in distance, ~1 stop under key.\",\n    \"wrap\": \"Key wraps ~120° around face; no hard shadow edges.\",\n    \"specular_map\": \"Subtle highlights on upper cheekbones and collarbones only.\",\n    \"flare_halation\": \"Very mild halation on neon points; no global bloom.\",\n    \"film_grade\": {\n      \"profile\": \"Fujifilm Classic Chrome\",\n      \"contrast\": \"soft S-curve\",\n      \"saturation\": \"-12%\",\n      \"shadow_tint\": \"slight cyan/green bias\",\n      \"skin_tone\": \"peach-warm +3\",\n      \"black_lift\": \"+2%\"\n    }\n  },\n\n  \"lens_handheld\": {\n    \"camera\": \"Fujifilm X-T5\",\n    \"focal_length_equiv\": \"35 mm\",\n    \"aperture\": \"f/1.8–f/2.0 (creamy bokeh, gentle falloff)\",\n    \"shutter\": \"1/125–1/160 s\",\n    \"iso\": \"640 (±1 stop)\",\n    \"focus\": \"Single-point AF on near eye; ears falloff.\",\n    \"handheld\": \"Micro roll −0.5° to −1.0°, slight natural sway; no tripod-perfect horizon.\",\n    \"bokeh\": \"Round 7–9 blade look; smooth edge highlights; prohibit double-line or onion-ring bokeh.\",\n    \"grain\": \"Fine luminance grain only, uniform.\",\n    \"vignette\": \"Very light, center-weighted.\"\n  },\n\n  \"film_grade\": {\n    \"curve\": \"Soft S-curve; very slightly lifted blacks (+2%); gentle highlight roll-off.\",\n    \"palette\": \"Classic Chrome—saturation −10~15%; shadows with slight cyan/green bias; skin tones peach-warm +3.\",\n    \"grain\": \"Fine, uniform luminance grain (not color noise).\",\n    \"halation\": \"Subtle around neon highlights only; no global bloom.\"\n  },\n\n  \"retouching\": {\n    \"notes\": \"Preserve skin texture, knit detail and natural flyaway hairs; remove only transient blemishes; absolutely no beauty-filter smoothing.\",\n    \"bloom\": \"Very light and confined to neon points; facial features remain crisp.\"\n  },\n  \"avoid\": [\n    \"Smile or upward mouth corners\",\n    \"Head turned to the LEFT (must be to the RIGHT) or head raised (must be slightly lowered)\",\n    \"Staged/posed look or direct eye contact\",\n    \"Tripod-perfect alignment (remove handheld feel)\",\n    \"Over-saturation or HDR contrast—keep Classic Chrome mood\",\n    \"Harsh flash or clipped highlights\",\n    \"Plastic skin smoothing\",\n    \"Bokeh double-lines or onion-ring artifacts\",\n    \"Wrong aspect ratio (must be 1:1)\",\n    \"Exact duplication of any real person’s face\"\n  ]\n}",
        "created_at": "Wed Nov 05 03:24:06 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1985903140911079424",
            "url": "https://pbs.twimg.com/media/G49YYohWYAAtKTo.jpg"
          }
        ],
        "retweet": null,
        "quoted": {
          "id": "1984507571894411768",
          "text": "#前女友来了 \n\n咒语：\n\nA stealthy candid capture of a Asian beauty at a night market, straight hair with bangs, rosy cheeks, wearing a deep-neck tank top and jeans, browsing stalls with a curious gaze, low-light with neon signs blurring in the background, grainy texture like from a phone in dim conditions.",
          "created_at": "Sat Nov 01 06:27:30 +0000 2025",
          "lang": "en",
          "media": [
            {
              "type": "photo",
              "id": "1984507562725654528",
              "url": "https://pbs.twimg.com/media/G4pjHSpWwAA7DHh.jpg"
            }
          ],
          "retweet": null,
          "quoted": null,
          "user": {
            "id": "1775864328887189504",
            "name": "古一",
            "screen_name": "MANISH1027512",
            "description": "AI摄影师📷 | Midjourney咒术师 | 中推vibe shooting第一人 | 资深测试开发  | AI Creator | 开源自动化框架作者  | 长期主义者 | 每天一杯冰震浓缩续命☕️ 以上只是标签，人生没有边界，探索从不设限。",
            "followers_count": 6773,
            "friends_count": 357,
            "verified": false,
            "is_blue_verified": true
          },
          "stats": {
            "retweet_count": 70,
            "favorite_count": 622,
            "reply_count": 29,
            "quote_count": 7
          }
        },
        "user": {
          "id": "1775864328887189504",
          "name": "古一",
          "screen_name": "MANISH1027512",
          "description": "AI摄影师📷 | Midjourney咒术师 | 中推vibe shooting第一人 | 资深测试开发  | AI Creator | 开源自动化框架作者  | 长期主义者 | 每天一杯冰震浓缩续命☕️ 以上只是标签，人生没有边界，探索从不设限。",
          "followers_count": 6773,
          "friends_count": 357,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 21,
          "favorite_count": 160,
          "reply_count": 16,
          "quote_count": 3
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 21,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1985929614427111935",
      "text": "原文翻译：https://t.co/YXBXYDv0e4",
      "created_at": "Wed Nov 05 04:38:11 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 4,
        "favorite_count": 24,
        "reply_count": 1,
        "quote_count": 0
      }
    },
    {
      "id": "1985937447302131810",
      "text": "现在写了错别字我都懒得改了，这样读者一看：有错别字，看来是手工打的不是 AI 生成的，就好像买水果看到有点虫子还放心一点，一看就没打过农药，有机的😂",
      "created_at": "Wed Nov 05 05:09:19 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1985927706035269731",
        "text": "对于向深入学习上下文工程（Context Engineering）的同学，这又是一篇必看的文章。\n\n这篇文章讲的是如何解决 MCP 工具太多的问题，但凡你做过 Agent 开发，用了大量 MCP 工具，就会知道 MCP 工具多了后最大的问题就是上下文占用太多，不仅导致成本高，还会影响推理和生成质量。\n\n另外一个问题就是 MCP 工具返回的中间结果也会挤占大量的上下文空间。\n\n看这文章的时候忍不住夸了一下 Manus，他们确实在上下文工程方面探索的很深入了，里面的工程技巧和他们以前分享过的很类似（我一会把之前分享过的 Manus 相关的文章在评论也发一下）。\n\nAnthropic 的方案也很简单直接，就是把“代码”也当作工具的一种，然后从代码中去调用 MCP。\n\n这样做有很多好处：\n\n1. 解决了系统提示词中工具定义太多的问题\n\n不需要在系统提示词中加载所有 MCP 工具，只需要定义一个“代码”工具。\n\n那需要工具了怎么办呢？\n\n这些代码都保存在统一的目录下，去目录检索下就能找到合适的工具了，比如这是文中的一个目录示例：\n\nservers\n├── google-drive\n│   ├── getDocument.ts\n│   ├── ... (other tools)\n│   └── index.ts\n├── salesforce\n│   ├── updateRecord.ts\n│   ├── ... (other tools)\n│   └── index.ts\n└── ... (other servers)\n\n找不到现成的工具怎么办？\n\n直接现写一个！写完了还可以保存起来下次继续用。\n\n2. 解决了 MCP 工具返回结果太长的问题\n\n比如说我们要用 MPC 工具获取 1 万行数据后筛选转换出合格的数据，就可以先从代码中调用 MCP 工具获取这 1 万行数据，然后从代码中去筛选过滤，最后只返回 5 条数据，这样上下文中就只需要保留那 5 条过滤的数据，而不是像以前一样有 1 万条数据在里面。\n\n3. 解决了数据隐私问题\n\n如果你直接使用 MCP 工具，工具返回的数据都要加载到上下文每次上传给 LLM，用代码就可以对敏感数据先二次处理再加到上下文\n\n4. 中间结果持久化和技能沉淀\n\n代码可以把一些中间结果写入文件保存到硬盘，一方面可以不占用上下文空间，另一方面也可以随时从硬盘避免反复调用 MCP。\n\n还有就是虽然很多代码是临时生成的，但是这些临时生成的代码可以保存下来，沉淀为“技能”（Skill），加上 SKILL .MD 文件就和 Claude Code 的技能一样可以被反复使用了。",
        "created_at": "Wed Nov 05 04:30:36 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1985927696103231488",
            "url": "https://pbs.twimg.com/media/G49ut7vX0AAVZ8C.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "3178231",
          "name": "宝玉",
          "screen_name": "dotey",
          "description": "Prompt Engineer, dedicated to learning and disseminating knowledge about AI, software engineering, and engineering management.",
          "followers_count": 142946,
          "friends_count": 1442,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 82,
          "favorite_count": 396,
          "reply_count": 13,
          "quote_count": 8
        }
      },
      "stats": {
        "retweet_count": 3,
        "favorite_count": 55,
        "reply_count": 26,
        "quote_count": 8
      }
    },
    {
      "id": "1985960729590088071",
      "text": "最近，你是不是也总刷到《XX 指南》？\n\n连马东锡老师都忍不住吐槽了。我也有同感，刷到一堆《XX 指南》的推文，第一反应就是骂马斯克又改 X 的推送算法了。这就像当年，来总将微博时间线从“按关注人时间排序”改成算法推荐，也没少挨骂。\n\n似乎一切都是算法的问题：算法在暗处操纵喜好、制造对立，把我们关进一个个信息茧房。\n\n但如果，这一切只是我们的错觉呢？如果就算没有算法，这个世界也照样撕裂，照样有茧房呢？一个最“纯净”的社交平台，也会“自动”演化出我们今天讨厌的一切！\n\n先别急着反驳，我们来看一个刚出炉的、非常有意思的实验。\n\n来自荷兰阿姆斯特丹大学的一篇论文《我们能修复社交媒体吗？用“生成式社交模拟”来测试各种“劝人向善”的干预措施》，就借助 AI 做了一个模拟试验，他们打造了一个极简版的没有算法推荐的社交平台，有点像早年的推特和微博，只有发帖、转帖和关注功能。\n\n不过他们没有用真人，而是借助 LLM（大语言模型）模拟了 500 个有不同人格的虚拟用户，这些 AI 虚拟用户有不同的政治立场、兴趣爱好和背景。\n（顺便说一下，感觉他们这个灵感来自当年斯坦福用 GPT-4 构建的一个名为 Smallville 的虚拟小镇，25 个 AI 虚拟人在小镇上生活，他们有工作，会八卦，能组织社交，结交新朋友，甚至举办情人节派对，每个小镇居民都有独特的个性和背景故事。）\n\n猜猜结果如何？\n\n大约 5 万次互动就很快复现了三个典型的社交媒体问题：\n\n1. 形成“回音室”：根本不需要算法“投喂”，AI 虚拟人迅速“站队” 。立场接近的互相关注，很快就分成了好几个小圈子，而且圈子之间几乎不相往来 。\n\n2. 大v 们垄断流量：10%的头部用户，拥有 75-80% 的粉丝。\n\n3. 极端声音被放大：立场更鲜明、更极端的观点，获得了更多的转帖和关注。\n\n然后，他们测试了六种从文献中挑选出来的平台级干预措施，结果发现改善极其有限，没有一种干预措施能完全打破导致这些病症的底层机制，有些改变甚至让问题变得更糟：\n> 我们评估了六种干预措施。虽然有几个显示出温和的积极影响，但没有一个能彻底解决核心病症。并且，在一个维度上的改善，往往是以在另一个维度上的恶化为代价的。（例如：“按时间排序”降低了不平等，却加剧了“棱镜效应”；“搭桥算法”缓解了“棱镜效应”，却加剧了不平等。）\n\n社交媒体被诟病的三大乱象——信息茧房、影响力集中、极端声音放大，很可能根植于人类的网络社交行为本身，跟算法推荐的关系也许并没有我们想的那么大。是我们自己，在主动寻找“同温层”，是我们自己，在把观点极端的人捧成“大v”。\n\n这也不难解释为什么有“关注列表定律”：\n\n> @河森堡：几年前，微博流行起一个说法，叫 “关注列表定律”，大意是如果一个人如果理直气壮地冒傻气说蠢话，你点开此人的关注列表，一定会有那么几个账号。\n\n> @幻想狂劉先生: 已经有社会学者在研究这个了，在前信息化时代社会个体被动接受信息，信息传播以单向为主。进入双向时代之后，信息源在筛选受众，受众也在主动筛选信息来源，这时候受众选择信源时的倾向性本身可以反应其认知水平，认知程度和相关立场。\n\n不是算法在撕裂社交媒体，是世界本就如此。我们之所以觉得撕裂，可能只是因为，算法让我们被迫看到了原本看不到的世界。\n\n在没有社交媒体的年代，我们身边都是和自己差不多的人，看的报纸、电视，都是被编辑筛选过的和谐现实。现在，算法把那些原本存在、但被遮蔽的声音，全都翻了出来 。\n\nTombkeeper 有一个经典的“提费降速”理论，就是类似的观点，大意是2017 年开始“提速降费”，上网人群基数大增，三教九流都来了，导致极端言论增加。\n\n你觉得撕裂，不是算法制造了对立，而是算法让你看见了真实的、多元的、有时甚至有点刺眼的折叠世界。\n\n我相信社交平台其实反而有动机去打破信息茧房。道理很简单：如果算法只给你看你喜欢的东西，你很快就会腻。为了让你能上瘾，能更久地留在平台上，算法必须不断给你惊喜，推荐你可能感兴趣的、但你没见过的新内容。\n\n所以我相信老马和来总他们会把算法优化好的，虽然当前还存在各种问题，总还是会朝着好的方向发展。\n\n这就是为什么虽然我也经常骂老马和来总的算法，但我另一方面也挺依赖平台的推送。 经常有网友问我信息来源是哪里，其实我不止一次说过：我的信息来源主要是 X 的推送和 Hacker News。我几乎只用 X 的“For You”，而不是按时间和关注排序的“Following”，因为算法确实经常帮我发现一些我没关注的、但是有价值的内容。\n\n这篇论文《我们能修复社交媒体吗？》的结尾说的很透彻：\n\n> 这些问题能从一个如此简单的平台中“涌现”出来，这表明问题可能根本不在于算法的实现细节，而在于更深层次的结构性机制：它们源于“内容互动”和“网络形成”之间纠缠不清的动态。\n>\n> “转发”不仅仅是在放大内容；它是在“构建”这个社交网络。因为用户是通过他们已关注账户的“转发”，才接触到其他人的。\n>\n> 这意味着一个核心机制：我们进行转发时那种“情绪化的、应激式的、党同伐异的”本质，直接决定了谁能被看见、谁能涨粉。\n>\n> 这就创造了一个自我强化的恶性循环：情绪化的互动 推动了 社交网络的增长，而 增长的网络反过来又 塑造了你未来的信息曝光。这个循环不断地强化着意识形态同质性、注意力不平等和极端声音的过度代表。\n>\n> 我们的发现，挑战了“社交媒体的功能障碍主要是由算法策展（algorithmic curation）造成的”这一普遍观点。相反，这些问题可能植根于社交媒体的底层架构：一个通过“情绪化、应激式分享”来增长的社交网络。\n>\n> 如果真是这样，那么想改善网络话语环境，光靠技术上的“修修补补”是不够的——这要求我们必须重新思考定义这些环境的最根本的互动和可见性动态。\n\n所以问题又绕回来了。既然病根儿不在算法，而在于“情绪化的、应激式的分享”，那光靠平台技术上的“修修补补”是不够的。\n\n这篇论文虽然没给解决方案，但它至少提醒了我们，作为用户，我们自己可以做出改变。\n\n就像开头说到的《XX 指南》，为什么我总刷到？其实仔细想想，并不是满屏都是它，只是其他推文看了就忘了，唯独这种内容，最容易引起情绪、转发和评论，导致它被一次又一次地强化。\n\n这时候，马东锡老师的做法就很高明：他提了一嘴，但用“Low B 指南”代替，也不转发引用。\n\n这，就是一种拒绝参与“情绪化恶性循环”的努力。\n\n如果我们无法改变平台“通过应激式分享来增长”的底层架构，那至少，我们可以改变自己分享和转发的“应激”模式。",
      "created_at": "Wed Nov 05 06:41:49 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "video",
          "id": "1985959528014237696",
          "url": "https://video.twimg.com/amplify_video/1985959528014237696/vid/avc1/1280x720/uDZRnrJE_qvQx9S6.mp4?tag=21",
          "bitrate": 2176000
        }
      ],
      "retweet": null,
      "quoted": {
        "id": "1984979067871879243",
        "text": "简中推圈，可以轻易的被这个 low\nb 指南带偏，说明中推目前毫无高质量话题领导力，非常 low，跟早期的微博完全没法比。",
        "created_at": "Sun Nov 02 13:41:03 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1477948736156454913",
          "name": "马东锡 NLP",
          "screen_name": "dongxi_nlp",
          "description": "Prev. PhD @Stockholm_Uni | Alumni @KTHuniversity @uppsalauni Sharing insights on AI, autonomous agents, and large language & reasoning models",
          "followers_count": 31905,
          "friends_count": 825,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 4,
          "favorite_count": 193,
          "reply_count": 68,
          "quote_count": 5
        }
      },
      "stats": {
        "retweet_count": 11,
        "favorite_count": 83,
        "reply_count": 17,
        "quote_count": 5
      }
    },
    {
      "id": "1985960733218386344",
      "text": "论文地址：https://t.co/XrPXNOUSYr https://t.co/qQRlB8krmr",
      "created_at": "Wed Nov 05 06:41:50 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1985960718403846144",
          "url": "https://pbs.twimg.com/media/G4-MwFZXQAAndcp.jpg"
        }
      ],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 0,
        "favorite_count": 2,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1985974178873323607",
      "text": "RT @song66546656: 你越是会写作，你越能把AI写作用的好。\n\n很多人觉得AI写作现在已经这么强了，自己没有必要去练习写作了。\n\n我不认可这种观点。\n\n写作的核心是什么？\n\n是整理加表达，是一种结构化甚至系统化的能力。\n\n写作能够提升你的逻辑能力和表达能力。而这两…",
      "created_at": "Wed Nov 05 07:35:16 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1985960397338526185",
        "text": "你越是会写作，你越能把AI写作用的好。\n\n很多人觉得AI写作现在已经这么强了，自己没有必要去练习写作了。\n\n我不认可这种观点。\n\n写作的核心是什么？\n\n是整理加表达，是一种结构化甚至系统化的能力。\n\n写作能够提升你的逻辑能力和表达能力。而这两种能力才是写作能力的元能力。\n\nAI只能保证写作的下限，而且完全由AI写的文章，充满了逻辑正确却毫无新意的内容。\n\n我们往往就是因为听过太多正确的道理，所以我们才难以行动。而AI就是那个最会讲正确的废话的产品。\n\n如果你没有独特的洞察，没有严密的逻辑，甚至连活人感都没有，这样的写作放在在AI时代，我想是没有竞争力的。",
        "created_at": "Wed Nov 05 06:40:30 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1625510502246801408",
          "name": "送姜",
          "screen_name": "song66546656",
          "description": "男 | 电信专业| 06 | 努力做一名终身学习者|正在琢磨怎么赚一点小钱",
          "followers_count": 580,
          "friends_count": 135,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 16,
          "favorite_count": 109,
          "reply_count": 12,
          "quote_count": 4
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 16,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1985975728341422560",
      "text": "//@高飞:新名词：“有机内容”，指由人类编写，但文字偶有疏漏的文章。对于人机合作撰写的内容，则可以用“有机率”来表达，如：这篇有机率至少30%。 https://t.co/Ub4xGeiYu2",
      "created_at": "Wed Nov 05 07:41:25 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1985975723442483200",
          "url": "https://pbs.twimg.com/media/G4-aZfhWsAAR7oV.jpg"
        }
      ],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 1,
        "favorite_count": 9,
        "reply_count": 2,
        "quote_count": 0
      }
    },
    {
      "id": "1986084157760413780",
      "text": "3年前我刚开始在推特上写时就经历类似的事，处理方法也是持续输出。\n写得多了越来越多的人知道你了，就知道源头在哪里了。\n现在就连人家出个雷军推荐产品的硬件演示视频，都一堆人 at 我说提示词是不是我写的",
      "created_at": "Wed Nov 05 14:52:17 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1986026354773778736",
        "text": "本人已被治愈\n\n充满写作灵感\n\n会继续输出的\n\n我相信肯定能有我的容身之处的哈哈哈\n\n（图片是我和剪辑师的聊天） https://t.co/p4lyozzNPg",
        "created_at": "Wed Nov 05 11:02:36 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1986026334183682048",
            "url": "https://pbs.twimg.com/media/G4_IbbOW8AANS86.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1965832077758095360",
          "name": "自由李亿freeliyi",
          "screen_name": "freeliyi",
          "description": "长居欧洲写代码｜靠写作为生多年\n深度阅读分享｜创业、金融、自我成长\n目标是通过输出积累专长\n希望自己积极快乐活在当下\n快乐事业=退休（x，yt）\n和自己的全能自恋相处中｜复利追求者",
          "followers_count": 12704,
          "friends_count": 253,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 1,
          "favorite_count": 19,
          "reply_count": 6,
          "quote_count": 1
        }
      },
      "stats": {
        "retweet_count": 1,
        "favorite_count": 51,
        "reply_count": 9,
        "quote_count": 2
      }
    },
    {
      "id": "1986116682528465190",
      "text": "我们家老大今年暑假找了个实习，一个顶尖的生物实验室。他在这段实习经历最大的收获就是认识了几个真正优秀的人，这对他正面激励很大，他能切实的感受到这些人为什么优秀，能从他们身上学到什么。实习结束他说要改变自己的交际圈子了。\n进大公司是向优秀人学习的最佳路径之一，就是有时候也要看运气。",
      "created_at": "Wed Nov 05 17:01:32 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1986085213148160032",
        "text": "洗澡的时候想到的：\n\n《为什么要去大公司：见识决定上限》\n\n（Rainman 口述版）\n\n我原本打算在工作四周年那天写一篇长文，回顾自己这四年在软件工程这条路上学到的东西。\n但大纲还没列、资料还没翻，事情又多，所以一直拖着。\n\n直到今天洗澡的时候，我突然想通了一件很核心的事——\n为什么我当初一定要去大公司？为什么要去尽可能高、尽可能大的地方？\n\n不是为了光环，也不是为了简历。\n真正的底层原因只有一个：\n见识会决定一个人的上限。\n\n我的起点：一张从重庆飞到上海的机票\n\n我第一家实习是戴尔 EMC，在上海。\n我当时从重庆买了张机票就飞过去，傻乎乎的，什么都不懂。\n\n但就是在那里，我人生第一次看到“真正厉害的人”是什么样的。\n\n我见过最强的老板：风度、气质、领导力的“三位一体”\n\n那位老板负责整个 VxRail 项目，级别很高，但并不端着。\n\n他不会亲自招人，但每个实习生第一天都要到他那儿报到。\n他会亲自请你在楼下吃个饭，聊聊项目、聊聊你的兴趣。\n\n我到现在都记得他给我的第一印象：\n穿着得体，但不浮夸\n工程师的风范，但不刻意\n谦逊、自信、自然\n气质干净、从容\n英文毫不费力\n说话不疾不徐\n处理事情轻松、稳定\n像是随时能 hold 住全局的人\n\n你一看就知道：\n这就是常春藤读出来的人，这就是顶级公司里真正的领导者。\n\n他身上那种“见过世界”的质感，就是你在任何培训班、任何草台班子里绝对见不到的。\n\n那一刻我突然明白了：\n\n原来一个人最顶级的状态，是这样子的。\n\n锚定上限：从那之后，我知道自己想成为什么样的人\n\n后来换了很多老板，也换了很多公司。\n有人聪明、有人成熟、有人勤奋，但再也没有见过像他这样“全维度满分”的人。\n\n他给我定了一个锚点：\n身材外形得体\n风度气质自然\n领导力稳定\n英文过硬\n对世界的理解透彻\n强者的底气 + 谦逊的态度\n\n那是我人生第一次看到“上限”。\n\n从那以后我很清楚一件事：\n我要成为这样的人。\n不只是技术好，而是整体的“人”的状态要强。\n\n这就是我为什么一直在整理自己、提升自己。\n不是虚荣，是——\n你见过什么，你就会渴望成为那样的人。\n\n大公司真正意义：不是平台，而是“看到顶级人的机会”\n\n很多人以为去大公司是为了：\n薪水更高\n履历更好看\n资源更多\n\n这些都对，但都不是本质。\n\n真正的意义是：\n\n你能看到什么样的人，你就会变成什么样的人。\n你见过的“顶”，会成为你余生的参照系。\n\n有些团队永远给不出这种参照。\n你身边是什么人，你就会把天花板看成屋顶。\n\n但你只要看过一次真正的顶级强者——\n你的“自我标准”就再也回不去了。",
        "created_at": "Wed Nov 05 14:56:29 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "826639262988718080",
          "name": "Rainman",
          "screen_name": "0xdeusyu",
          "description": "读万卷书行万里路｜软件工程师｜AI = 我的 OIALO｜连接一切｜不争论，只拉黑｜@Baidu_Inc\nRead ten thousand books, travel ten thousand miles. | AI·OIALO | Nexus Thinker | Cloud Computing | RD",
          "followers_count": 5851,
          "friends_count": 547,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 9,
          "favorite_count": 64,
          "reply_count": 5,
          "quote_count": 2
        }
      },
      "stats": {
        "retweet_count": 11,
        "favorite_count": 111,
        "reply_count": 10,
        "quote_count": 0
      }
    },
    {
      "id": "1986148836239188089",
      "text": "通俗易懂的解释 LLM，RAG 和 AI Agent 的差别，以下内容为原推的翻译：\n\n我终于明白了LLM、RAG和AI智能体的区别\n\n过去两年里，我一直在搭建真正落地的AI系统。现在，我终于清楚了：\n\nLLM（大语言模型）、RAG（检索增强生成）和AI智能体（AI Agents），根本不是互相竞争的技术，而是构成同一个AI智能系统的三个层次。很多人用错了方法，把它们当成互斥的工具。\n\n---\n\n> 大语言模型是“大脑” <\n\nLLM 就像AI的脑子，它会思考，会写作，也懂语言。但问题来了：它是冻结在某个时间点的。\n\n比如 GPT-4，它的知识截止到训练结束的那一天。你问它昨天的新闻发生了什么？那可就瞎编了。\n\n大语言模型很聪明，但却不了解“现在”正在发生的事。\n\n---\n\n> RAG是AI的“记忆” <\n\n这时候就需要 RAG（Retrieval-Augmented Generation，检索增强生成）了，它相当于给大脑接入了“外置内存”。\n\n当你提问时，RAG会先去外部数据库或文档里搜索，把相关资料抓出来，再丢给大语言模型作为上下文。\n\n这样一来，原本静态的模型一下子就“活”了：\n\n- 有最新的数据\n- 有真实的事实\n- 完全不需要重新训练模型\n\n最关键的是，准确率立刻就提高了。大语言模型不用再靠记忆乱猜，而是真正地在实时检索到的信息上进行推理。你甚至还能追溯每个答案到底用了哪些文档。\n\n---\n\n## > AI智能体是AI的“行动力” <\n\n尽管LLM能思考，RAG能提供新鲜的数据，但它们都缺乏真正的行动能力。\n\n这时，AI智能体（AI Agents）出场了。它在大语言模型的外面套上了一个控制循环：\n\n- 设定目标\n- 规划步骤\n- 执行行动\n- 回顾反思\n\nAI智能体并不仅仅是回答问题那么简单，它能自主地去研究一个话题、收集数据、撰写报告，甚至帮你发邮件，全程自动化。\n\n---\n\n> 真正的生产级AI，要同时用好这三者 <\n\n很多酷炫的AI展示，其实只是单纯用了LLM再配上花里胡哨的提示词。但真正能落地的AI系统，往往同时结合了这三个要素：\n\n- LLM 提供推理和思考能力\n- RAG 确保知识准确而新鲜\n- AI智能体 则提供行动和决策能力\n\n---\n\n> 如何选用这三者？ <\n\n- 只用LLM\n  如果你需要纯语言的任务，比如写作、摘要、解释。\n\n- LLM + RAG\n  如果你需要回答涉及特定文档、技术手册、专业领域知识的问题，并确保答案准确无误。\n\n- LLM + RAG + AI 智能体\n  如果你需要真正的自主行动，比如系统自己决策、执行任务、管理复杂流程。\n\n---\n\n> AI的未来，不是选哪一种，而是如何把这三层架构起来 <\n\n记住这个公式：\n\n- LLM负责思考\n- RAG负责知识\n- AI智能体负责行动\n\n真正的AI智能系统，就是这三者协同起来，形成一个完整的智能架构。",
      "created_at": "Wed Nov 05 19:09:18 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1985663551697273216",
        "text": "I finally understand the difference between LLMs, RAG, and AI Agents.\n\nAfter building production AI systems for 2 years...\n\nHere's what actually matters:\n\nThey're not competing technologies. They're three layers of the same intelligence stack, and most people are using them completely wrong.\n\n> The LLM is the brain <\n\nIt can reason, write, and understand language. But here's the catch: it's frozen in time. GPT-4 knows nothing past its training cutoff. Ask it about yesterday's news? Hallucination city.\n\nLLMs are brilliant at thinking but blind to the present.\n\n> RAG is the memory system <\n\nIt connects that frozen brain to live knowledge. When you ask a question, RAG searches external databases, pulls relevant documents, and feeds them to the LLM as context.\n\nSuddenly your static model becomes dynamic. Fresh data. Real facts. Zero retraining needed.\n\nThe accuracy gains are immediate. Instead of guessing from training data, the model reasons over actual retrieved information. You can audit exactly which documents influenced each answer.\n\n> AI Agents are the decision-makers <\n\nWhile LLMs think and RAG informs, neither can act. Agents wrap a control loop around the brain. They perceive goals, plan steps, execute actions, and reflect on results.\n\nAn Agent doesn't just answer questions. It researches topics, pulls data, synthesizes reports, and sends emails. All autonomous.\n\nHere's where it gets interesting.\n\nMost AI demos are just LLMs with fancy prompting. Real production systems layer all three: the LLM for reasoning, RAG for accuracy, and the Agent framework for autonomy.\n\nUse an LLM alone when you need pure language tasks: writing, summarizing, explaining.\n\nAdd RAG when accuracy matters: answering from internal docs, technical manuals, domain-specific knowledge.\n\nDeploy Agents when you need real autonomy: systems that decide, act, and manage complex workflows.\n\nThe future isn't about choosing one. It's about architecting all three together.\n\nLLMs for thinking. RAG for knowing. Agents for doing.\n\nThat's the actual intelligence stack.",
        "created_at": "Tue Nov 04 11:00:57 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1985663547595264000",
            "url": "https://pbs.twimg.com/media/G45-ed3bkAA4uFQ.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1955077938879299584",
          "name": "Connor Davis",
          "screen_name": "connordavis_ai",
          "description": "Founder of @getoutbox_ai \n\nLearn how to build AI Agents for FREE 👉 https://t.co/q9zPwlldZ4",
          "followers_count": 4020,
          "friends_count": 51,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 310,
          "favorite_count": 1511,
          "reply_count": 61,
          "quote_count": 16
        }
      },
      "stats": {
        "retweet_count": 44,
        "favorite_count": 205,
        "reply_count": 5,
        "quote_count": 1
      }
    },
    {
      "id": "1986166824841420928",
      "text": "TIFF 文件格式可能很多人都不陌生，是一种无损的突破存储格式，已经存在很久了，不过我一直没想到这背后还有故事，直到今天看到 Hacker News 上的一个热帖：《Mr Tiff》 ，原来这是一个为 TIFF 作者“正名”的故事。\n\n（本文由 AI 辅助翻译创作，提示词和原始会话见评论）\n\n作家约翰·巴克（John Buck）有一个执念：他要为那些真正发明了我们习以为常技术的工程师们著书立传，让他们的名字不被公司和时间所吞没。\n\n为了这个目标，他投入了超过一万个小时。他常说，这就像一场跨越时空的侦探游戏，你必须通过几十年前的蛛丝马迹，去拼凑一个“无限接近”的真相。\n\n在撰写《发明未来》一书时，他遇到了一个棘手的案子。\n\n约翰在研究苹果的 AIFF（音频交换文件格式）时，采访了它的创造者史蒂夫·米尔恩和马克·伦茨纳。他们提到，AIFF 的诞生离不开两个更早的“开放标准”基石：IFF 和 TIFF（标签图像文件格式）。\n\n查找 IFF 的发明者很顺利。杰里·莫里森（Jerry Morrison），电子艺界（EA）的工程师，履历清晰。\n\n但 TIFF 却毫无线索。\n\n约翰的每一次搜索，得到的结果都只有一个词：Aldus。\n\n“Aldus 创造了 TIFF。” 所有的资料都这么说。\n\n可 Aldus 是一家公司，不是一个人。这家定义了“桌面出版”概念的公司早已消失在历史长河中，被 Adobe 收购，没有留下任何关于 TIFF 创造者的线索。\n\n约翰不信邪。他开始疯狂地翻阅旧的《MacWeek》杂志，终于，在一个角落里，他找到了一个名字：史蒂夫·卡尔森 (Steve Carlson)。\n\n他兴奋地顺着这个名字查下去，又在计算机历史博物馆的口述史中找到了佐证。但很快，线索又断了。这个“卡尔森”似乎也人间蒸发了。\n\n约翰陷入了困境。为什么他找不到这个人？\n\n在绝望中，约翰下载了那份古老的 Aldus TIFF 规范文档，希望能找到作者的名字。然而，文档的作者栏一片空白。\n\n他不死心。鬼使神差地，他将那片空白区域的文字复制到了一个纯文本文档中。\n\n就在那一刻，一个隐藏在“白底白字”中的名字显现了出来：史蒂夫·卡尔森 (Steve Carlsen)。\n\n不是 \"Carls‘o’n\"，而是 \"Carls‘e’n\"！\n\n一个字母的差别。\n\n这个拼写错误，就像一道屏障，将这位发明者隐藏了几十年。\n\n约翰立刻用正确的名字 \"Carlsen\" 搜索。Bingo！专利、地址、一切都对上了。他找到了斯蒂芬·E·卡尔森（Stephen E. Carlsen）的专利，确认他曾在 Aldus 工作。\n\n约翰追踪到一个地址，发现斯蒂芬住在一个退休村里。他没有任何公开的电子邮箱。\n\n约翰使出了他最后的办法：他写了一封信，贴上邮票，寄了出去。\n\n四个月后，约翰的收件箱里出现了一封新邮件。\n\n是斯蒂芬·卡尔森。\n\n斯蒂芬确认了当年的故事。他非常谦逊，称这“没什么大不了的”。他说，当年他们只是为了让 PageMaker 软件能兼容市面上五花八门的扫描仪，与其为每个型号都写一个导入程序，不如定义一个行业标准。\n\n斯蒂芬不仅定义了标准，还亲自去游说那些第三方开发商和扫描仪制造商采用它。\n\n约翰将 TIFF 的故事写进了书里，斯蒂芬看后回复：“看起来不错。”\n\n此后，约翰再也没有收到他的回音。\n\n两年过去了。约翰突然又收到了一封邮件，来自斯蒂芬的前妻佩吉。\n\n佩吉告诉约翰，斯蒂芬在几个月前去世了。\n\n她在整理遗物时，才发现了约翰那封迟到的信。佩吉解释了为什么斯蒂芬后来不再回复：“那段时间，他已经开始挣扎着使用电脑和手机了……他是一个谦逊的人，从不主动寻求认可。”\n\n邮件的最后，佩吉写道：\n\n“谢谢您对斯蒂芬工作的认可。直到他生命的最后一刻，我都叫他‘TIFF 先生’。”\n\n“TIFF 先生”。\n\n约翰读到这里，感觉那一万多个小时的枯燥研究，在这一刻全都得到了回报。\n\n那天深夜，当家人都已入睡，约翰·巴克打开了电脑。\n\n他登上了维基百科，找到了“TIFF (Tag Image File Format)”词条。\n\n他删掉了那句含糊不清的“由 Aldus 公司创建”。\n\n然后，他一字一句地敲下了新的事实：\n\n“……由斯蒂芬·卡尔森 (Stephen Carlsen) 创建，他是 Aldus 的一名工程师。”\n\nTIFF 先生，现在，全世界都认识你了。",
      "created_at": "Wed Nov 05 20:20:46 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1986166757334069248",
          "url": "https://pbs.twimg.com/media/G5BIJIOWMAAdRmv.jpg"
        }
      ],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 0,
        "favorite_count": 11,
        "reply_count": 1,
        "quote_count": 0
      }
    },
    {
      "id": "1986166827177971804",
      "text": "原文：https://t.co/sGp4pv5cYg\n\n提示词：\n&gt; 把下面的内容改写成一个吸引人的中文故事，第三人称描述，精简有故事性：\n&gt; {原文Markdown}\n原始会话：https://t.co/OQCECNXle9",
      "created_at": "Wed Nov 05 20:20:47 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 0,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1986168275894784194",
      "text": "RT @freeliyi: 提到电车，你想到特斯拉。\n\n提到加密货币，你想到比特币。\n\n提到Meme币，你想到狗狗币。\n\n为什么是这些名字？\n\n因为它们在你心智里，占据了那个位置。\n\n这就是《定位》这本书讲的事：\n\n占据一个位置，你就不用跟所有人竞争。\n\n很多人觉得定位与自己无…",
      "created_at": "Wed Nov 05 20:26:32 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1986168173847322954",
        "text": "提到电车，你想到特斯拉。\n\n提到加密货币，你想到比特币。\n\n提到Meme币，你想到狗狗币。\n\n为什么是这些名字？\n\n因为它们在你心智里，占据了那个位置。\n\n这就是《定位》这本书讲的事：\n\n占据一个位置，你就不用跟所有人竞争。\n\n很多人觉得定位与自己无关。\n\n但实际上，无论工作、创业，还是个人发展，我们都需要定位。\n\n就拿我来说。\n\n我在推特上写书评，慢慢形成了自己的风格。\n\n结果发现，越来越多人开始模仿。\n\n有朋友甚至把我的文章，拆成AI提示词批量生产。\n\n一开始我有点焦虑。\n\n后来想通了，大家都是为了提供优质内容，没有高下之分。\n\n但问题来了：在无数的信息中，我该占据什么位置？\n\n我怎么才能，找到自己的空间？\n\n带着困惑，我重读《定位》，两个案例给了我答案。\n\n先说泰诺的例子。\n\n它出世的时候，阿司匹林是镇痛药的老大。\n\n泰诺怎么办？\n\n它没说自己效果多好，而是说：\n\n“为千百万不应服用阿司匹林的人着想。\n\n如果您的胃容易不舒服，如果您有胃溃疡，在服用阿司匹林之前应该请教一下医生。”\n\n“阿司匹林会刺激胃黏膜，引起哮喘或过敏反应，造成胃肠道隐性微量出血。”\n\n“幸好还有泰诺……”\n\n你看，泰诺没说“我比阿司匹林好”，而是重新定位了阿司匹林——指出它有副作用，不适合所有人。\n\n结果？\n\n泰诺成了镇痛药第一品牌。\n\n它不用跟阿司匹林正面竞争“谁止痛更好”，而是找到了“对某些人来说阿司匹林不适合”这个空间。\n\n再说七喜。\n\n当时可口可乐和百事可乐占了软饮料市场三分之二。\n\n七喜作为小品牌，怎么办？\n\n它没说自己配方多特别、口味多好，就说了三个字：“非可乐”。\n\n销量从8770万涨到1.9亿，成了世界第三大软饮料。\n\n我第一次读时觉得，这不就是个广告词吗，有什么了不起。\n\n这次重读，我停下来想：为什么“非可乐”这么管用？\n\n因为可口可乐在消费者心智里已经牢牢占据了“可乐”这个位置。\n\n如果七喜说“我的可乐更好喝”，那就是跟可口可乐正面竞争，根本没机会赢。\n\n七喜做的是：开辟另一个位置——你不想喝可乐的时候，喝我。\n\n这样一来，七喜就不用跟可口可乐竞争了。\n\n看完这两个案例，我发现了一个规律：\n\n不要跟领导者正面竞争，要么重新定位它（泰诺），要么开辟新位置（七喜）。\n\n这对我们有什么启发？\n\n比如你要发个Meme币。\n\n狗狗币已经占据了“第一Meme币”的位置。\n\n你不能说“我比狗狗币好”，那是正面竞争，你赢不了。\n\n你可以问：能不能开辟一个新位置？\n\n狗狗币用的是柴犬，PEPE就用了完全不同的文化IP——悲伤蛙（Pepe the Frog）。\n\n找到了自己的位置，就不用跟狗狗币竞争了。\n\n再比如找工作。\n\n面试时，不是说“我比其他候选人强”——那是正面竞争，面试官不一定信。\n\n而是问：我能在面试官心智里占什么位置？\n\n别人都是“全栈工程师”，你可以是“深度专精前端的人”。\n\n别人都强调技术，你可以是“懂技术也懂业务的人”。\n\n再比如做自媒体。\n\n大号已经占据了“全面、深度、专业”。\n\n你说“我也很全面”，那是正面竞争，你没机会。\n\n你可以是“只讲一个垂直领域的”，或者“用最简单的话讲复杂概念的”。\n\n回到我自己。\n\n我一开始想的是：怎么证明我写得比AI好？\n\n但这个问题本身就是在寻求正面竞争。\n\n我跟AI比“谁写得更好”，我赢不了，也没必要赢。\n\n我该问的是：我要在读者心智里占什么位置？\n\n想了想，我的答案是：远方来信，不是书评。\n\n书评告诉你这本书讲了什么，有什么价值，哪些观点值得注意。\n\n它追求全面、准确、有见地。\n\n来信不一样。\n\n来信是用我自己的经验，展现书的某个角度，引发你的思考。\n\n它不追求全面，而是真实。\n\n我遇到了什么困惑，为什么重读这本书，书里哪个观点击中了我，我想通了什么。\n\n前者是产品，后者是人。\n\n我不用跟“专业书评”竞争谁更全面。\n\n我有自己的位置。\n\nAI工具我当然会用，帮我整理资料、检查逻辑、优化表达。\n\n就像摄影师会用自动对焦、自动测光一样。\n\n工具越强大，会用工具的人价值反而越清晰。\n\n因为工具是工具，知道“拍什么、为什么拍”的那个人才是关键。\n\n真正的战场不在产品，在目标受众的脑子里。\n\n七喜是“非可乐”。\n\n我是“远方来信，不是书评”。\n\n不是说这样就比别人好。\n\n而是这样我能做、也愿意做。\n\n幸运的话，或许大家也喜欢。\n\n这就是我的定位。\n\n分享给大家，希望能带来启发。",
        "created_at": "Wed Nov 05 20:26:08 +0000 2025",
        "lang": "zh",
        "media": [
          {
            "type": "photo",
            "id": "1986167712544878592",
            "url": "https://pbs.twimg.com/media/G5BJAuqWcAAOoH-.jpg"
          }
        ],
        "retweet": null,
        "quoted": {
          "id": "1986080514801820129",
          "text": "@freeliyi &gt; 这应该是由于 AI 内容泛滥后大众对于内容信任感的缺失，普通人正在产生一种AI免疫反应。  我们越来越不相信那些看起来标准、完美但没有灵魂的东西。相比之下，一个你关注了很久的、活生生的博主，用他自己的方式给你推荐一款产品，这种真实感和信任感变得前所未有的珍贵。\n\nhttps://t.co/OXhlw53CBv",
          "created_at": "Wed Nov 05 14:37:48 +0000 2025",
          "lang": "zh",
          "media": [],
          "retweet": null,
          "quoted": null,
          "user": {
            "id": "3178231",
            "name": "宝玉",
            "screen_name": "dotey",
            "description": "Prompt Engineer, dedicated to learning and disseminating knowledge about AI, software engineering, and engineering management.",
            "followers_count": 142946,
            "friends_count": 1442,
            "verified": false,
            "is_blue_verified": true
          },
          "stats": {
            "retweet_count": 0,
            "favorite_count": 3,
            "reply_count": 0,
            "quote_count": 1
          }
        },
        "user": {
          "id": "1965832077758095360",
          "name": "自由李亿freeliyi",
          "screen_name": "freeliyi",
          "description": "长居欧洲写代码｜靠写作为生多年\n深度阅读分享｜创业、金融、自我成长\n目标是通过输出积累专长\n希望自己积极快乐活在当下\n快乐事业=退休（x，yt）\n和自己的全能自恋相处中｜复利追求者",
          "followers_count": 12704,
          "friends_count": 253,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 9,
          "favorite_count": 63,
          "reply_count": 9,
          "quote_count": 4
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 9,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1986172124428431603",
      "text": "这篇总结也很好：\nhttps://t.co/rQqEhdiORG\n\nAnthropic 又发布了一篇神级指南。\n\n这次的主题是：如何构建更高效的 AI 智能体 (AI Agent)，让它们能更聪明地使用工具，并且极大地节省 Token 。\n\n如果你是 AI 开发者，这篇文章绝对不容错过！\n\n它主要解决了 AI 智能体在调用工具时遇到的三大难题：Token 成本、延迟 (latency) 和工具组合的效率。\n\n怎么做到的？简单来说，它把“代码执行”和“模型编写的代码” (MCP, Model-Written Code) 结合了起来。它不再让 AI 智能体直接去“调用工具”，而是把这些工具“伪装”成代码 API，让 AI 智能体像程序员一样通过写代码来使用它们。\n\n以下是这篇指南的核心干货：\n\n1. Token 效率的“黑洞”：想象一下，如果 AI 智能体一上来就把所有可能用到的工具定义全塞进大脑（上下文窗口 (context window)），并且在执行任务时，每一步的中间结果都塞回去。这样会导致 Token 开销大到爆炸，一个复杂的多工具任务跑下来，有时会超过 15 万个 Token。\n\n2. “代码即 API” 策略：新方法是，不直接调用工具，而是把这些“模型编写的代码” (MCP) 工具包打包成代码 API（比如 TypeScript 模块）。AI 智能体可以像程序员一样“导入” (import) 并通过编程来调用它们。效果立竿见影：一个 15 万 Token 的任务，瞬间被压缩到了 2000 个 Token，节省了 98.7%！\n\n3. 工具的“渐进式发现”：不再一股脑加载所有工具。AI 智能体学会了“按需取用”，通过搜索文件系统或调用 search_tools（搜索工具）函数，只在需要时才加载当前任务相关的工具定义。这完美解决了“上下文臃肿” (context rot) 和 Token 过载的问题。\n\n4. “数据本地处理”：在把结果喂给大语言模型 (LLM) 之前，先在代码执行环境里把数据处理好（比如筛选、转换、汇总）。举个例子：AI 智能体不需要查看 1 万行的表格，代码环境会先帮它筛选出那 5 行最重要的，再交给它。\n\n5. 更优的控制流 (Control Flow)：与其让 AI 智能体一步步地“指挥”工具（比如“做完A，再做B”），不如直接用代码原生的循环 (loops)、条件判断 (conditionals) 和错误处理来管理流程。这样做，既减少了延迟，也省了 Token。\n\n6. 隐私保护：敏感数据可以在整个工作流中传递，而完全不进入大模型的“视野”（上下文）。只有那些被明确指定“返回”或“记录”的值才会被模型看到，还可以选择自动对个人身份信息 (PII) 进行脱敏。\n\n7. 状态持久化 (State Persistence)：AI 智能体可以把中间结果存成文件，“断点续传”。这样一来，它们就能处理那些需要跑很久的“大任务”，并且能跟踪进度。\n\n8. 可复用的“技能包”：AI 智能体可以把写好的有效代码保存成“可复用函数”（并配上 SKILL .MD 文档），久而久之，它就能积累出一个强大的高级“技能库”。\n\n这种方法虽然更复杂，也还不完美，但它绝对能全面提升你构建的 AI 智能体的效率和准确性。",
      "created_at": "Wed Nov 05 20:41:50 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1986099467914023194",
        "text": "Anthropic just posted another banger guide.\n\nThis one is on building more efficient agents to handle more tools and efficient token usage.\n\nThis is a must-read for AI devs!\n\n(bookmark it)\n\nIt helps with three major issues in AI agent tool calling: token costs, latency, and tool composition.\n\nHow? It combines code executions with MCP, where it turns MCP servers into code APIs rather than direct tool calls.\n\nHere is all you need to know:\n\n1. Token Efficiency Problem: Loading all MCP tool definitions upfront and passing intermediate results through the context window creates massive token overhead, sometimes 150,000+ tokens for complex multi-tool workflows.\n\n2. Code-as-API Approach: Instead of direct tool calls, present MCP servers as code APIs (e.g., TypeScript modules) that agents can import and call programmatically, reducing the example workflow from 150k to 2k tokens (98.7% savings).\n\n3. Progressive Tool Discovery: Use filesystem exploration or search_tools functions to load only the tool definitions needed for the current task, rather than loading everything upfront into context. This solves so many context rot and token overload problems.\n\n4. In-Environment Data Processing: Filter, transform, and aggregate data within the code execution environment before passing results to the model. E.g., filter 10,000 spreadsheet rows down to 5 relevant ones.\n\n5. Better Control Flow: Implement loops, conditionals, and error handling with native code constructs rather than chaining individual tool calls through the agent, reducing latency and token consumption.\n\n6. Privacy: Sensitive data can flow through workflows without entering the model's context; only explicitly logged/returned values are visible, with optional automatic PII tokenization.\n\n7. State Persistence: Agents can save intermediate results to files and resume work later, enabling long-running tasks and incremental progress tracking.\n\n8. Reusable Skills: Agents can save working code as reusable functions (with SKILL .MD documentation), building a library of higher-level capabilities over time.\n\nThis approach is complex and it's not perfect, but it should enhance the efficiency and accuracy of your AI agents across the board.\n\nanthropic. com/engineering/code-execution-with-mcp",
        "created_at": "Wed Nov 05 15:53:07 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1986099464017453056",
            "url": "https://pbs.twimg.com/media/G5AK8JFaoAAGuTp.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "3448284313",
          "name": "elvis",
          "screen_name": "omarsar0",
          "description": "Building @dair_ai • Ex Meta AI, Elastic, PhD • Sharing research and insights on AI Agents  • New cohort ➞ https://t.co/EguwCjYeNk",
          "followers_count": 271725,
          "friends_count": 699,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 86,
          "favorite_count": 672,
          "reply_count": 22,
          "quote_count": 3
        }
      },
      "stats": {
        "retweet_count": 11,
        "favorite_count": 37,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1986173551116698045",
      "text": "AI 能提升下限，但是如果自身水平不足，看不出来生成内容的问题，但如果专业的人去用 AI 生成内容，再去基于 AI 内容二次创作，反而能兼顾创作速度和质量，就像优秀的程序员借助 AI 写代码可以又快又好一样。",
      "created_at": "Wed Nov 05 20:47:30 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1986169596953412012",
        "text": "关于红牛的故事，今天有个朋友用提示词生成了，然后拿给我看\n\n我当时的感觉是连贯性和钩子上不够，但是生成的东西的确也包含了该有的内容\n\n可能还需要大家做个，最终指导型优化的agent吧",
        "created_at": "Wed Nov 05 20:31:47 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1965832077758095360",
          "name": "自由李亿freeliyi",
          "screen_name": "freeliyi",
          "description": "长居欧洲写代码｜靠写作为生多年\n深度阅读分享｜创业、金融、自我成长\n目标是通过输出积累专长\n希望自己积极快乐活在当下\n快乐事业=退休（x，yt）\n和自己的全能自恋相处中｜复利追求者",
          "followers_count": 12704,
          "friends_count": 253,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 0,
          "favorite_count": 3,
          "reply_count": 0,
          "quote_count": 1
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 11,
        "reply_count": 3,
        "quote_count": 0
      }
    },
    {
      "id": "1986176094479819047",
      "text": "以前看过的一个很好的比喻就是把 AI 作品和手写的比做工业制品和手工制品，其实工业制品整体水平已经高过人工制品的平均水平了，大众也不排斥，但好的手工制品能卖好的价钱。\n大众不喜欢的是低劣的工业制品，或者工业制品伪装成手工制品。\nhttps://t.co/PmPIUZlukW",
      "created_at": "Wed Nov 05 20:57:36 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1986174867821990209",
        "text": "@dotey 可能这就是个颗粒度的问题，就像小白感觉不出好代码一样\n\n不过有趣的事情是，大众不需要太精细的颗粒度\n\n所以很多时候可以写了就发看反馈，而不是一味找所谓写作厉害的人（比如我）修改",
        "created_at": "Wed Nov 05 20:52:44 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1965832077758095360",
          "name": "自由李亿freeliyi",
          "screen_name": "freeliyi",
          "description": "长居欧洲写代码｜靠写作为生多年\n深度阅读分享｜创业、金融、自我成长\n目标是通过输出积累专长\n希望自己积极快乐活在当下\n快乐事业=退休（x，yt）\n和自己的全能自恋相处中｜复利追求者",
          "followers_count": 12704,
          "friends_count": 253,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 0,
          "favorite_count": 1,
          "reply_count": 0,
          "quote_count": 1
        }
      },
      "stats": {
        "retweet_count": 0,
        "favorite_count": 8,
        "reply_count": 1,
        "quote_count": 0
      }
    },
    {
      "id": "1986177655956275225",
      "text": "RT @Hallof888: AI带来的“第二次文艺复兴”比生产力的提升更重要，很多人都太关注于效率提升，而忽略了背后的海啸级别的社会变革正在酝酿。\n\n15世纪文艺复兴带来的是人的觉醒与知识民主化（印刷术 + 科学精神）…",
      "created_at": "Wed Nov 05 21:03:49 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1951858969238245749",
        "text": "AI带来的“第二次文艺复兴”比生产力的提升更重要，很多人都太关注于效率提升，而忽略了背后的海啸级别的社会变革正在酝酿。\n\n15世纪文艺复兴带来的是人的觉醒与知识民主化（印刷术 + 科学精神）\n\n今天的AI则带来认知能力的民主化，让每个人都拥有专家级的认知助手。每个人都拥有一个浓缩了人类社会发展几千年来的知识遗产宝库钥匙，只是取决于你是否愿意打开宝库。\n\nLLM像印刷术 + 哥白尼 + 牛顿 + 达芬奇的合体，极大释放个体的创造力和行动力。\n\n人类第一次可以将“语言”- 这个最古老的魔法，转化为通用认知引擎，重新激活了思想的力量。\n\n“思想有多远，就能走多远”\n“人类失去联想，世界将会怎样”\n这两句古早级别的广告语对当下AI解放思维的现状起到了最好的阐述。\n\n过往的大众被工业社会打造为螺丝钉，AI的全流程化能力使得超级个体快速崛起。一个人可以从创意，设计，计划到实施。\n\n过往的中产无法接触到知识金字塔上的皇冠，和巴菲特吃顿午餐要几千万，知识和经验是属于贵族的专属。现在最聪明知识最渊博的AI可以近乎免费给你指名方向。\n\n过往的哲学家精于思考，但缺乏执行的手段，或者被执行的琐碎所劝退，今天有一个理解在线，情商在线，执行给力的助手。就像福尔摩斯拥有了华生一样，探索变得更有实地感。让前沿工作者，哲学家能更聚焦于未知的探索。\n\n这些都是思维解放所带来的，对各个阶层所造成的冲击，而且这还属于冲击的早期，类比于达芬奇刚刚开始研究人体解刨学，牛顿还在观察苹果落地。\n\n看看X上的高质量文章逐步增多，就知道AI对认知的提升和思维的解放有多大影响。\n\n思维和认知永远是决定人类命运上限的东西，行动则是保证下限的兜底。过去几十年，工业革命主要是保证了行动的效率，大大丰富了物产，工业制品的泛滥使得每个人都能拥有基本用品，贫困的下限得以提高。未来几十年，AI引发的思维效率提升，认知上限提升，将极大拓展人类的命运上限。这个上限包括了医疗，教育，社会治理等方方面面，也会进一步加大上限和下限的差距。",
        "created_at": "Sun Aug 03 04:13:36 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "890596889975898112",
          "name": "RickyH",
          "screen_name": "Hallof888",
          "description": "#AI engineering #LLM #Agent #Philosophy of AI\n\n#LLM: Second Renaissance#\n\nI am focusing on AI native process,organizations and how it will change world.",
          "followers_count": 326,
          "friends_count": 346,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 4,
          "favorite_count": 14,
          "reply_count": 4,
          "quote_count": 2
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 4,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1986186408080666922",
      "text": "刚测试了一下，codemaps 真的还可以，能帮助你了解特定功能的workflow，快速定位到相关代码位置，不过注意还是需要有一定编程基础，不然还是看不懂。\n对于新人入职熟悉现有代码库会帮助很大，或者去看一些比较复杂的开源程序都会有帮助。 https://t.co/qWy9XxvKRb",
      "created_at": "Wed Nov 05 21:38:35 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1986186152760459265",
          "url": "https://pbs.twimg.com/media/G5BZyF0WQAE8_a3.jpg"
        }
      ],
      "retweet": null,
      "quoted": {
        "id": "1985762813252378905",
        "text": "first DeepWiki, now Codemaps.\n\ninvesting in coding agents increases separation from you and your code, increasing chance of slop.\n\ninvesting in codebase understanding scales with model intelligence and keeps you both accountable for what you ship and increases your confidence in shipping the hardest, highest value code.",
        "created_at": "Tue Nov 04 17:35:23 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1985762245364645888",
            "url": "https://pbs.twimg.com/media/G47YPbtXgAA0bnv.jpg"
          },
          {
            "type": "photo",
            "id": "1985762806038253568",
            "url": "https://pbs.twimg.com/media/G47YwEYX0AAnOdb.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "33521530",
          "name": "swyx",
          "screen_name": "swyx",
          "description": "achieve ambition with intentionality, intensity, & integrity \n\n- @dxtipshq \n- @sveltesociety\n- @aidotengineer \n- @latentspacepod \n- @cognition + @smol_ai",
          "followers_count": 130706,
          "friends_count": 3489,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 32,
          "favorite_count": 608,
          "reply_count": 24,
          "quote_count": 6
        }
      },
      "stats": {
        "retweet_count": 9,
        "favorite_count": 64,
        "reply_count": 4,
        "quote_count": 1
      }
    }
  ]
}