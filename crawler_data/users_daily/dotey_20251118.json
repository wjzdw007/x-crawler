{
  "user": {
    "screen_name": "dotey",
    "name": "宝玉",
    "description": "Prompt Engineer, dedicated to learning and disseminating knowledge about AI, software engineering, and engineering management.",
    "followers_count": 144778,
    "verified": false,
    "is_blue_verified": true
  },
  "date": "20251118",
  "last_updated": "2025-11-18T14:05:24.887402",
  "tweet_count": 10,
  "tweets": [
    {
      "id": "1990580371147444609",
      "text": "RT @Linkc: 说一下我这边的设计团队的情况，角色也完全转变了。\n之前一个设计项目过来，总监、手绘、视觉、3D都要动起来，流水线作业，在几个流程之间反复。…",
      "created_at": "Tue Nov 18 00:38:38 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1990567871681057243",
        "text": "说一下我这边的设计团队的情况，角色也完全转变了。\n之前一个设计项目过来，总监、手绘、视觉、3D都要动起来，流水线作业，在几个流程之间反复。\n现在的状态是，所有设计师取消垂直定位，每个人的title都是美术指导或者设计项目负责人。从需求讨论开始进场，手绘草图直接给AI生成高保真效果，需求方有问题现场就改。后续各种形式的素材80%用AI生成，精细交付物比如3D模型、雕塑、程序外包出去。一个设计迭代周期可以从3周压缩到1周，投入的设计师资源也减少了几倍。\n出了成本上的变化，最重要的是参与者变少以后不用再费心信息对齐问题，可以省掉80%无聊的会议。不用在视觉、美感层面无休止地讨论，设计师一个人就能决定。（当然客户的意见更重要）\n我们22年Q3开始接触AI，年底第一次做纯AI商业项目，23年Q2的一个展会项目开始尝试运行这套机制。总之需要团队转变，前期投入学习成本，也需要公司能接受新的运作方式。",
        "created_at": "Mon Nov 17 23:48:58 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": {
          "id": "1990511327501025536",
          "text": "Peter Yang 对 Cursor 设计负责人 Ryo Lu 的访谈中，其中两点尤其认同：\n\n1. 在 AI 原生（AI-native）公司里，角色边界会变得很模糊。\n\n在 Cursor，设计师、产品经理、工程师之间的分工并不是传统那种各管一摊。\n\nRyo 的说法是：大家会根据自己的长处来做事，谁更擅长就多承担那一块，然后用 AI Agent 把这些工作串起来，形成一个完整的产品体验。\n\n2. 模型越强，规格说明（spec）就越重要，而不是越不重要。\n\nRyo 的预测是：随着大语言模型能力越来越强，它们会变得非常擅长“严格按规格实现需求”。\n\n这意味着：你的 spec 写得有多清晰、具体、准确，很大程度上就决定了 AI 帮你做出来的东西质量有多高。\n\n3. 分批发布，每一轮都会根据反馈打磨调整\n\nRyo 讲了 Cursor 内部发布的节奏：\n\n第一步，先发给公司内部员工用；\n\n第二步，再把最新的 nightly build 发给 Cursor 的忠实用户；\n\n第三步，才逐步推给普通用户；\n\n最后，才是企业用户（enterprise）。\n\n每一批用户都是一次打磨机会，让他们在小范围发现问题、修细节，再扩大范围。",
          "created_at": "Mon Nov 17 20:04:17 +0000 2025",
          "lang": "zh",
          "media": [],
          "retweet": null,
          "quoted": null,
          "user": {
            "id": "3178231",
            "name": "宝玉",
            "screen_name": "dotey",
            "description": "Prompt Engineer, dedicated to learning and disseminating knowledge about AI, software engineering, and engineering management.",
            "followers_count": 144733,
            "friends_count": 1452,
            "verified": false,
            "is_blue_verified": true
          },
          "stats": {
            "retweet_count": 7,
            "favorite_count": 49,
            "reply_count": 3,
            "quote_count": 3
          }
        },
        "user": {
          "id": "14430631",
          "name": "陈言Linkc-Chen",
          "screen_name": "Linkc",
          "description": "🚀 果壳AI创新实验室负责人，连续创业失败者。\n📱 自媒体副业，3个月变现10w+，一年做到小红书AI赛道头部。",
          "followers_count": 2089,
          "friends_count": 340,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 1,
          "favorite_count": 13,
          "reply_count": 1,
          "quote_count": 0
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 1,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1990583480929914922",
      "text": "转译：也许你并没有真正尝试——能干的人，也会选择性地无能为力\n作者：Cate Hall\n\n五年前的假期里，有两件事情同时发生在我身上：我去了戒毒康复中心，并且遭遇了一名网络跟踪者。\n\n这两件事并非完全没有关联。那个跟踪我的人来自印度，他是在我玩扑克牌时开始关注我的。他逐渐认定我们之间存在某种亲密关系，并坚信我的每条推特都是专门发给他的暗号。\n\n当我连续两个月停止发推后，他确信我一定出事了，于是找到我的邮箱和电话号码，开始疯狂给我发消息，逼问我的下落。\n\n当我意识到这一切时，情况已经失控了。我明确地知道，自己永远不会回应他。我开始不断拉黑他的账号，但他总能换个号码、注册新账号或用其他方法找到我。他每天给我发几十条消息，从威胁到哀求都有。半年后，他甚至找到了我的公司申请职位，我由此得知了他的真实姓名，试图通过他的一位旧友来寻求帮助。然而，那位朋友却因为害怕惹祸上身而拒绝帮忙。我感觉自己束手无策，只好寄希望于他迟早会放弃。\n\n但他从未放弃。数年过去了，我从未回复过他，他却每天依旧给我发数条消息。这些消息越来越恐怖，越来越色情，甚至威胁称会来伯克利伤害我。去年11月，情况终于到了极点：短短几天内，他向我发来了他刚办好的护照和签证申请的照片，并宣称即将前往美国。同时，他通过伪装我的电话号码向我哥哥勒索了一笔钱，声称绑架了我。\n\n「受够了！」我愤怒地想，我决定立刻行动起来。但事实上，我什么都没做。我只是蜷缩成一团哭泣，朋友们劝我报警，我却绝望地认为，自己在美国，他在印度，报警根本没用。\n\n可我的丈夫并不这样想。他坚持认为一定有更好的办法，并请求我允许他代我处理此事。他迅速联系了FBI和美国驻印度领事馆，并在他朋友Govind的帮助下（Govind在印度有亲戚），成功联系到当地警方。短短几个月后，问题得到彻底解决。那个跟踪者再也无法踏上美国的土地。\n\n这件事最有意思的一点是，我丈夫采取的策略并不特别新颖。他所用的方法，和我帮别人处理类似问题时能想到的几乎一模一样。那么，为什么非得另一个人介入，我才明白自己并没有真正尝试过？\n\n我想原因可能是这样的：当跟踪者进入我生活时，我正处于人生的低谷期——孤独、迷茫又穷困潦倒。当时我采用的唯一应对办法，就是忽略并寄希望于他自己放弃，这似乎是当时我唯一有能力做的事。但问题在于，我对这个问题的态度，从那时起就被固定住了。后来，我的生活状况逐渐改善，我的能力也增强了，可我从未重新评估过当时的做法是否正确。\n\n我想，我们所有人都是如此。\n\n人并非简单地高能或低能，而是选择性地拥有行动力（selectively agentic）。\n\n假设我们把生活分成三大领域：工作、与他人的关系（包括所有人际关系）、以及自我关系（身体健康、自我探索、情绪成长等等）。事实上，每个人可能都有至少一个领域，仍然停留在早年未成熟的阶段。在那个领域，我们面对问题时就像十几岁的孩子一样幼稚和无助，而事实上我们早已成年。\n\n在我所处的圈子里，有许多工作领域的高成就者。他们在科学、技术和政策领域不断创新，改变世界。但他们中的不少人，却没有将同样的聪明才智应用到内心的成长和人际关系中。他们能在异国他乡成功推出新产品，却抱怨在约会软件上找不到有趣的人。\n\n默认情况下，我们面对一个曾经失败过的问题时，总是停留在最初尝试并失败的那种无助状态。\n\n比如，假设你20岁时曾尝试过心理治疗，但并未有效缓解焦虑。你逐渐认定这是个无法解决的问题，于是接受焦虑就是你性格的一部分。但现在，你可能已经32岁了，是一家创业公司的技术主管。当工作中遇到难题时，你总能竭尽全力，尝试各种方法，不断学习。可对待自己的焦虑问题时，你却不再尝试了。\n\n你可能从没认真想过自己是否能：\n- 仔细检查自己的营养和睡眠状况；\n- 了解各种补剂或药物；\n- 投资改善自己的休息与恢复；\n- 问问朋友们最有效的治疗方法，寻找最优秀的治疗师或教练；\n- 研究一些专为你这样的人开发的新疗法。\n\n你没做这些事，只是忍受，或者用最初学到的需要极大意志力的方法来抵抗焦虑。这种挣扎让你觉得自己很努力。然而感受到辛苦，并不意味着你真正尝试过了。\n\n这让我想起了亚历山大技巧（Alexander Technique）的一个相关概念：“感知失真”（faulty sensory appreciation）。长久习惯的身体紧张会扭曲你的感官，让你误以为僵硬的姿势才是“良好的体态”。同理，那些选择性无能的人可能也有感知失真的情况。比如你觉得人际关系总是困难重重，需要不断付出意志力，这种辛苦甚至成了你努力的证明。然而，不断地挣扎可能只是说明你的生活结构存在问题。\n\n我建议你假设，在你的生活中肯定存在某个领域，你不自觉地被冻结在了过去的某个状态。这非常值得你仔细排查。仔细审视一下工作、与他人关系和自我关系这三个方面，找出你面对的最大问题。有时候，它可能看起来并不像个具体问题，而只是一种悲伤或愤怒，比如没人理解的悲伤，或工作缺乏意义的挫败感。\n\n找到它们后，问问自己：“我真的已经尽了全力、用尽了所有资源去想办法了吗？如果换成朋友遇到同样的问题，我能否给出更好的建议？我如何确定自己是真的尝试过了？”\n\n注：作者的新书《You Can Just Do Things》即将出版。\n\n---\n\n来源：https://t.co/Wnaj0aUlvA",
      "created_at": "Tue Nov 18 00:50:59 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 1,
        "favorite_count": 5,
        "reply_count": 1,
        "quote_count": 1
      }
    },
    {
      "id": "1990599007530303588",
      "text": "https://t.co/aBhEeNzIge 来自 X 账号 TestingCatalog 的爆料：Google 在 Gemini 企业版（Gemini Enterprise）里新增多智能体「自动做研究」模式\n\nGoogle 正在 Gemini for Enterprise 里打造一个多智能体系统。你给它一个主题，再配上一套评估标准，它就能自己生成一大堆点子，然后拉起一整支智能体团队，像打锦标赛一样一轮轮评审这些点子。\n\n这个系统一次可以连续干活大约 40 分钟。对一个面向普通企业用户的产品来说，这已经是非常长的一次连续推理过程了。\n\n在这 40 分钟结束时，用户会收到一大串点子清单，按你一开始设定的标准从优到劣排好名。整个规模也不小：系统一次能产出大约 100 个点子。对每一个点子，你都能拿到：\n- 一个概览\n- 一个更详细的说明\n- 一份点评总结\n- 一份完整长评\n- 以及一份专门的「锦标赛表现报告」（tournament performance report）\n\n这个「表现报告」还是一个单独的输出，可以单独打开慢慢看。所有生成出来的点子都是可选择的，你可以点进任意一个，继续深入展开。\n\n在当前的内测版本里，Google 看起来内置了三个智能体，其中有两个就是搭在这个多智能体「锦标赛」系统之上的。\n\n第一个叫 “Idea Generation”（创意生成）\n\n在这个模式里，你只要给一个主题，这个智能体就会启动整套多智能体工作流，用「锦标赛式评估」（tournament-style evaluation）来生成和排序各种相关点子。（所谓锦标赛式，就是不断让方案互相“对决”，胜出的留下，弱的被淘汰）\n\n第二个叫 “Co-scientist”（联合科学家）\n\n这个则更偏向科研和研究场景。你可以指定一个研究主题，再提供一些额外数据，然后一整个智能体团队会先生成研究方向和方案，再用同样的锦标赛机制去评估这些想法，只是这次会更强调科研和科学探索的需求。\n\n这里最有意思的一点，是它背后明显投入了非常夸张的算力。允许智能体在一个任务上连续工作大约 40 分钟，这在现在的大多数智能体工具里都算是「豪华配置」了。\n\n在整个 40 分钟里，系统会不断迭代这个问题，不停生成、筛选、打分、重组。目前，这一切都还只出现在 Gemini for Enterprise 里，属于内部开发阶段，对普通用户是隐藏的，还没有以正式功能形式对外开放。\n\n跟现有的智能体实现相比，这一套看起来是个明显的前进一大步。就算是那些已经带浏览器模式的高级智能体，通常也会受限于上下文窗口和时间预算（time budget）。\n\n而这次，Google 的做法，是直接把一大块算力「摆在台面上」给企业客户用，做成一个正儿八经的前端产品界面。这也和所谓的「Level 3 AI」的概念非常契合：这一层级的 AI 智能体，被描述为可以在同一个问题上持续工作一段较长时间。（这里的 Level 3 并不是统一标准，更像是行业里对“能长时间连续工作的智能体”的一种非正式分级说法）从这个角度看，让智能体在单个任务上跑满 40 分钟，是一个非常典型、甚至偏激进的例子。\n\n在实际使用中，这套系统输出的核心是「被充分筛选和精炼过的点子集合」。但它们远不只是随手抛出来的一堆建议，而是可以视为一组结构化的研究方向：在你给定的数据和问题背景下，这些方向有可能真正指向高价值的洞见。所以，Google 正在推进这种极其强力的智能体能力，专门服务于组织、公司和研究团队，这件事本身非常耐人寻味。\n\n等这项功能真正对外发布时，很可能会是一次不小的跃迁，尤其是如果这些智能体最终由 Gemini 3 Pro 来驱动的话。现在，Gemini 3 Pro 还没有进入 Gemini Enterprise，所以目前还不清楚这些实验性智能体背后具体用的是哪一个模型。\n\n这里依然有很多东西需要测试和验证。当你把一个提示词（prompt）提交给这套系统时，它首先会给出一份「计划做什么」的概要：会在哪些维度上评估、打算从哪些方向出发生成和筛选点子。只有在你确认这份概要之后，系统才会真正启动那次「大任务」。这相当于在烧一大笔算力之前，先和你对齐「我到底打算怎么理解你的问题」。\n\n除了多智能体锦标赛工作流之外，Gemini Enterprise 里还有另一个智能体，叫 “chat with your docs”（和文档聊天），它配了一套独立的 UI。这个智能体允许用户上传大小最高 30MB 的 PDF，然后面向这些文档进行专门对话。\n\n这个功能同样属于 Gemini Enterprise 的一部分，目前还没有对外发布，而且在生产环境中暂时不可用。它的设计思路是：最多 30MB 的 PDF 内容可以被分析并写入模型的上下文里，这样用户就能从现有文档中抽取更有价值的信息，而不是只靠人自己翻页看。\n\n在 Gemini Enterprise 里，还有不少其他功能正在开发中，但真正最抢眼的，还是这两条线：\n1. 多智能体锦标赛式工作流\n2. 面向文档的专用智能体\n\n特别是那个基于锦标赛的多智能体架构，看起来就是一种突破性的产品路线——其他大语言模型（LLM）服务商，目前似乎还没有在这个层级上，给用户提供类似的东西。多智能体锦标赛在面向终端用户的工具里依然非常少见。也许可以拿 Grok Heavy 来做某种对比，但很可能也不能算是和 Google 这套完全同一个方向的东西。\n\n等这些智能体成熟之后，如果能看到一套正式的评估结果和基准测试，那会非常有价值。光从现在的描述来看，那个 Co-scientist 智能体已经足够让很多大型组织和研究团队心动——尤其是那些正在探索新科学方向的团队。\n\n至于这些智能体具体什么时候会正式上线，或者会不会开放给非企业用户，目前还都是未知数。\n\n来源：https://t.co/g3qDUK7cbR",
      "created_at": "Tue Nov 18 01:52:41 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "video",
          "id": "1990408684631924736",
          "url": "https://video.twimg.com/amplify_video/1990408684631924736/vid/avc1/3840x2008/rmctRjqa-MaUX9XP.mp4?tag=21",
          "bitrate": 25128000
        }
      ],
      "retweet": null,
      "quoted": null,
      "stats": {
        "retweet_count": 2,
        "favorite_count": 39,
        "reply_count": 6,
        "quote_count": 3
      }
    },
    {
      "id": "1990612409900273746",
      "text": "一方面我不喜欢 Andrej Karpathy 总是发明新的概念，一方面又不得不承认他确实很多想法是很有价值的。\n\n比如这里对 Software 1.0/2.0 的定义就挺好的：\n1). 软件1.0时代，容易自动化的是你能明确告诉计算机怎么做的事情。\n2). 软件2.0时代，容易自动化的是你能自动验证结果好坏的事情。\n\n那这里的自动化都什么意思呢？\n\n1. 软件1.0：靠指定规则（Specify Rule）自动化\n\n过去的几十年，我们用的所有传统软件（比如Excel、Word、会计系统），都是“软件1.0”。\n\n它的核心逻辑是“指定”（Specify）。\n\n你必须像个事无巨细的监工，把每一个规则都用代码写得清清楚楚。比如做个会计软件，你必须告诉它：\n“如果A栏的数字大于B栏，那么C栏就显示红色。”“月末，把所有D栏的数字加起来，放到Z栏。”\n\n软件1.0擅长什么？ 自动化那些规则固定、逻辑清晰的任务。\n\n软件1.0解决的是什么问题呢？ 是人类的“机械性重复劳动”。比如打字员、记账员、算账员。只要一个任务的全部流程能被清晰描述出来，软件1.0就能接管它。\n\n2. 软件2.0：靠指定目标（Specify Objective）自动化\n\n现在，AI 来了，升级到了软件2.0。\n\n它的逻辑完全变了。我们不再是指定规则，而是设定目标。\n\n我们不再像监工一样告诉AI每一步怎么做，而是像个教练，只告诉它验收的标准是什么。\n\n比如训练AI下棋。我们不告诉它“当对方出这一招，你就必须走那一步”。我们只给它一个目标：“想办法赢棋”。\n\n然后，AI 就开始自己搜索那个能赢棋的步骤。它通过海量的自我对弈（也就是梯度下降）来寻找最佳策略。\n\n这就是 AK 的核心观点：软件1.0是我们手动写程序，软件2.0是AI自动搜索生成程序。\n\n3. 软件 1.0 时代看“可指定性”（Specifiability），2.0 时代看“可验证性”（Verifiability）。\n\n如果说软件 1.0 自动化任务的标准是我们能不能指定清晰的规则，比如说你要写个自动抓取的爬虫，只要指定清晰饿抓取规则和解析规则就可以了。\n\n那么软件 2.0 自动化任务的标准则是结果是不是能自动被验证。\n\n“可验证性”就是AI能不能在一个任务上进行高效的“刻意练习”。\n\nAK 给出了“可验证”的三个关键条件：\n\n1). 可重置 (Resettable)\nAI必须能够无限次地重新开始尝试。比如下棋，这局输了，没关系，棋盘一清，马上开下一局。\n\n2). 高效率 (Efficient)\nAI的练习速度必须远超人类。它可以在一小时内“看”完人类一辈子都看不完的视频，一天内下几百万盘棋。\n\n3). 可奖励 (Rewardable)\n这是最关键的一点。必须有一个自动化的、即时的、没有争议的奖惩机制。\n\n自动化至关重要。如果AI每次做完一件事，都需要一个人类专家来看半天，然后给个模棱两可的评价（比如“嗯，这个创意还行”），那AI就没法高效学习。\n\n像在编程、数学领域就很容易符合上面的三个条件，但是像写作这种非标准化的就很难验证。\n\n但对于软件来说，稍微复杂一点的软件系统，其实很难达到可验证的标准。\n\n比如说我在实现 UI 时，会尝试把 UI 设计稿扔给 AI，然后给 AI 一个截图工具，让它反复截图对比设计稿，然后找出差异优化，但是以目前的 AI 能力，还不足以修复这些差异，所以无论你运行多久，也不会真的得到一个理想的结果。\n\n这可能就是我不太喜欢 AK 发明的这些新概念的原因，总是提出一个个概念，但是并没有解决多少问题。",
      "created_at": "Tue Nov 18 02:45:56 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1990116666194456651",
        "text": "Sharing an interesting recent conversation on AI's impact on the economy.\n\nAI has been compared to various historical precedents: electricity, industrial revolution, etc., I think the strongest analogy is that of AI as a new computing paradigm (Software 2.0) because both are fundamentally about the automation of digital information processing.\n\nIf you were to forecast the impact of computing on the job market in ~1980s, the most predictive feature of a task/job you'd look at is to what extent the algorithm of it is fixed, i.e. are you just mechanically transforming information according to rote, easy to specify rules (e.g. typing, bookkeeping, human calculators, etc.)? Back then, this was the class of programs that the computing capability of that era allowed us to write (by hand, manually).\n\nWith AI now, we are able to write new programs that we could never hope to write by hand before. We do it by specifying objectives (e.g. classification accuracy, reward functions), and we search the program space via gradient descent to find neural networks that work well against that objective. This is my Software 2.0 blog post from a while ago. In this new programming paradigm then, the new most predictive feature to look at is verifiability. If a task/job is verifiable, then it is optimizable directly or via reinforcement learning, and a neural net can be trained to work extremely well. It's about to what extent an AI can \"practice\" something. The environment has to be resettable (you can start a new attempt), efficient (a lot attempts can be made), and rewardable (there is some automated process to reward any specific attempt that was made).\n\nThe more a task/job is verifiable, the more amenable it is to automation in the new programming paradigm. If it is not verifiable, it has to fall out from neural net magic of generalization fingers crossed, or via weaker means like imitation. This is what's driving the \"jagged\" frontier of progress in LLMs. Tasks that are verifiable progress rapidly, including possibly beyond the ability of top experts (e.g. math, code, amount of time spent watching videos, anything that looks like puzzles with correct answers), while many others lag by comparison (creative, strategic, tasks that combine real-world knowledge, state, context and common sense). \n\nSoftware 1.0 easily automates what you can specify.\nSoftware 2.0 easily automates what you can verify.",
        "created_at": "Sun Nov 16 17:56:02 +0000 2025",
        "lang": "en",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "33836629",
          "name": "Andrej Karpathy",
          "screen_name": "karpathy",
          "description": "Building @EurekaLabsAI. Previously Director of AI @ Tesla, founding team @ OpenAI, CS231n/PhD @ Stanford. I like to train large deep neural nets.",
          "followers_count": 1475028,
          "friends_count": 1028,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 1514,
          "favorite_count": 12074,
          "reply_count": 536,
          "quote_count": 402
        }
      },
      "stats": {
        "retweet_count": 34,
        "favorite_count": 175,
        "reply_count": 13,
        "quote_count": 5
      }
    },
    {
      "id": "1990614486957322609",
      "text": "这配图画的挺好的👍\nhttps://t.co/pzAHow0m4A https://t.co/MqSrKMIMpJ",
      "created_at": "Tue Nov 18 02:54:12 +0000 2025",
      "lang": "zh",
      "media": [
        {
          "type": "photo",
          "id": "1990614380824711168",
          "url": "https://pbs.twimg.com/media/G6AVO43XUAAB2wy.jpg"
        }
      ],
      "retweet": null,
      "quoted": {
        "id": "1990218960617492784",
        "text": "Love this framing！\n\nThis is exactly what we’re building at Weco:\n- you write an eval script (your verifier)\n- Weco iterates on the code to optimize it against that eval\n\nSoftware 1.0: write the process\nSoftware 2.0: write the evaluation https://t.co/4bPfmhrTN6",
        "created_at": "Mon Nov 17 00:42:31 +0000 2025",
        "lang": "en",
        "media": [
          {
            "type": "photo",
            "id": "1990218953696624641",
            "url": "https://pbs.twimg.com/media/G56tmABWQAEmAxp.jpg"
          }
        ],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "4074787285",
          "name": "Zhengyao Jiang",
          "screen_name": "zhengyaojiang",
          "description": "Cofounder & CEO @WecoAI.\nAutomating hill climbing with AI-Driven Exploration (AIDE).\nPhD in Machine Learning @UCL_DARK.\n(Zheng=j-uhng, j as in job; yao=y-aoww)",
          "followers_count": 4808,
          "friends_count": 442,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 62,
          "favorite_count": 539,
          "reply_count": 23,
          "quote_count": 6
        }
      },
      "stats": {
        "retweet_count": 3,
        "favorite_count": 9,
        "reply_count": 1,
        "quote_count": 0
      }
    },
    {
      "id": "1990621905607340492",
      "text": "RT @Yangyixxxx: 一个套壳应用的信息差套利机会",
      "created_at": "Tue Nov 18 03:23:40 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1990353774079324280",
        "text": "一个套壳应用的信息差套利机会",
        "created_at": "Mon Nov 17 09:38:13 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": {
          "id": "1990264645454619054",
          "text": "不知道有没有了解过「拼豆」？\n虽然小众，但小红书上特别受欢迎，相关内容能达到 10w 赞\n用彩色小塑料粒，就能拼成各种像素风格的手工品，做宝可梦、星露谷物语、线条小狗效果\n\n拼豆图纸非常重要，经常能看到用户在帖子下求楼主发图纸。\n重要的来了——我用阿里新发的千问 APP 的时候，发现Qwen-image 模型在这个任务里，能够完美的把参考图像转换为拼豆图纸……\n\n之前在别的产品里，就没见过能设计出完全正确的图纸（P2 是千问的效果，P3、4 是别家的，包括 nano-banana，差距很明显）。\n\n用法也很简单，就是参考图+Prompt：转为拼豆图纸，还没见过比更稳定的模型。",
          "created_at": "Mon Nov 17 03:44:03 +0000 2025",
          "lang": "zh",
          "media": [
            {
              "type": "photo",
              "id": "1990259775914004480",
              "url": "https://pbs.twimg.com/media/G57SuKoaUAADr4W.jpg"
            },
            {
              "type": "photo",
              "id": "1990263446085238784",
              "url": "https://pbs.twimg.com/media/G57WDzFbAAAr_Jr.jpg"
            },
            {
              "type": "photo",
              "id": "1990263553098760192",
              "url": "https://pbs.twimg.com/media/G57WKBvbwAAcrh3.jpg"
            },
            {
              "type": "photo",
              "id": "1990264454240702465",
              "url": "https://pbs.twimg.com/media/G57W-ewakAEU6sF.jpg"
            }
          ],
          "retweet": null,
          "quoted": null,
          "user": {
            "id": "1810991009230376960",
            "name": "一泽Eze",
            "screen_name": "eze_is_1",
            "description": "👉👉👉 公众号：一泽Eze\n🧬 Product Manager | Prompt Engineer | AI\n🎐 Innovating for impact",
            "followers_count": 3312,
            "friends_count": 75,
            "verified": false,
            "is_blue_verified": true
          },
          "stats": {
            "retweet_count": 3,
            "favorite_count": 25,
            "reply_count": 9,
            "quote_count": 2
          }
        },
        "user": {
          "id": "3122661542",
          "name": "Yangyi",
          "screen_name": "Yangyixxxx",
          "description": "Believing is seeing",
          "followers_count": 109038,
          "friends_count": 500,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 3,
          "favorite_count": 21,
          "reply_count": 0,
          "quote_count": 0
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 3,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1990647111164309803",
      "text": "我第第一二步是反过来的，先AI解读筛选一下，再决定要不要看全文",
      "created_at": "Tue Nov 18 05:03:50 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": null,
      "quoted": {
        "id": "1990624448022728953",
        "text": "Andrej Karpathy 这个阅读方法有点意思…\n\n大概就是：\n先自己把文章/章节从头到尾过一遍，把大轮廓先搭起来；\n第二遍丢给 LLM 解释 + 总结，看看它怎么梳理；\n第三步直接开 Q&A，把想深挖的地方一个个怼出来问。\n\n很有意思，阅读这件事从一个人对着文本死磕变成一个人和一个  AI 一起拆书。\n\n这种方法能很好的解决之前那种看完了但有没什么留下来的浅刷。\n\n有人也是这种阅读习惯吗？",
        "created_at": "Tue Nov 18 03:33:47 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "1830880351801221120",
          "name": "凡人小北",
          "screen_name": "frxiaobei",
          "description": "行道途中。非求速成，惟求通达。\n2023 年扎进AI ，打通Know-How，不少赚钱项目，踩过坑，也见过光。\n围城里待得够久了，出来聊聊世界，聊聊技术、聊聊赚钱。",
          "followers_count": 19243,
          "friends_count": 352,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 40,
          "favorite_count": 236,
          "reply_count": 11,
          "quote_count": 5
        }
      },
      "stats": {
        "retweet_count": 4,
        "favorite_count": 17,
        "reply_count": 5,
        "quote_count": 0
      }
    },
    {
      "id": "1990654162363678887",
      "text": "RT @AztecaAlpaca: 其实我感觉AK也没提出很多新概念。可能平均一年一两个吧。\n\nAI是门很新的学科，在短期内诞生一大堆新概念是必然的。\n\nAK具有比较强大的影响力，会把一些概念搞火。一方面在于他的专业背景，一方面在于他有比较好的人缘，包括顶级大佬和普通技术人员都…",
      "created_at": "Tue Nov 18 05:31:51 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1990651366478323723",
        "text": "其实我感觉AK也没提出很多新概念。可能平均一年一两个吧。\n\nAI是门很新的学科，在短期内诞生一大堆新概念是必然的。\n\nAK具有比较强大的影响力，会把一些概念搞火。一方面在于他的专业背景，一方面在于他有比较好的人缘，包括顶级大佬和普通技术人员都比较认他。\n\n我看到宝玉老师的评论区有人说这是那种“只提概念不考虑落地”的做法。对此我认为说反了。\n\nAK的提出的这些概念，大多是那种已经落地的应用方式，但缺少一个名词来概述它。就像孩子出生了，在家族里找一个有威望有文化会取名的老先生来给孩子取名一样。\n\n比如vibe coding。即便他不提出来，也会有人换个词来定义那种已经普遍存在的编程方式。这个概念能火起来，本身还是因为它万事俱备，只缺个名词了。\n\n至于软件1.0，2.0之类的，其实是他多年前就试图梳理的一组概念，他有过比较深入的思考。只是今年在yc学院的演讲中把这个理念进一步延伸了一下。\n\n这是一个特别热衷于发明新概念的时代，不信的话可以看看那些厂家，尤其是某些快把《山海经》给翻烂的企业。相比之下，AK已经算是很克制了。\n\n取名字这件事情，挺有技术含量的。AK的问题还是取名的成功率过高，造成了一些“他很喜欢发明新概念”的错觉。",
        "created_at": "Tue Nov 18 05:20:44 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": {
          "id": "1990612409900273746",
          "text": "一方面我不喜欢 Andrej Karpathy 总是发明新的概念，一方面又不得不承认他确实很多想法是很有价值的。\n\n比如这里对 Software 1.0/2.0 的定义就挺好的：\n1). 软件1.0时代，容易自动化的是你能明确告诉计算机怎么做的事情。\n2). 软件2.0时代，容易自动化的是你能自动验证结果好坏的事情。\n\n那这里的自动化都什么意思呢？\n\n1. 软件1.0：靠指定规则（Specify Rule）自动化\n\n过去的几十年，我们用的所有传统软件（比如Excel、Word、会计系统），都是“软件1.0”。\n\n它的核心逻辑是“指定”（Specify）。\n\n你必须像个事无巨细的监工，把每一个规则都用代码写得清清楚楚。比如做个会计软件，你必须告诉它：\n“如果A栏的数字大于B栏，那么C栏就显示红色。”“月末，把所有D栏的数字加起来，放到Z栏。”\n\n软件1.0擅长什么？ 自动化那些规则固定、逻辑清晰的任务。\n\n软件1.0解决的是什么问题呢？ 是人类的“机械性重复劳动”。比如打字员、记账员、算账员。只要一个任务的全部流程能被清晰描述出来，软件1.0就能接管它。\n\n2. 软件2.0：靠指定目标（Specify Objective）自动化\n\n现在，AI 来了，升级到了软件2.0。\n\n它的逻辑完全变了。我们不再是指定规则，而是设定目标。\n\n我们不再像监工一样告诉AI每一步怎么做，而是像个教练，只告诉它验收的标准是什么。\n\n比如训练AI下棋。我们不告诉它“当对方出这一招，你就必须走那一步”。我们只给它一个目标：“想办法赢棋”。\n\n然后，AI 就开始自己搜索那个能赢棋的步骤。它通过海量的自我对弈（也就是梯度下降）来寻找最佳策略。\n\n这就是 AK 的核心观点：软件1.0是我们手动写程序，软件2.0是AI自动搜索生成程序。\n\n3. 软件 1.0 时代看“可指定性”（Specifiability），2.0 时代看“可验证性”（Verifiability）。\n\n如果说软件 1.0 自动化任务的标准是我们能不能指定清晰的规则，比如说你要写个自动抓取的爬虫，只要指定清晰饿抓取规则和解析规则就可以了。\n\n那么软件 2.0 自动化任务的标准则是结果是不是能自动被验证。\n\n“可验证性”就是AI能不能在一个任务上进行高效的“刻意练习”。\n\nAK 给出了“可验证”的三个关键条件：\n\n1). 可重置 (Resettable)\nAI必须能够无限次地重新开始尝试。比如下棋，这局输了，没关系，棋盘一清，马上开下一局。\n\n2). 高效率 (Efficient)\nAI的练习速度必须远超人类。它可以在一小时内“看”完人类一辈子都看不完的视频，一天内下几百万盘棋。\n\n3). 可奖励 (Rewardable)\n这是最关键的一点。必须有一个自动化的、即时的、没有争议的奖惩机制。\n\n自动化至关重要。如果AI每次做完一件事，都需要一个人类专家来看半天，然后给个模棱两可的评价（比如“嗯，这个创意还行”），那AI就没法高效学习。\n\n像在编程、数学领域就很容易符合上面的三个条件，但是像写作这种非标准化的就很难验证。\n\n但对于软件来说，稍微复杂一点的软件系统，其实很难达到可验证的标准。\n\n比如说我在实现 UI 时，会尝试把 UI 设计稿扔给 AI，然后给 AI 一个截图工具，让它反复截图对比设计稿，然后找出差异优化，但是以目前的 AI 能力，还不足以修复这些差异，所以无论你运行多久，也不会真的得到一个理想的结果。\n\n这可能就是我不太喜欢 AK 发明的这些新概念的原因，总是提出一个个概念，但是并没有解决多少问题。",
          "created_at": "Tue Nov 18 02:45:56 +0000 2025",
          "lang": "zh",
          "media": [],
          "retweet": null,
          "quoted": null,
          "user": {
            "id": "3178231",
            "name": "宝玉",
            "screen_name": "dotey",
            "description": "Prompt Engineer, dedicated to learning and disseminating knowledge about AI, software engineering, and engineering management.",
            "followers_count": 144778,
            "friends_count": 1453,
            "verified": false,
            "is_blue_verified": true
          },
          "stats": {
            "retweet_count": 34,
            "favorite_count": 175,
            "reply_count": 13,
            "quote_count": 5
          }
        },
        "user": {
          "id": "1725169104963657728",
          "name": "阿兹特克小羊驼🦙",
          "screen_name": "AztecaAlpaca",
          "description": "躺平在科技与人文的十字路口，不思进取，不求进步，随手解构虚无价值。",
          "followers_count": 1018,
          "friends_count": 571,
          "verified": false,
          "is_blue_verified": false
        },
        "stats": {
          "retweet_count": 2,
          "favorite_count": 13,
          "reply_count": 2,
          "quote_count": 0
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 2,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1990686678273671300",
      "text": "RT @Yangyixxxx: 费曼学习法为什么有效\n我觉得最重要的一件事 是它有一种很明确的反馈信号\n\n如果一个信息，我从其他地方学到了，但我却没办法自然而然的讲述给别人，并让他人理解，那这个信息我肯定是没理解的\n\n比如一个方法论有五个元素，我说第一遍的时候，可能还会查原出处…",
      "created_at": "Tue Nov 18 07:41:03 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1990639388850880981",
        "text": "费曼学习法为什么有效\n我觉得最重要的一件事 是它有一种很明确的反馈信号\n\n如果一个信息，我从其他地方学到了，但我却没办法自然而然的讲述给别人，并让他人理解，那这个信息我肯定是没理解的\n\n比如一个方法论有五个元素，我说第一遍的时候，可能还会查原出处\n\n第二遍的时候，发现总有1-2个元素记不住\n\n第三遍的时候，会有一些逻辑性做分类，然后就能陈述了\n\n第四遍第五遍的时候，基本就是自己的东西了，然后还会在这个基础上加入自己这个时空的理解，比如当下时间，环境，当下角色，对这个信息不一样角度的阐释，然后这个旧时代的信息就会有了新时代的灵魂\n\n有一些信息是从实践中抽象，归纳总结的\n有一些信息，是从书中获悉，结合演绎的\n但不论怎样，费曼学习法是一种检验，它虽然无法确认人们是否真的理解了这个信息（需要实践），但它一定能证伪，当我无法叙说这个理论或框架时，我一定是没有理解\n\n这就是费曼学习法的强大之处\n它比做题更容易被验证，因为做题是结果导向，过程可以黑盒结果可以靠蒙\n\n但费曼学习法是过程导向，讲不出就是讲不出\n\n讲的出，又分听的人是否能有所收获\n\n如果讲的东西还能按照参考受众的理解程度差异，形成不一样的表述，让受众都能有所受益\n\n那么说明这个信息至少是在表层理解了\n至于说是不是真的掌握，可以运用自如在实际生产当中，那就需要再依靠执行来确认\n\n当我们刻意练习费曼学习法时\n我们会发现一个奇妙的事情\n就是这种加深信息理解的机会\n会随着费曼学习次数的增多\n而不断增多\n\n因为每次费曼学习法都是在广播\n广播就会令信息传递\n信息传递就会有回声\n这些回声就又会为信息源头带来多次广播的机会\n于是费曼学习法就持续强化了\n这个概念就慢慢形成了一种肌肉记忆",
        "created_at": "Tue Nov 18 04:33:09 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": null,
        "user": {
          "id": "3122661542",
          "name": "Yangyi",
          "screen_name": "Yangyixxxx",
          "description": "Believing is seeing",
          "followers_count": 109038,
          "friends_count": 500,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 2,
          "favorite_count": 32,
          "reply_count": 2,
          "quote_count": 1
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 2,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    },
    {
      "id": "1990687752732524773",
      "text": "RT @0xShellywang: 为什么许多用户会觉得 AI “没那么有用”？\n\n不是 AI 不强，而是我们常常连“到底想要什么”都没说清楚。\n\n很多人第一次用 AI 的体验是这样的：\n\n“诶，它怎么不懂我在说什么？”\n“我让它做，结果不对啊？”\n“这个东西感觉用起来不太聪明…",
      "created_at": "Tue Nov 18 07:45:20 +0000 2025",
      "lang": "zh",
      "media": [],
      "retweet": {
        "id": "1990626456947568974",
        "text": "为什么许多用户会觉得 AI “没那么有用”？\n\n不是 AI 不强，而是我们常常连“到底想要什么”都没说清楚。\n\n很多人第一次用 AI 的体验是这样的：\n\n“诶，它怎么不懂我在说什么？”\n“我让它做，结果不对啊？”\n“这个东西感觉用起来不太聪明。”\n\n问题往往不在 AI，AJ 分享中提及的“AI 擅长优化，不擅长定义目标”道出了真相。\n\n现在所有 AI 的工作模式，都是一个循环：\n\n人定目标 → AI 生成方案 → 人验证结果 → 调整目标 → AI 继续优化\n\n瓶颈不在于 AI，在人：我们定义不清、也验证不好。\n\n很多人其实说不清楚自己到底要什么，也不知道结果算不算好。\n\n于是就会觉得：\n\n“怎么 AI 没那么厉害？”\n\n不是它不行，是我们的目标和验收标准太模糊。\n\n这才是白领真正的痛点，也是不少人焦虑“AI 会不会取代我”的根源。\n\nAI 时代，会拆任务、会验结果的人是最不容易被取代的。\n\n能不能把一个几个月才能知道结果的大任务，拆成 100 个一天就能验证的小任务？能不能搭建一个让 AI 大量试错的环境？\n\n做到这两件事，你在 AI 时代就已经站在前排了。\n\n许多公司用不好 AI ，也是因为验证本身就很难。\n\n现实里你会遇到四类让人头疼的任务：\n\n1. 多目标冲突：速度要快、成本要低、质量还不能降\n2. 反馈周期太长：半年才知道这玩法行不行\n3. 隐性知识太多：全靠老员工的“第六感”\n4. 强上下文依赖：换个人就得从头摸索\n\n在这些场景里，你根本不能靠结果管理，只能靠过程管理。\n\n但过程管理很贵，我们需要记录：\n\n 1. 当时的情况\n2. 考虑了什么\n3. 为什么这么选\n4. 结果如何\n\n这超级累，所以大部分公司做不到。\n\n于是就会变成：\n\n知识留在人 → 人走了，知识没了 → 新人重复踩坑 → 公司规模死在知识传递\n\n企业连“人类自己的知识”都没有结构化，AI 就更无从助力优化。\n\n企业内部，降低“记录成本”，是另外一个重要突破机会。\n\n当记录变轻，整个组织的知识开始显性化，任务就能拆，验证就能跑，AI 就能真正介入优化。\n\n学会定义目标 → 拆成小任务 → 建立快速验证机制 → 留下过程痕迹\n\n这会是 AI 时代的核心工作流。",
        "created_at": "Tue Nov 18 03:41:46 +0000 2025",
        "lang": "zh",
        "media": [],
        "retweet": null,
        "quoted": {
          "id": "1990116666194456651",
          "text": "Sharing an interesting recent conversation on AI's impact on the economy.\n\nAI has been compared to various historical precedents: electricity, industrial revolution, etc., I think the strongest analogy is that of AI as a new computing paradigm (Software 2.0) because both are fundamentally about the automation of digital information processing.\n\nIf you were to forecast the impact of computing on the job market in ~1980s, the most predictive feature of a task/job you'd look at is to what extent the algorithm of it is fixed, i.e. are you just mechanically transforming information according to rote, easy to specify rules (e.g. typing, bookkeeping, human calculators, etc.)? Back then, this was the class of programs that the computing capability of that era allowed us to write (by hand, manually).\n\nWith AI now, we are able to write new programs that we could never hope to write by hand before. We do it by specifying objectives (e.g. classification accuracy, reward functions), and we search the program space via gradient descent to find neural networks that work well against that objective. This is my Software 2.0 blog post from a while ago. In this new programming paradigm then, the new most predictive feature to look at is verifiability. If a task/job is verifiable, then it is optimizable directly or via reinforcement learning, and a neural net can be trained to work extremely well. It's about to what extent an AI can \"practice\" something. The environment has to be resettable (you can start a new attempt), efficient (a lot attempts can be made), and rewardable (there is some automated process to reward any specific attempt that was made).\n\nThe more a task/job is verifiable, the more amenable it is to automation in the new programming paradigm. If it is not verifiable, it has to fall out from neural net magic of generalization fingers crossed, or via weaker means like imitation. This is what's driving the \"jagged\" frontier of progress in LLMs. Tasks that are verifiable progress rapidly, including possibly beyond the ability of top experts (e.g. math, code, amount of time spent watching videos, anything that looks like puzzles with correct answers), while many others lag by comparison (creative, strategic, tasks that combine real-world knowledge, state, context and common sense). \n\nSoftware 1.0 easily automates what you can specify.\nSoftware 2.0 easily automates what you can verify.",
          "created_at": "Sun Nov 16 17:56:02 +0000 2025",
          "lang": "en",
          "media": [],
          "retweet": null,
          "quoted": null,
          "user": {
            "id": "33836629",
            "name": "Andrej Karpathy",
            "screen_name": "karpathy",
            "description": "Building @EurekaLabsAI. Previously Director of AI @ Tesla, founding team @ OpenAI, CS231n/PhD @ Stanford. I like to train large deep neural nets.",
            "followers_count": 1475028,
            "friends_count": 1028,
            "verified": false,
            "is_blue_verified": true
          },
          "stats": {
            "retweet_count": 1514,
            "favorite_count": 12074,
            "reply_count": 536,
            "quote_count": 402
          }
        },
        "user": {
          "id": "1415979016901648386",
          "name": "Shelly",
          "screen_name": "0xShellywang",
          "description": "AI 探索 ，币圈摸鱼\n很爱买锅跟做饭，INFJ网络话痨\n0市场预算实现1500万用户\n跑过百亿交易额\nCooking MaybeAI & OmniMCP & Footprint",
          "followers_count": 3286,
          "friends_count": 237,
          "verified": false,
          "is_blue_verified": true
        },
        "stats": {
          "retweet_count": 7,
          "favorite_count": 41,
          "reply_count": 3,
          "quote_count": 1
        }
      },
      "quoted": null,
      "stats": {
        "retweet_count": 7,
        "favorite_count": 0,
        "reply_count": 0,
        "quote_count": 0
      }
    }
  ]
}