#!/usr/bin/env python3
"""
å®æ—¶æ•°æ®éªŒè¯å™¨ - ä¸“é—¨é’ˆå¯¹å®æ—¶çˆ¬å–æ•°æ®çš„éªŒè¯é€»è¾‘
ä¸å¼ºåˆ¶è¦æ±‚å†…å®¹åŒ¹é…ï¼Œé‡ç‚¹éªŒè¯æ•°æ®ç»“æ„å’Œå®Œæ•´æ€§
"""

from tools.validator import DataValidator, ValidationResult
from typing import List, Dict, Optional

class RealtimeValidator(DataValidator):
    """å®æ—¶æ•°æ®éªŒè¯å™¨ - ç»§æ‰¿åŸºç¡€éªŒè¯å™¨å¹¶ä¼˜åŒ–éªŒè¯é€»è¾‘"""
    
    def compare_with_golden_dataset_realtime(self, tweets: List[Dict], golden_dataset_file: str) -> ValidationResult:
        """å®æ—¶æ¨¡å¼çš„é»„é‡‘æ•°æ®é›†å¯¹æ¯” - ä¸»è¦éªŒè¯ç»“æ„è€Œä¸æ˜¯å†…å®¹"""
        issues = []
        details = {}
        
        try:
            with open(golden_dataset_file, 'r', encoding='utf-8') as f:
                golden_data = json.load(f)
        except:
            return ValidationResult(False, 50, ["æ— æ³•è¯»å–é»„é‡‘æ•°æ®é›†"], {})
        
        golden_posts = golden_data.get('baseline_tweets', [])
        
        # å®æ—¶æ•°æ®éªŒè¯é€»è¾‘
        score = 100
        
        # 1. æ•°é‡æ£€æŸ¥ï¼ˆä»…ä½œä¸ºä¿¡æ¯ï¼Œä¸å¤§å¹…æ‰£åˆ†ï¼‰
        count_diff_ratio = abs(len(tweets) - len(golden_posts)) / len(golden_posts) if golden_posts else 1
        if count_diff_ratio > 0.5:  # è¶…è¿‡50%æ‰è­¦å‘Š
            issues.append(f"æ¨æ–‡æ•°é‡å·®å¼‚: {len(tweets)} vs {len(golden_posts)} (å®æ—¶æ•°æ®æ­£å¸¸)")
            score -= min(10, count_diff_ratio * 20)  # æœ€å¤šæ‰£10åˆ†
        
        # 2. æ•°æ®ç»“æ„éªŒè¯ï¼ˆè¿™ä¸ªå¾ˆé‡è¦ï¼‰
        structure_score = self.validate_data_structure_consistency(tweets, golden_posts)
        if structure_score < 90:
            issues.append(f"æ•°æ®ç»“æ„ä¸€è‡´æ€§ä¸è¶³: {structure_score:.1f}%")
            score = min(score, structure_score)
        
        # 3. å†…å®¹é‡‡æ ·éªŒè¯ï¼ˆé™ä½æ ‡å‡†ï¼‰
        sample_match_score = self.validate_content_sampling(tweets, golden_posts)
        
        details = {
            "golden_posts_count": len(golden_posts),
            "current_posts_count": len(tweets),
            "structure_consistency_score": structure_score,
            "content_sampling_score": sample_match_score,
            "validation_mode": "realtime_adaptive",
            "note": "å®æ—¶æ•°æ®ä¸è¦æ±‚å†…å®¹åŒ¹é…ï¼Œä¸»è¦éªŒè¯ç»“æ„å®Œæ•´æ€§"
        }
        
        # æœ€ç»ˆè¯„åˆ†ï¼šç»“æ„å®Œæ•´æ€§æƒé‡80%ï¼Œå†…å®¹é‡‡æ ·20%
        final_score = structure_score * 0.8 + sample_match_score * 0.2
        
        return ValidationResult(
            is_valid=final_score >= 85,  # é™ä½é€šè¿‡æ ‡å‡†
            score=max(0, final_score),
            issues=issues,
            details=details
        )
    
    def validate_data_structure_consistency(self, tweets: List[Dict], golden_posts: List[Dict]) -> float:
        """éªŒè¯æ•°æ®ç»“æ„ä¸€è‡´æ€§"""
        if not tweets or not golden_posts:
            return 50
        
        # æ£€æŸ¥å…³é”®å­—æ®µå­˜åœ¨æ€§
        required_fields = ['id', 'text', 'user', 'created_at']
        optional_fields = ['media', 'stats', 'retweet', 'quoted']
        
        score = 100
        
        # æ£€æŸ¥æ¯æ¡æ¨æ–‡çš„å­—æ®µå®Œæ•´æ€§
        missing_counts = {field: 0 for field in required_fields}
        
        for tweet in tweets[:10]:  # æ£€æŸ¥å‰10æ¡
            for field in required_fields:
                if field not in tweet or not tweet[field]:
                    missing_counts[field] += 1
        
        # è®¡ç®—å­—æ®µå®Œæ•´æ€§å¾—åˆ†
        for field, missing in missing_counts.items():
            missing_ratio = missing / min(10, len(tweets))
            if missing_ratio > 0:
                score -= missing_ratio * 20  # æ¯ä¸ªå­—æ®µç¼ºå¤±æ‰£20åˆ†
        
        return max(0, score)
    
    def validate_content_sampling(self, tweets: List[Dict], golden_posts: List[Dict]) -> float:
        """å†…å®¹é‡‡æ ·éªŒè¯ - å®æ—¶æ¨¡å¼ä¸‹ä¸å¼ºåˆ¶åŒ¹é…"""
        if not tweets:
            return 0
        
        # å¯¹äºå®æ—¶æ•°æ®ï¼Œæˆ‘ä»¬ä¸»è¦æ£€æŸ¥å†…å®¹è´¨é‡è€Œä¸æ˜¯åŒ¹é…åº¦
        score = 90  # åŸºç¡€åˆ†90
        
        # æ£€æŸ¥æ–‡æœ¬è´¨é‡
        empty_text_count = 0
        for tweet in tweets[:10]:
            text = tweet.get('text', '').strip()
            if not text or len(text) < 5:  # æ–‡æœ¬è¿‡çŸ­
                empty_text_count += 1
        
        if empty_text_count > 0:
            empty_ratio = empty_text_count / min(10, len(tweets))
            score -= empty_ratio * 30
        
        return max(0, score)
    
    def comprehensive_validation_realtime(self, tweets: List[Dict], golden_dataset_file: Optional[str] = None) -> Dict[str, ValidationResult]:
        """å®æ—¶æ•°æ®çš„ç»¼åˆéªŒè¯"""
        results = {}
        
        # 1. æ–‡æœ¬å®Œæ•´æ€§éªŒè¯ (æƒé‡25%)
        results['text_completeness'] = self.validate_text_completeness(tweets)
        
        # 2. è½¬æ¨å®Œæ•´æ€§éªŒè¯ (æƒé‡25%)
        results['retweet_integrity'] = self.validate_retweet_integrity(tweets)
        
        # 3. åª’ä½“æ–‡ä»¶å¯è®¿é—®æ€§éªŒè¯ (æƒé‡25%)
        results['media_accessibility'] = self.validate_media_accessibility(tweets)
        
        # 4. æ•°æ®ç»“æ„éªŒè¯ (æƒé‡25%)
        results['data_structure'] = self.validate_data_structure(tweets)
        
        # 5. å®æ—¶é»„é‡‘æ•°æ®é›†å¯¹æ¯” (ä»…ä½œä¸ºå‚è€ƒï¼Œä¸å½±å“æ€»åˆ†)
        if golden_dataset_file:
            golden_result = self.compare_with_golden_dataset_realtime(tweets, golden_dataset_file)
            # å°†å…¶æ ‡è®°ä¸ºå‚è€ƒä¿¡æ¯
            golden_result.score = 100  # ä¸å½±å“æ€»åˆ†
            golden_result.is_valid = True
            results['golden_comparison_reference'] = golden_result
        
        return results

def main():
    """æµ‹è¯•å®æ—¶éªŒè¯å™¨"""
    import json
    
    validator = RealtimeValidator()
    
    # è¯»å–å®æ—¶æ•°æ®
    with open('crawler_data/daily_posts/20250911_recommended_posts.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    tweets = data['tweets']
    
    print(f"ğŸ” å®æ—¶éªŒè¯å™¨æµ‹è¯• - åˆ†æ{len(tweets)}æ¡æ¨æ–‡")
    
    # æ‰§è¡Œå®æ—¶éªŒè¯
    results = validator.comprehensive_validation_realtime(tweets, 'golden_dataset/golden_dataset_20250911_220234.json')
    
    # è®¡ç®—æ€»åˆ†
    core_categories = ['text_completeness', 'retweet_integrity', 'media_accessibility', 'data_structure']
    scores = [results[cat].score for cat in core_categories if cat in results]
    overall_score = sum(scores) / len(scores) if scores else 0
    
    print(f"\nğŸ“Š å®æ—¶éªŒè¯ç»“æœ:")
    for category, result in results.items():
        status = "âœ… PASS" if result.is_valid else "âŒ FAIL"
        if 'reference' in category:
            status += " (ä»…å‚è€ƒ)"
        print(f"{category}: {result.score:.1f}åˆ† - {status}")
    
    print(f"\nğŸ¯ æ ¸å¿ƒæ•°æ®è´¨é‡è¯„åˆ†: {overall_score:.1f}/100")
    
    if results.get('golden_comparison_reference'):
        ref_result = results['golden_comparison_reference']
        print(f"ğŸ“‹ é»„é‡‘æ•°æ®é›†å¯¹æ¯” (ä»…å‚è€ƒ): {ref_result.details}")

if __name__ == "__main__":
    main()