#!/usr/bin/env python3
"""
Xçˆ¬è™«å‘½ä»¤è¡Œå·¥å…· - æ”¯æŒçµæ´»å‚æ•°é…ç½®
"""

import argparse
import json

def main():
    parser = argparse.ArgumentParser(description='Xæ¨æ–‡çˆ¬è™« - ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š')
    
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        '-c', '--count',
        type=int,
        default=None,
        help='æŒ‡å®šè¦æŠ“å–çš„æ¨æ–‡æ•°é‡ (é»˜è®¤ä½¿ç”¨config.jsonä¸­çš„è®¾ç½®)'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config.json',
        help='æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)'
    )
    
    parser.add_argument(
        '--timeline',
        type=str,
        default='recommended',
        choices=['recommended', 'following'],
        help='æ—¶é—´çº¿ç±»å‹ (é»˜è®¤: recommended)'
    )
    
    parser.add_argument(
        '--max-pages',
        type=int,
        default=None,
        help='æœ€å¤§çˆ¬å–é¡µæ•° (å¯é€‰å®‰å…¨ä¸Šé™ï¼Œé»˜è®¤ç”±target_countè‡ªç„¶ç»ˆæ­¢)'
    )
    
    parser.add_argument(
        '--test',
        action='store_true',
        help='æµ‹è¯•æ¨¡å¼ - åªéªŒè¯æ•°æ®è´¨é‡ï¼Œä¸ç”Ÿæˆå®Œæ•´æŠ¥å‘Š'
    )
    
    parser.add_argument(
        '--user-summaries',
        action='store_true',
        help='ç”Ÿæˆç”¨æˆ·ä¸ªäººæ€»ç»“ - å¦‚æœæŒ‡å®š--countåˆ™æŠ“å–æ–°æ•°æ®åç”Ÿæˆæ€»ç»“ï¼Œå¦åˆ™åªå¤„ç†å·²æœ‰æ•°æ®'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„æ€»ç»“æ–‡ä»¶ (ä»…ä¸--user-summariesé…åˆä½¿ç”¨)'
    )
    
    
    args = parser.parse_args()
    
    print("ğŸš€ Xæ¨æ–‡çˆ¬è™«ç³»ç»Ÿ")
    print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
    if args.count:
        print(f"ğŸ¯ ç›®æ ‡æ•°é‡: {args.count} æ¡")
    print(f"ğŸ“ æ—¶é—´çº¿ç±»å‹: {args.timeline}")
    if args.max_pages:
        print(f"ğŸ“„ é¡µæ•°é™åˆ¶: {args.max_pages} é¡µ")
    
    try:
        if args.user_summaries and not args.count:
            # çº¯ç”¨æˆ·æ€»ç»“æ¨¡å¼ - åªå¤„ç†æ˜¨å¤©çš„æ•°æ®
            mode_text = "ç”Ÿæˆæ˜¨å¤©çš„ä¸ªäººæ€»ç»“"
            if args.force:
                mode_text += " (å¼ºåˆ¶è¦†ç›–æ¨¡å¼)"
            print(f"\nğŸ¤– ç”¨æˆ·æ€»ç»“æ¨¡å¼ - {mode_text}")
            from crawler import XCrawler
            crawler = XCrawler()
            crawler.generate_user_summaries_for_yesterday(force_overwrite=args.force)
        elif args.test:
            # æµ‹è¯•æ¨¡å¼
            print("\nğŸ§ª æµ‹è¯•æ¨¡å¼å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨æ­£å¸¸æ¨¡å¼")
        else:
            # æ­£å¸¸æ¨¡å¼ - æŠ“å–æ–°æ•°æ®
            if args.user_summaries:
                # åªæŠ“å–æ•°æ®å¹¶ç”Ÿæˆç”¨æˆ·æ€»ç»“ï¼Œä¸ç”Ÿæˆå…¨å±€æŠ¥å‘Š
                print(f"\nğŸ“¡ æŠ“å–æ•°æ®å¹¶ç”Ÿæˆç”¨æˆ·æ€»ç»“...")
                from crawler import XCrawler
                crawler = XCrawler()
                
                # ç›´æ¥ä½¿ç”¨çˆ¬è™«æŠ“å–æ•°æ®
                tweets = crawler.crawl_daily_posts(
                    timeline_type='recommended', 
                    target_count=args.count,
                    max_pages=args.max_pages
                )
                
                if tweets:
                    print(f"\nâœ… æ•°æ®æŠ“å–å®Œæˆï¼š{len(tweets)} æ¡æ¨æ–‡")
                    
                    # ä¸ºå‰ä¸€å¤©çš„æ•°æ®ç”Ÿæˆç”¨æˆ·æ€»ç»“
                    print(f"ğŸ”„ ä¸ºå‰ä¸€å¤©çš„æ•°æ®ç”Ÿæˆç”¨æˆ·æ€»ç»“...")
                    
                    crawler.generate_user_summaries_for_yesterday(force_overwrite=args.force)
                else:
                    print(f"\nâŒ æ•°æ®æŠ“å–å¤±è´¥")
            else:
                # æ ‡å‡†æ¨¡å¼ï¼šåªæŠ“å–æ•°æ®
                print(f"\nğŸ“¡ æŠ“å–æ•°æ®...")
                from crawler import XCrawler
                crawler = XCrawler()

                tweets = crawler.crawl_daily_posts(
                    timeline_type='recommended',
                    target_count=args.count,
                    max_pages=args.max_pages
                )

                if tweets:
                    print(f"\nâœ… æ•°æ®æŠ“å–å®Œæˆï¼š{len(tweets)} æ¡æ¨æ–‡")
                    print(f"ğŸ“ æ•°æ®ä¿å­˜åœ¨ crawler_data/daily_posts/ ç›®å½•")
                else:
                    print(f"\nâŒ æ•°æ®æŠ“å–å¤±è´¥")
                
    except FileNotFoundError:
        print(f"\nâŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œè®¤è¯é…ç½®:")
        print("   python working_auth.py")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. éªŒè¯è®¤è¯ä¿¡æ¯æ˜¯å¦æœ‰æ•ˆ")
        print("   3. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ä¿¡æ¯")

def show_examples():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("""
ğŸ¯ ä½¿ç”¨ç¤ºä¾‹:

# ä½¿ç”¨é»˜è®¤é…ç½®
python run_crawler.py

# æŒ‡å®šæŠ“å–200æ¡æ¨æ–‡
python run_crawler.py --count 200

# æŠ“å–50æ¡followingæ—¶é—´çº¿æ¨æ–‡
python run_crawler.py --count 50 --timeline following

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
python run_crawler.py --config my_config.json --count 150

# æµ‹è¯•æ¨¡å¼ - åªéªŒè¯æ•°æ®è´¨é‡
python run_crawler.py --test

# ç”Ÿæˆç”¨æˆ·ä¸ªäººæ€»ç»“ (æ˜¨å¤©çš„æ•°æ®)
python run_crawler.py --user-summaries

# å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„æ€»ç»“æ–‡ä»¶ (ç”¨äºæµ‹è¯•)
python run_crawler.py --user-summaries --force
# ç”Ÿæˆç”¨æˆ·æ€»ç»“ï¼ˆæç¤ºè¯å®Œå…¨ç”±é…ç½®æ–‡ä»¶å†³å®šï¼‰
python run_crawler.py --user-summaries

# æŠ“å–500æ¡æ–°æ•°æ®å¹¶ç”Ÿæˆä»Šå¤©çš„ç”¨æˆ·æ€»ç»“ (ä¸ç”Ÿæˆå…¨å±€æŠ¥å‘Š)
python run_crawler.py --count 500 --user-summaries

# æŠ“å–æ–°æ•°æ®å¹¶å¼ºåˆ¶è¦†ç›–ç”¨æˆ·æ€»ç»“
python run_crawler.py --count 300 --user-summaries --force

# æ ‡å‡†æ¨¡å¼ï¼šæŠ“å–æ•°æ®å¹¶ç”Ÿæˆå…¨å±€åˆ†ææŠ¥å‘Š
python run_crawler.py --count 500

# é«˜çº§é…ç½® - é™åˆ¶æœ€å¤§é¡µæ•°
python run_crawler.py --count 100 --max-pages 3
""")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 2 and sys.argv[1] in ['help']:
        show_examples()
    else:
        main()