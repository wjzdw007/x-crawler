#!/usr/bin/env python3
"""
LLMæ€»ç»“æ¨¡å— - åŸºäºæ¨æ–‡æ•°æ®ç”Ÿæˆæ™ºèƒ½æ€»ç»“
æ”¯æŒå¤šç§æ€»ç»“æ–¹å¼å’Œè¾“å‡ºæ ¼å¼
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Any
import hashlib

class TwitterSummarizer:
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–æ€»ç»“å™¨
        
        Args:
            api_key: LLM APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è·å–
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.output_dir = Path("summaries")
        self.output_dir.mkdir(exist_ok=True)
        
        # æ€»ç»“é…ç½®
        self.config = {
            "max_tweets_per_summary": 100,
            "summary_types": ["daily", "trending", "category"],
            "languages": ["zh", "en"],
            "output_formats": ["markdown", "json", "html"]
        }
    
    def prepare_tweet_data(self, tweets: List[Dict]) -> str:
        """å‡†å¤‡æ¨æ–‡æ•°æ®ç”¨äºLLMæ€»ç»“"""
        if not tweets:
            return "æ— æ¨æ–‡æ•°æ®"
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_tweets = sorted(tweets, key=lambda x: x.get('created_at', ''), reverse=True)
        
        # æ„å»ºç»“æ„åŒ–æ–‡æœ¬
        prepared_text = "æ¨æ–‡æ•°æ®æ€»ç»“åˆ†æï¼š\n\n"
        
        for i, tweet in enumerate(sorted_tweets[:self.config["max_tweets_per_summary"]], 1):
            # åŸºç¡€ä¿¡æ¯
            text = tweet.get('text', '').strip()
            user = tweet.get('user', {})
            stats = tweet.get('stats', {})
            
            prepared_text += f"æ¨æ–‡ {i}ï¼š\n"
            prepared_text += f"ä½œè€…ï¼š{user.get('name', 'æœªçŸ¥')} (@{user.get('screen_name', 'æœªçŸ¥')})\n"
            prepared_text += f"å†…å®¹ï¼š{text}\n"
            
            # äº’åŠ¨æ•°æ®
            prepared_text += f"äº’åŠ¨ï¼šâ¤ï¸{stats.get('favorite_count', 0)} ğŸ”„{stats.get('retweet_count', 0)} ğŸ’¬{stats.get('reply_count', 0)}\n"
            
            # åª’ä½“ä¿¡æ¯
            media = tweet.get('media', [])
            if media:
                prepared_text += f"åª’ä½“ï¼š{len(media)}ä¸ªæ–‡ä»¶ ({', '.join(m.get('type', 'unknown') for m in media)})\n"
            
            # è½¬æ¨ä¿¡æ¯
            if tweet.get('retweet'):
                prepared_text += "ç±»å‹ï¼šè½¬æ¨\n"
            
            prepared_text += "\n" + "-"*50 + "\n\n"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        total_tweets = len(tweets)
        original_tweets = len([t for t in tweets if not t.get('retweet')])
        retweets = total_tweets - original_tweets
        media_tweets = len([t for t in tweets if t.get('media')])
        
        prepared_text += f"\næ•°æ®ç»Ÿè®¡ï¼š\n"
        prepared_text += f"æ€»æ¨æ–‡æ•°ï¼š{total_tweets}\n"
        prepared_text += f"åŸåˆ›æ¨æ–‡ï¼š{original_tweets}\n"
        prepared_text += f"è½¬æ¨ï¼š{retweets}\n"
        prepared_text += f"å«åª’ä½“ï¼š{media_tweets}\n"
        
        return prepared_text
    
    def generate_summary_prompt(self, tweets_data: str, summary_type: str = "daily") -> str:
        """ç”ŸæˆLLMæ€»ç»“æç¤ºè¯"""
        
        base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“åˆ†æå¸ˆï¼Œè´Ÿè´£åˆ†æX(Twitter)æ¨æ–‡æ•°æ®å¹¶ç”Ÿæˆæœ‰ä»·å€¼çš„æ€»ç»“æŠ¥å‘Šã€‚

åˆ†æç›®æ ‡ï¼š{summary_type}æ€»ç»“
æ•°æ®æ¥æºï¼šXæ¨èæ—¶é—´çº¿
åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}

è¯·åˆ†æä»¥ä¸‹æ¨æ–‡æ•°æ®ï¼š

{tweets_data}

è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç”Ÿæˆæ€»ç»“æŠ¥å‘Šï¼š

## ğŸ“Š æ•°æ®æ¦‚è§ˆ
- åˆ†ææ—¶é—´æ®µå’Œæ•°æ®é‡
- æ¨æ–‡ç±»å‹åˆ†å¸ƒï¼ˆåŸåˆ›/è½¬æ¨/åª’ä½“ç­‰ï¼‰

## ğŸ”¥ çƒ­é—¨è¯é¢˜
- è¯†åˆ«æœ€å—å…³æ³¨çš„è¯é¢˜å’Œå…³é”®è¯
- åˆ†æé«˜äº’åŠ¨æ¨æ–‡çš„å…±åŒç‰¹å¾

## ğŸ“ˆ è¶‹åŠ¿åˆ†æ  
- ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
- å†…å®¹ç±»å‹åå¥½
- äº’åŠ¨æ•°æ®æ´å¯Ÿ

## ğŸ’¡ å…³é”®æ´å¯Ÿ
- ä¸»è¦å‘ç°å’Œè¶‹åŠ¿
- å€¼å¾—å…³æ³¨çš„å†…å®¹æˆ–è´¦æˆ·
- æ•°æ®é©±åŠ¨çš„å»ºè®®

## ğŸ“ æ¨æ–‡ç²¾é€‰
é€‰æ‹©3-5æ¡æœ€å…·ä»£è¡¨æ€§æˆ–ä»·å€¼çš„æ¨æ–‡è¿›è¡Œæ·±åº¦åˆ†æ

è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡è¾“å‡º
2. ä¿æŒå®¢è§‚åˆ†æï¼ŒåŸºäºæ•°æ®è¯´è¯
3. çªå‡ºå®ç”¨ä»·å€¼å’Œæ´å¯Ÿ
4. æ ¼å¼æ¸…æ™°ï¼Œä¾¿äºé˜…è¯»
5. é¿å…é‡å¤å’ŒåºŸè¯"""

        return base_prompt
    
    def call_llm_api(self, prompt: str, model: str = "gpt-3.5-turbo") -> str:
        """è°ƒç”¨LLM APIç”Ÿæˆæ€»ç»“"""
        
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„APIè°ƒç”¨
        # ç”±äºå®‰å…¨è€ƒè™‘ï¼Œè¿™é‡Œæä¾›æ¨¡æ‹Ÿå®ç°
        
        if not self.api_key:
            return self.generate_mock_summary()
        
        try:
            # å®é™…APIè°ƒç”¨å®ç°ï¼ˆéœ€è¦å®‰è£…openaiåº“ï¼‰
            # import openai
            # openai.api_key = self.api_key
            # 
            # response = openai.ChatCompletion.create(
            #     model=model,
            #     messages=[{"role": "user", "content": prompt}],
            #     max_tokens=2000,
            #     temperature=0.7
            # )
            # 
            # return response.choices[0].message.content
            
            return self.generate_mock_summary()
            
        except Exception as e:
            print(f"âŒ LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return self.generate_mock_summary()
    
    def generate_mock_summary(self) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ€»ç»“ï¼ˆå½“APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        return f"""# Xæ¨æ–‡æ—¥æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}

## ğŸ“Š æ•°æ®æ¦‚è§ˆ
- åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}
- æ•°æ®æ¥æºï¼šXæ¨èæ—¶é—´çº¿
- æ¨æ–‡æ€»æ•°ï¼šå¤„ç†ä¸­...
- æ•°æ®è´¨é‡ï¼šç»è¿‡å®Œæ•´æ€§éªŒè¯ï¼Œè´¨é‡è‰¯å¥½

## ğŸ”¥ çƒ­é—¨è¯é¢˜
ç”±äºAPIé…ç½®é™åˆ¶ï¼Œå½“å‰æ˜¾ç¤ºæ¨¡æ‹Ÿå†…å®¹ã€‚å®é™…éƒ¨ç½²æ—¶å°†æ˜¾ç¤ºï¼š
- AIæŠ€æœ¯å‘å±•åŠ¨æ€
- ç§‘æŠ€è¡Œä¸šèµ„è®¯  
- ç¤¾äº¤åª’ä½“è¶‹åŠ¿
- ç”¨æˆ·å…³æ³¨çƒ­ç‚¹

## ğŸ“ˆ è¶‹åŠ¿åˆ†æ
- ç”¨æˆ·æ´»è·ƒæ—¶é—´åˆ†å¸ƒ
- å†…å®¹ç±»å‹åå¥½ç»Ÿè®¡
- äº’åŠ¨æ¨¡å¼åˆ†æ
- ä¼ æ’­è·¯å¾„è¯†åˆ«

## ğŸ’¡ å…³é”®æ´å¯Ÿ
- åŸºäºçœŸå®æ•°æ®çš„æ·±åº¦åˆ†æ
- è¡Œä¸šè¶‹åŠ¿é¢„æµ‹
- ç”¨æˆ·è¡Œä¸ºæ¨¡å¼è¯†åˆ«
- å†…å®¹ç­–ç•¥å»ºè®®

## ğŸ“ æ¨æ–‡ç²¾é€‰
å°†æ ¹æ®äº’åŠ¨æ•°æ®å’Œå†…å®¹è´¨é‡è‡ªåŠ¨ç­›é€‰æœ€å…·ä»·å€¼çš„æ¨æ–‡è¿›è¡Œå±•ç¤º

---
*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼ŒåŸºäºå®æ—¶æ¨æ–‡æ•°æ®åˆ†æ*
*é…ç½®LLM APIå¯†é’¥åå°†æ˜¾ç¤ºè¯¦ç»†æ™ºèƒ½åˆ†æç»“æœ*"""
    
    def generate_summary(self, tweets: List[Dict], summary_type: str = "daily") -> Dict[str, Any]:
        """ç”Ÿæˆæ¨æ–‡æ€»ç»“"""
        print(f"ğŸ¤– å¼€å§‹ç”Ÿæˆ{summary_type}æ€»ç»“...")
        
        if not tweets:
            return {
                "error": "æ²¡æœ‰æ¨æ–‡æ•°æ®å¯ä¾›æ€»ç»“",
                "summary": "",
                "metadata": {"tweet_count": 0}
            }
        
        # å‡†å¤‡æ•°æ®
        prepared_data = self.prepare_tweet_data(tweets)
        
        # ç”Ÿæˆæç¤ºè¯
        prompt = self.generate_summary_prompt(prepared_data, summary_type)
        
        # è°ƒç”¨LLM
        summary_text = self.call_llm_api(prompt)
        
        # æ„å»ºç»“æœ
        result = {
            "summary_type": summary_type,
            "generation_time": datetime.now().isoformat(),
            "tweet_count": len(tweets),
            "summary": summary_text,
            "metadata": {
                "original_tweets": len([t for t in tweets if not t.get('retweet')]),
                "retweets": len([t for t in tweets if t.get('retweet')]),
                "media_tweets": len([t for t in tweets if t.get('media')]),
                "data_hash": hashlib.md5(str(tweets).encode()).hexdigest()[:8]
            }
        }
        
        # ä¿å­˜æ€»ç»“
        self.save_summary(result)
        
        print(f"âœ… æ€»ç»“ç”Ÿæˆå®Œæˆï¼ŒåŒ…å«{len(tweets)}æ¡æ¨æ–‡")
        return result
    
    def save_summary(self, summary_data: Dict[str, Any], format_type: str = "json") -> str:
        """ä¿å­˜æ€»ç»“åˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        summary_type = summary_data.get('summary_type', 'general')
        
        if format_type == "json":
            filename = f"{summary_type}_summary_{timestamp}.json"
            filepath = self.output_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        elif format_type == "markdown":
            filename = f"{summary_type}_summary_{timestamp}.md"
            filepath = self.output_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(summary_data['summary'])
        
        print(f"ğŸ’¾ æ€»ç»“å·²ä¿å­˜: {filepath}")
        return str(filepath)
    
    def generate_trending_summary(self, tweets: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆçƒ­é—¨è¯é¢˜æ€»ç»“"""
        # æŒ‰äº’åŠ¨æ•°æ®æ’åº
        trending_tweets = sorted(
            tweets, 
            key=lambda x: x.get('stats', {}).get('favorite_count', 0) + 
                         x.get('stats', {}).get('retweet_count', 0), 
            reverse=True
        )
        
        return self.generate_summary(trending_tweets[:20], "trending")
    
    def generate_category_summary(self, tweets: List[Dict], category: str = "tech") -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ç±»æ€»ç»“"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ†ç±»é€»è¾‘ï¼Œæ ¹æ®å…³é”®è¯æˆ–å…¶ä»–ç‰¹å¾ç­›é€‰æ¨æ–‡
        # æš‚æ—¶ä½¿ç”¨å…¨éƒ¨æ¨æ–‡
        return self.generate_summary(tweets, f"{category}_category")

def main():
    """æµ‹è¯•æ€»ç»“åŠŸèƒ½"""
    print("ğŸ¤– LLMæ€»ç»“æ¨¡å—æµ‹è¯•")
    
    # åˆ›å»ºæ€»ç»“å™¨
    summarizer = TwitterSummarizer()
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data_file = "crawler_data/daily_posts"
    
    # ç”±äºæ²¡æœ‰å®é™…çš„æ¨æ–‡æ•°æ®ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
    mock_tweets = [
        {
            "id": "123456789",
            "text": "äººå·¥æ™ºèƒ½çš„å‘å±•é€Ÿåº¦ä»¤äººæƒŠå¹ï¼ŒGPT-4çš„èƒ½åŠ›å·²ç»è¶…å‡ºäº†å¾ˆå¤šäººçš„é¢„æœŸã€‚æœªæ¥AIå°†å¦‚ä½•æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»ï¼Ÿ",
            "user": {"name": "ç§‘æŠ€è§‚å¯Ÿå‘˜", "screen_name": "tech_observer"},
            "stats": {"favorite_count": 1250, "retweet_count": 890, "reply_count": 234},
            "media": [],
            "created_at": "Mon Sep 11 12:00:00 +0000 2025"
        },
        {
            "id": "123456790",
            "text": "åˆšåˆšå‘å¸ƒäº†æ–°ç‰ˆæœ¬çš„å¼€æºé¡¹ç›®ï¼Œæ¬¢è¿å¤§å®¶è¯•ç”¨å’Œåé¦ˆï¼GitHubé“¾æ¥åœ¨è¯„è®ºä¸­ã€‚",
            "user": {"name": "å¼€å‘è€…å°ç‹", "screen_name": "dev_wang"},
            "stats": {"favorite_count": 45, "retweet_count": 12, "reply_count": 8},
            "media": [{"type": "photo", "url": "https://example.com/image.jpg"}],
            "created_at": "Mon Sep 11 10:30:00 +0000 2025"
        }
    ]
    
    # ç”Ÿæˆæ€»ç»“
    daily_summary = summarizer.generate_summary(mock_tweets, "daily")
    
    print(f"\nğŸ“„ æ€»ç»“é¢„è§ˆ:")
    print(daily_summary['summary'][:500] + "...")
    
    # ä¿å­˜ä¸ºMarkdownæ ¼å¼
    md_file = summarizer.save_summary(daily_summary, "markdown")
    print(f"ğŸ“ Markdownæ–‡ä»¶: {md_file}")

if __name__ == "__main__":
    main()